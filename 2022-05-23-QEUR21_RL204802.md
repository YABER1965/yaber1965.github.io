## QEUR21_RL2048P0:　RTメトリックスの最適化 (その1)

## ～　新しいRT・・・？　～

### ・・・　やっぱり弱気のD先生、今回のシリーズに対して「意義」を見出せるか？　・・・

D先生 ： “う～ん・・・、やっぱり強化学習って普及するにはまだ早いんじゃないですかねぇ・・・。”

![imageRL1-2-1](https://yaber1965.github.io/images/imageRL1-2-1.jpg)

D先生 ： “AIって、J国では若干遅れて2018年ぐらいに「巷の」ブームが来たでしょう。もう、現在では（ブームは）終わったような気が・・・。”

![imageRL1-2-2](https://yaber1965.github.io/images/imageRL1-2-2.jpg)

QEU:FOUNDER ： “そんなこと、わかっているって・・・。「70％はうまくいかない」というのは悲観的に見えるが、小生は逆に「30％もできること」はすごいと思うよ。現状の30％を35％や40％するための努力がいま最も必要なんです。逆に言うと、皆が放り出しちゃうと進歩がなくなりますがな・・・。”

![imageRL1-2-3](https://yaber1965.github.io/images/imageRL1-2-3.jpg)

D先生 ： “その通りです。A国のT社も2016年時点では「ゲームばっかりして遊んでいる会社」とみなされていたんですよね。そのノウハウがきちんと累積していって、現在のようなイノベーションにつながったわけです。それでも、我々にはある種の「方向性の設定」は必要じゃないかと・・・。”

![imageRL1-2-4](https://yaber1965.github.io/images/imageRL1-2-4.jpg)

QEU:FOUNDER ： “我々としては、やっぱり（テクノ）メトリックスにこだわるべきじゃないか？前回に説明したHughes現象（DLに入力するデータ規模(次元数)が大きくなりすぎると計算時間が膨大）について、もう少し詳しく検討しましょう。ここで、入力データの次元数が20次元とします。適切な制御に必要な「状態の分解能」が1次元あたり10とします。すると、なんと・・・(笑)。”

状態の規模：　20次元　、　必要な分解能：　10　→　必要なユニークな状態：　10＾20ケース

D先生 ： “うひゃぁ、スゴイ数です。これじゃぁ膨大な計算時間とデータが必要になってします。・・・んと・・・・、あれ？そういうことは、学習の計算量を少なくするには状態の規模を小さくするだけでなく、必要な分解能を最小化する必要もありますよねぇ。”

![imageRL1-2-5](https://yaber1965.github.io/images/imageRL1-2-5.jpg)

QEU:FOUNDER ： “これからやるのは2048というゲームです。これは、数字を上下左右（4通り）に滑らせて遊びます。・・・ということは、ゲームそのものが要求する分解能は1次元あたり4以下です。これ以上の分解能が必要なのは、関数が不要に複雑になっているから・・・。”

D先生 ： “ここで前回において、FOUNDERが提案したメトリックスに戻りましょう。感度(Y1)の代わりに「コサイン類似度」とSN比(Y2)の代わりに「L1（マンハッタン）距離」でしたよね・・・。そういえば、なぜユークリッド距離を使わなかったんですか？皆、どちらかというと、そちらの方が皆さんが馴染みでしょうに・・・。”

**(コサイン類似度)**

![imageRL1-2-6](https://yaber1965.github.io/images/imageRL1-2-6.jpg)

**（マンハッタン距離）**

![imageRL1-2-7](https://yaber1965.github.io/images/imageRL1-2-7.jpg)

QEU:FOUNDER ： “2つの理由があります。まず一つ目の理由は、マンハッタン距離の方がパターン特徴量として優秀であろうという予想・・・。二つ目は、RTメトリックスは成分であり、コサイン類似度とマンハッタン距離はそうでないこと・・・。まずは、一つ目の理由ね・・・。”

![imageRL1-2-8](https://yaber1965.github.io/images/imageRL1-2-8.jpg)

QEU:FOUNDER ： “上の図では、ゲームボードが数字のタイルで埋め尽くされています。つまり、ゲーム的には「かなりヤバイ状態」になっています。もし、このボードの数字「2」のボードが消えていれば、かなりゲームが楽になっているでしょう。じゃあ、ユーグリッド距離で数字「２」がある場合とない場合では、どれだけ特徴量（距離）がかわりますか？”

D先生 ： “2乗和されていますから、ユークリッド距離では、値はほとんどかわりません。あぁ・・、そういうことか・・・。”

QEU:FOUNDER ： “次に、もう一つの理由を説明するよ。RT法の感度とSN比のメトリックスは変動分解ででてきたメトリックスなので、多重共線性が起こることはないんですよ。一方、コサイン類似度とユーグリッド距離では共線性がつよいかもしれません。両方ともに2乗式でできている距離だから・・・。これを考えれば、「新RT法」という新概念も出てこない・・・わけでもない・・・（笑）。”

D先生 ： “ニヤニヤと気持ちが悪い・・・。さて、能書きが長くなりました。やっと実験にはいりましょう。”

## ～　データ採取環境を整える　～

QEU:FOUNDER ： “じゃあ、初めに画像データを採取する環境を整えましょう。最近はBlenderがクセになっちゃった・・・(笑)。”

![imageRL1-2-9](https://yaber1965.github.io/images/imageRL1-2-9.jpg)

D先生 ： “あとは、画像データ自動化のプログラムをドン！！”

```python
#newRT_camera_pic_fiveeye.py 
import bpy
from mathutils import *
import math
import os
import random
import numpy as np
import pandas as pd

# ----------
# 円周率
vpi = 3.141592

# ===========================
# ラベル
num_label = 0

# ラベルの定義
# num_label = 0 正方形(square)
# num_label = 1 円形(circle)
# num_label = 2 三角(triangle)

# ===========================

# ----------
# カメラのみを選んで削除し、再設置する
def reset_cameras(obj_cnt):

 # -----
 # remove existing cameras  
 bpy.ops.object.select_by_type(type='CAMERA')
 bpy.ops.object.delete()

 if obj_cnt == 0:
  # ランダム偏差量の設定
  diff_posX  = 0
  diff_posY  = 0
  datum_posZ = 14.0
  # -----
  diff_gradX = 0
  diff_gradY = 0
  diff_gradZ = 0
 else:
  # ランダム偏差量の設定
  diff_posX  = 0
  diff_posY  = round(random.random()*5.0 - 2.5, 2)
  datum_posZ = 14.0
  # -----
  diff_gradX = 0
  diff_gradY = 0
  diff_gradZ = random.random()*30.0 - 15.0

 # ===========================
 # CAMERA LEFT
 # ===========================
 # 位置の初期設定
 posXL = 0 + diff_posX
 posYL = -1 + diff_posY
 posZL = 14.0

 # ----
 # 角度の初期設定
 gradXL = 0 + diff_gradX
 gradYL = round(-4.09*vpi/180,2) + diff_gradY
 gradZL = round((90.0+diff_gradZ)*vpi/180,2)

 # add new cameras  
 bpy.ops.object.camera_add(location=(posXL, posYL, posZL), rotation=(gradXL, gradYL, gradZL))
 bpy.context.object.data.name="camera_left"

 # ===========================
 # CAMERA CENTER
 # ===========================
 # 位置の初期設定
 posXC = 0 + diff_posX
 posYC = 0 + diff_posY
 posZC = 14.0

 # ----
 # 角度の初期設定
 gradXC = 0 + diff_gradX
 gradYC = 0 + diff_gradY
 gradZC = round((90.0+diff_gradZ)*vpi/180,2)

 # add new cameras  
 bpy.ops.object.camera_add(location=(posXC, posYC, posZC), rotation=(gradXC, gradYC, gradZC))
 bpy.context.object.data.name="camera_center"

 # ===========================
 # CAMERA RIGHT
 # ===========================
 # 位置の初期設定
 posXR = 0 + diff_posX
 posYR = 1.0 + diff_posY
 posZR = 14.0

 # ----
 # 角度の初期設定
 gradXR = 0 + diff_gradX
 gradYR = round(4.09*vpi/180,2) + diff_gradY
 gradZR = round((90.0+diff_gradZ)*vpi/180,2)

 # add new cameras  
 bpy.ops.object.camera_add(location=(posXR, posYR, posZR), rotation=(gradXR, gradYR, gradZR))
 bpy.context.object.data.name="camera_right"

 # ===========================
 # CAMERA UP
 # ===========================
 # 位置の初期設定
 posXU = -1.0 + diff_posX
 posYU = 0 + diff_posY
 posZU = 14.0

 # ----
 # 角度の初期設定
 gradXU = round(-4.09*vpi/180,2) + diff_gradX
 gradYU = 0 + diff_gradY
 gradZU = round((90.0+diff_gradZ)*vpi/180,2)

 # add new cameras  
 bpy.ops.object.camera_add(location=(posXU, posYU, posZU), rotation=(gradXU, gradYU, gradZU))
 bpy.context.object.data.name="camera_up"

 # ===========================
 # CAMERA DOWN
 # ===========================
 # 位置の初期設定
 posXD = 1.0 + diff_posX
 posYD = 0 + diff_posY
 posZD = 14.0

 # ----
 # 角度の初期設定
 gradXD = round(4.09*vpi/180,2) + diff_gradX
 gradYD = 0 + diff_gradY
 gradZD = round((90.0+diff_gradZ)*vpi/180,2)

 # add new cameras  
 bpy.ops.object.camera_add(location=(posXD, posYD, posZD), rotation=(gradXD, gradYD, gradZD))
 bpy.context.object.data.name="camera_down"

 # ----
 # パラメタ引き渡し用のベクトル(L,C,R)
 arr_cameraL = [ posXL, posYL, posZL, gradXL, gradYL, gradZL ]
 arr_cameraC = [ posXC, posYC, posZC, gradXC, gradYC, gradZC ]
 arr_cameraR = [ posXR, posYR, posZR, gradXR, gradYR, gradZR ]
 arr_cameraU = [ posXU, posYU, posZU, gradXU, gradYU, gradZU ]
 arr_cameraD = [ posXD, posYD, posZD, gradXD, gradYD, gradZD ]

 return arr_cameraL, arr_cameraC, arr_cameraR, arr_cameraU, arr_cameraD

# ----------
# ライトのみを選んで削除し、再設置する
def reset_lights(obj_cnt):

 # ----
 # 位置の初期設定
 posXL = 4
 posYL = -0.2
 posZL = 6.0
 posXR = -4
 posYR = 0.2
 posZR = 6.0
 
 # ----
 # 角度の初期設定
 gradXL = 0.8*vpi/180
 gradYL = 32*vpi/180
 gradZL = 0
 gradXR = -0.8*vpi/180
 gradYR = -32*vpi/180
 gradZR = 0

 # remove existing light   
 bpy.ops.object.select_by_type(type='LIGHT')
 bpy.ops.object.delete()

 # locate area light
 # LEFT
 bpy.ops.object.light_add(type='AREA', location=(posXL, posYL, posZL), rotation=(gradXL, gradYL, gradZL))
 bpy.context.object.data.energy = 350 + random.random()*50
 bpy.context.object.data.name="light_left"
 bpy.context.object.data.shape = 'RECTANGLE'
 bpy.context.object.data.size = 1
 bpy.context.object.data.size_y = 10
 # RIGHT
 bpy.ops.object.light_add(type='AREA', location=(posXR, posYR, posZR), rotation=(gradXR, gradYR, gradZR))
 bpy.context.object.data.energy = 350 + random.random()*50
 bpy.context.object.data.name="light_right"
 bpy.context.object.data.shape = 'RECTANGLE'
 bpy.context.object.data.size = 1
 bpy.context.object.data.size_y = 10

 # パラメタ引き渡し用のベクトル
 arr_lightL = [ posXL, posYL, posZL, gradXL, gradYL, gradZL ]
 arr_lightR = [ posXR, posYR, posZR, gradXR, gradYR, gradZR ]

 return arr_lightL, arr_lightR

# ----------
# リストの初期化
mx_temp   = []

# ----------
# Sceneを指示
scene   = bpy.context.scene

# file count
file_cnt = 0

# Camera shot
for obj_cnt in range(5):

 # ----
 # カメラのみを選んで削除し、再設置する
 arr_cameraL, arr_cameraC, arr_cameraR, arr_cameraU, arr_cameraD = reset_cameras(obj_cnt)

 # パラメタ引き渡し用のベクトル
 posX = arr_cameraC[0] 
 posY = arr_cameraC[1] 
 posZ = arr_cameraC[2] 
 gradX = arr_cameraC[3] 
 gradY = arr_cameraC[4] 
 gradZ = arr_cameraC[5] 

 # ライトのみを選んで削除し、再設置する
 arr_lightL, arr_lightR = reset_lights(obj_cnt)

 # ----
 cam_cnt = 0
 # 画像の撮影
 for ob in scene.objects:
  print( ob.name )
  if ob.type == 'CAMERA':
   bpy.context.scene.camera = ob
   #print('Set camera %s' % ob.name )
   # ----
   degX = int(gradX*180/vpi)
   degY = int(gradY*180/vpi)
   degZ = int(gradZ*180/vpi)
   # ----
   # 撮影とファイル保存
   name_cam = "cam-era{0}_{1}_{2}_{3}_{4}_{5}_{6}_{7}_square".format(file_cnt,cam_cnt,degX,degY,degZ,posX,posY,num_label)
   name_cam = name_cam.replace('0.', '0')
   name_cam = name_cam.replace('-', 'm')
   print("filename_camera:{0}".format(name_cam))
   filename_pics = ". /camera_test/{0}".format(name_cam)
   bpy.context.scene.render.filepath = filename_pics
   bpy.ops.render.render( write_still=True )
   # リストに追加する
   mx_temp.append([name_cam, cam_cnt, num_label])
   cam_cnt  = cam_cnt + 1
   file_cnt = file_cnt + 1

# ----
# データフレームへの出力
df = pd.DataFrame(data=mx_temp, columns=['file_name', 'camNO', 'label',])
print(df)

# ----
# CSVファイルへの出力
name_csv = "labels{0}_square.csv".format(num_label)
print("filename_label:{0}".format(name_csv))
filename_csv = "./camera_test/{0}".format(name_csv)
df.to_csv(filename_csv)

```

QEU:FOUNDER ： “そして、こういう結果がボロボロと出てくるわけです。”

![imageRL1-2-10](https://yaber1965.github.io/images/imageRL1-2-10.jpg)

D先生 ： “あれ？そういえば、ファイブ・アイズをまだ使っていますね。”

QEU:FOUNDER ： “画像の平均化をするのに楽だからね。それだけです。”

## ～　まとめ　～

C部長 : “ちょっと、ひっかかるんだけど・・・。”

![imageRL1-2-11](https://yaber1965.github.io/images/imageRL1-2-11.jpg)

QEU:FOUNDER ： “いろいろと、ドラマがあるが・・・。”

<iframe width="560" height="315" src="https://www.youtube.com/embed/deHDXw3KNTg" ti-tle="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; en-crypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

C部長 : “ずいぶん、古いモノを引っ張ってきますね・・・。現在に通じるネタもありますが・・・。”

![imageRL1-2-12](https://yaber1965.github.io/images/imageRL1-2-12.jpg)

QEU:FOUNDER ： “あの件、どうなるのかなァ・・・。なにはともあれ、よく頑張りました。”


