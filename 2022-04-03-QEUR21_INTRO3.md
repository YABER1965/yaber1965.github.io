## QEUR21_INTRO3:　NN’erのためのTM（その3）～簡単なディープラーニング学習

### ～　NN’erの便利ツールになってもらいたい　～

QEU:FOUNDER ： “ディープラーニングは、この方（↓）のコードを参考にして作りましょう。結局は、コードがかなり変わったけど・・・(笑)。”

![image1-3-1](https://yaber1965.github.io/images/image1-3-1.jpg)

D先生 ： “まぁ・・・、行くべき方向は見えてますし、もうすっ飛ばしてプログラムに行きません？

QEU:FOUNDER ： “じゃあ・・・(笑)、D先生のお言葉に甘えてプログラムをドン！！”


```python
# ---------------
# NNアーキテクチャの最適化実験
# nn_opt_archi_learn_single.py
# データのDL学習(data pre-process)の第一段階です
# Kerasを使って、Dataset一つだけの学習を行います
# ---------------
# import libraries
import math
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# --------------
# Import `Sequential` from `keras.models`
from keras.models import Sequential 
# Import `Dense` from `keras.layers`
from keras.layers import Dense

# ---------------------------
# フォルダ指定
folder_input    = "./"  # My project folder
folder_csvout   = "./"  # My project folder

# ---------------------------
# 機械学習用のCSVファイルを定義する
nam_csv_input = "機械学習のCSVデータ" 
code_csv_input = "train_wineq_train1.csv" # CSVコードの指定
file_csv_input = folder_csvout + code_csv_input  # ファイルパス名の生成
print("------------ 計測データ出力用のCSV名 -------------")   
print("ゲームプレイリストのCSVファイル名 ：{0}".format(file_csv_input))

# loading the data
Dataframe = pd.read_csv(file_csv_input)

# show rows and columns
#Dataframe.head()

# getting info.
#Dataframe.info()
#Dataframe.describe()

# --------------
# レコードを学習・検証用と最終評価用に分ける
# 学習(training) -> 1
# 検証(validation) -> 2
# 評価(test) -> 3
# --------------
# トレーニング用のデータセット
df_train    = Dataframe[Dataframe['attr2']==1]
#print(df_train)

num_df_train = len(df_train)
print('num_df_train:',num_df_train)

mx_Xs_train = df_train.loc[:,"type":"alcohol"].values
#print(mx_Xs_train)
arr_Y_train = df_train.loc[:,"quality"].values
#print(arr_Y_train)

# --------------
# 検証用のデータセット
df_vali    = Dataframe[Dataframe['attr2']==2]
#print(df_vali)

num_df_vali = len(df_vali)
print('num_df_vali:',num_df_vali)

mx_Xs_vali = df_vali.loc[:,"type":"alcohol"].values
#print(mx_Xs_vali)
arr_Y_vali = df_vali.loc[:,"quality"].values
#print(arr_Y_vali)

# --------------
# 評価用のデータセット
df_test    = Dataframe[Dataframe['attr2']==3]
#print(df_test)

num_df_test = len(df_test)
print('num_df_test:',num_df_test)

mx_Xs_test = df_test.loc[:,"type":"alcohol"].values
#print(mx_Xs_test)
arr_Y_test = df_test.loc[:,"quality"].values
#print(arr_Y_test)

# --------------
# Initialize the constructor
model = Sequential()
 
# Add an input layer
model.add(Dense(128, activation ='relu', input_shape =(12, )))
# Add one hidden layer
model.add(Dense(128, activation ='relu'))
# Add an output layer
model.add(Dense(1))

# Model output shape
model.output_shape
 
# Model summary
model.summary()
 
# Model config
model.get_config()

# --------------
# 履歴出力用の関数を設定する
def plot_history(history):
    hist = pd.DataFrame(history.history)
    hist['epoch'] = history.epoch

    # ----
    arr_epoch       = hist['epoch']
    arr_train_mae   = hist['mae']
    arr_val_mae     = hist['val_mae']
    arr_train_mse   = hist['mse']
    arr_val_mse     = hist['val_mse']

    # ----    
    fig = plt.figure(figsize=(12,6))
    ax1 = fig.add_subplot(1,2,1)
    ax1.plot(arr_epoch, arr_train_mae, label='Train Error')
    ax1.plot(arr_epoch, arr_val_mae, label = 'Val Error')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Mean Abs Error')
    ax1.legend()

    # ----    
    ax2 = fig.add_subplot(1,2,2)
    ax2.plot(arr_epoch, arr_train_mse, label='Train Error')
    ax2.plot(arr_epoch, arr_val_mse, label = 'Val Error')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Mean Square Error')
    ax2.legend()
    fig.tight_layout()
    plt.show()

    return arr_epoch, arr_train_mse, arr_val_mse 

# --------------
# トレーニング用のデータセット
#mx_Xs_train = df_train.loc[:,"type":"alcohol"]
#arr_Y_train = df_train.loc[:,"quality"]
# --------------
# 検証用のデータセット
#mx_Xs_vali = df_vali.loc[:,"type":"alcohol"]
#arr_Y_vali = df_vali.loc[:,"quality"]
# --------------
# List all weight tensors
model.get_weights()
model.compile(loss ='mse',
    optimizer ='adam', metrics=['mae', 'mse'])

# Training Model
history = model.fit(mx_Xs_train, arr_Y_train, validation_data=(mx_Xs_vali, arr_Y_vali),
            epochs = 50, batch_size = 1, verbose = 1)
  
# Predicting the Value
y_pred = model.predict(mx_Xs_test)
print(y_pred)

# 学習履歴を出力する
arr_epoch, arr_train_mse, arr_val_mse = plot_history(history)
print("arr_epoch:", round(arr_epoch[19],4))
print("arr_train_mse:", round(arr_train_mse[19],4))
print("arr_val_mse:", round(arr_val_mse[19],4))

# 予測精度を確認する
fig2 = plt.figure(figsize=(8,5))

# 散布図の作画
ax3 = fig2.add_subplot(1,1,1)
ax3.scatter(y_pred, arr_Y_test, color="blue", label="reward")
ax3.set_title('accuracy between pred and actual', fontsize=16)
ax3.set_xlabel('Prediction')
ax3.set_ylabel('Actual')
ax3.set_xlim(left=2, right=9)  # x範囲
ax3.set_ylim(bottom=2, top=9)  # y範囲
ax3.legend(loc='upper left', fontsize=10)
fig2.tight_layout()
plt.show()

# --------------
# SN比を計算する
def calc_snr(y_pred, y_actual):
    
    num_yy  = len(y_pred)
    arr_xx  = np.zeros(num_yy)
    arr_xy  = np.zeros(num_yy)
    res_yy  = np.zeros(num_yy)
    
    for i in range(num_yy):
        arr_xx[i]  = y_pred[i] * y_pred[i]
        arr_xy[i]  = y_pred[i] * y_actual[i]
    # ----
    # 感度を計算する
    val_beta    = np.sum(arr_xy)/np.sum(arr_xx)

    for i in range(num_yy):
        res_yy[i]  = (y_actual[i] - val_beta * y_pred[i])**2
    val_msd     = np.sum(res_yy)

    # ----
    # SN比を計算する
    val_snr     = val_beta**2 / val_msd

    # ----
    # 対数化
    log_beta    = math.log10(val_beta)
    log_snr     = math.log10(val_snr)

    return round(log_beta,4), round(log_snr,4) 

# 感度とSN比を計算する
log_beta, log_snr = calc_snr(y_pred.flatten(), arr_Y_test)
print("log_beta:{}, log_snr:{}".format(log_beta, log_snr))

```

QEU:FOUNDER ： “レイヤのノード数を64にしたときのデータをみてみましょう・・・。”

（学習曲線）

![image1-3-2](https://yaber1965.github.io/images/image1-3-2.jpg)

（予測と実際の比較）

![image1-3-3](https://yaber1965.github.io/images/image1-3-3.jpg)

QEU:FOUNDER ： “これからメトリックを計算していこうと思います・・・。”

![image1-3-4](https://yaber1965.github.io/images/image1-3-4.jpg)

D先生 ： “epoch数が20（配列では19）のデータを取った意味が分かりにくいです。”

QEU:FOUNDER ： “学習誤差(mse)がある程度安定したところを狙ってサンプリングしたわけです。実は10エポックでもよかったけど・・・。そして、このデータが準備された５つの学習データセットで計算されて望小SN比が計算されるわけです。”

![image1-3-5](https://yaber1965.github.io/images/image1-3-5.jpg)

D先生 ： “なるほど・・・。”

QEU:FOUNDER ： “あとは、楽にするためにプログラムを改造して「バッチ処理」して答えを出してしまいましょう。”


## ～　まとめ　～

### ・・・　前回のつづきです。最近はC部長が「聞き手」になっていますネ　・・・

C部長 : “FOUNDERは、断固としてトラディショナル（伝統的）なタグチメソッドを使わないんですねえ・・・。ちょっと、「もったいない」ような・・・。”

![image1-3-6](https://yaber1965.github.io/images/image1-3-6.jpg)

QEU:FOUNDER ： “、QEUシステムがいまのところ、タグチメソッドの多くの手法を使わないのは「ある前提」のもとです。NNが提供する多次元多変量近似のソルーションが「技術者にとって満足できる」かどうか・・・。”

<iframe width="560" height="315" src="https://www.youtube.com/embed/wTA4sK_X8To" ti-tle="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; en-crypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

QEU:FOUNDER ： “「一石全鳥」というキャッチフレーズは、タグチメソッドが多次元多変量プロセスの最適化ソルーションであることが背景にあります。もちろん、そんなスゴイ成果が出るケースは多くはないが・・・。NN（ニューラルネット）は、その技術の本質が多次元多変量近似記述なので、このNNを使えばもっと簡単に最適化できるのではないかと思っているわけです。”

C部長 : “そういう意味では、FOUNDERにもタグチメソッドに対する魅力は残っている(・・ってこと)？”

![image1-3-7](https://yaber1965.github.io/images/image1-3-7.jpg)

QEU:FOUNDER ： “結論として、小生がタグチメソッドの本の中で薦める本は宮川先生の本だよね！学者ならではの慎重さと矜持が合わさった文章と論理展開がたまらないネ。まあ、タグチ本の話はここまでにしましょう。”
