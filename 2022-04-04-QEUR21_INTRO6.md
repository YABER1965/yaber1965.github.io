# QEUR21_INTRO6:　NN’erのためのTM（その6）～交互作用を検出する

## ～　予測精度アップの決めて！　～

### ・・・　赤ワインのデータセットだけの分析になりますが、すこしだけ進歩が生まれます　・・・

D先生 ： “さぁて・・・。交互作用の検出作業に入りましょうか・・・。どのモジュールを使います？R言語を使うことになるのでしょうか？“

![image1-6-1](https://yaber1965.github.io/images/image1-6-1.jpg)

QEU:FOUNDER ： “いまだったら、PythonでもR言語と同じような本格的な統計分析ができます。「statmodels」といって・・・、GLMや重回帰分析ができます。もっとも、多項式回帰分析まではできないですが・・・。”

![image1-6-2](https://yaber1965.github.io/images/image1-6-2.jpg)

D先生 ： “あれ？コレ（↑）・・・、面白いまとめ方をしていますね。「モデル化」と「予測」って、どんな意味ですか？ “

![image1-6-3](https://yaber1965.github.io/images/image1-6-3.jpg)

QEU:FOUNDER ： “つまり、システムの構造として「シンプル化を目指している」か、「複雑化を目指している」かですよね。今回のデータセットには説明変量（因子）が11個あります。それらの項目を極力削って単純化したいか、なるべく多く使って精度アップしたいのか・・・。よくよく考えてみれば、現場からすると（計測）データは必要だからとっているんですよね・・・。本来ならば、不要なデータはないはずです。”

D先生 ： “非線形とか交互作用が原因で回帰できないから、消してしまうんですよね・・・。線形回帰の場合・・・。“

QEU:FOUNDER ： “・・まあいいや・・・。これからR（言語）じゃなく「Python（言語）で」統計分析をしましょう。途中はガチャガチャやっていますが、最後には交互作用の因子が検出されています。それではプログラムをドン！！”


```python
# ---------------
# NNアーキテクチャの最適化実験
# nn_opt_factor_analysis_interaction.py
# データ因子の構造分析(factor analysis)の第一段階です
# 交互作用確認のためにグラフに出力します
# ---------------
# import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sb
import statsmodels.formula.api as smf
%matplotlib inline

# ---------------------------
# フォルダ指定
folder_input    = "./"  # My project folder

# ---------------------------
# 機械学習用のCSVファイルを定義する
nam_csv_input    = "機械学習のCSVデータ" 
nam_code_input   = "train_wineq_train1.csv" # CSVコードの指定
file_csv_input = folder_input + nam_code_input  # ファイルパス名の生成 
print("入力用CSVファイル名 ：{0}".format(file_csv_input))

# loading the data
Dataframe = pd.read_csv(file_csv_input)
df = Dataframe.loc[:,"fixed acidity":"quality"]

# show rows and columns
df.head()

# getting info.
df.info()
# ---
df.describe()

# plot pairplot
plt.figure(figsize=[10,6])
sb.pairplot(df)
#show graph
plt.show()

# correlation by visualization
plt.figure(figsize=[14,7])
# plot correlation
sb.heatmap(df.corr(), annot=True)
plt.show()


#---------------------
# 交互作用を生成するプログラム
df2 = df.copy()
df2.columns = ['item1','item2','item3','item4','item5','item6','item7','item8','item9','item10','item11','quality']
print(df2)

#---------------------
# 初期分析
model = smf.ols(formula='quality ~ item1+item2+item3+item4+item5+item6+item7+item8+item9+item10+item11', data=df2).fit()
summary = model.summary()
print(summary)

#---------------------
# 詳細分析(1) : item3の交互作用
model = smf.ols(formula='quality ~ item1+item2+item4+item6+item7+item8+item9+item10+item11+item3*item1+item3*item2+item3*item4+item3*item6+item3*item7+item3*item8+item3*item9+item3*item10+item3*item11', da-ta=df2).fit()
summary = model.summary()
print(summary)

#---------------------
# 詳細分析(2) : item5の交互作用
model = smf.ols(formula='quality ~ item1+item2+item4+item6+item7+item8+item9+item10+item11+item5*item1+item5*item2+item5*item4+item5*item6+item5*item7+item5*item8+item5*item9+item5*item10+item5*item11', da-ta=df2).fit()
summary = model.summary()
print(summary)

#---------------------
# 詳細分析(3) : item3とitem5の交互作用を加味する
model = smf.ols(formula='quality ~ item1+item2+item4+item6+item7+item8+item9+item10+item11+item3*item10+item5*item1+item5*item4+item5*item7+item5*item8+item5*item9+item5*item10', data=df2).fit()
summary = model.summary()
print(summary)

#---------------------
# まとめ(主効果と交互作用)
model = smf.ols(formula='quality ~ item1+item2+item4+item6+item8+item9+item10+item11+item3:item10+item5:item7+item5:item8+item5:item9+item5:item10', data=df2).fit()
summary = model.summary()
print(summary)

#---------------------
# 交互作用をグラフ化する
#item3:item10    -0.4732      0.140     -3.369      0.001      -0.749      -0.198
df2['item3_med'] = df2.item3 > df2.item3.median()
df2['item3_med'] = np.where(df2.item3 == False, "Below Median", "Above Median")
sb.lmplot(x='item10', y='quality', hue='item3_med', data=df2, ci=None, height=7, aspect=2.5);
plt.show()

#---------------------
# 交互作用をグラフ化する
#item5:item7     -0.0411      0.004    -10.944      0.000      -0.048      -0.034
#item5:item8     48.9807      7.258      6.748      0.000      34.752      63.209
#item5:item9    -12.8919      2.140     -6.025      0.000     -17.087      -8.697
#item5:item10    -6.2553      0.880     -7.107      0.000      -7.981      -4.530
df2['item5_med'] = df2.item5 > df2.item5.median()
df2['item5_med'] = np.where(df2.item5_med == False, "Below Median", "Above Median")
#print(df2.item5.median())
#print(df2.item5_med)
sb.lmplot(x='item7', y='quality', hue='item5_med', data=df2, ci=None, height=7, aspect=2.5);
#sb.lmplot(x='item8', y='quality', hue='item5_med', data=df2, ci=None, height=7, aspect=2.5);
#sb.lmplot(x='item9', y='quality', hue='item5_med', data=df2, ci=None, height=7, aspect=2.5);
#sb.lmplot(x='item10', y='quality', hue='item5_med', data=df2, ci=None, height=7, aspect=2.5);
#plt.show()

```

D先生 ： “コードの中に解析結果が出ていますね、これはありがたい・・・。これによると交互作用の因子はitem3とitem5になるわけです。・・・それにしても、item5はずいぶん多くの因子に影響を与えますね。“

QEU:FOUNDER ： “逆にいうと、これだけ多くの交互作用があれば回帰分析しても予測精度が上がらないわけですよ。まずはitem3の交互作用グラフを見てみましょう。”

![image1-6-4](https://yaber1965.github.io/images/image1-6-4.jpg)

D先生 ： “なるほど・・・。あきらかに交互作用が見えますね。“

QEU:FOUNDER ： “つぎにitem5の交互作用図をドン！！”

## (item7-8)

![image1-6-5](https://yaber1965.github.io/images/image1-6-5.jpg)

## (item9-10)

![image1-6-6](https://yaber1965.github.io/images/image1-6-6.jpg)

D先生 ： “item10は交互作用は統計上有意なのでしょうが、その量が少なすぎですね。無視してもいいんじゃないでしょうか、主効果の差異しか見えません。・・・なにはともあれ、解析によりデータセットに埋もれていた交互作用がみえてきました。 “

QEU:FOUNDER ： “これを使うと、以下のようにプロセスの構造を設定できますね。”

## **出力(Y) = f(XAs:ロバスト因子群、XBｓ：交互作用因子群、XCs:回帰因子群)**

D先生 ： “オリジナルの因子名があります。わからないことはないのでOKですが・・・。”

QEU:FOUNDER ： “ここで、ロバスト因子はitem3と5になります。”

D先生 ： “となると・・・、交互作用因子はitem7,8,9,10になります。なぜ誤差因子っていわないんですか？”

QEU:FOUNDER ： “今回の場合、パラメタ設計のように出荷後の品質をロバストにする目的はないからねえ・・・。でもItem3と5は、ほかに適当な言い方がないのでロバスト因子という言い方になりました。ここまでくると以下のように外側構造と内側構造が形成されます。”

## （内側構造）　～　（外側構造）

### ロバスト因子（item3,5）　～　g( [ XCs:回帰因子群] x [XBｓ：交互作用因子群] )

D先生 ： “この次は再びディープラーニングによる学習になります。面白くなりそうですね。”

QEU:FOUNDER ： “本当は違う展開をしたいんだが、D先生たってのリクエストなんでどうしましょうかねぇ・・・。”

## ～　まとめ　～

C部長 : “また面白い動画が出ていました。”

<iframe width="560" height="315" src="https://www.youtube.com/embed/SzrklyMkQUM" ti-tle="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; en-crypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

QEU:FOUNDER ： “この前の続きだね・・・。”

<iframe width="560" height="315" src="https://www.youtube.com/embed/SKX9H8FIqbc" ti-tle="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; en-crypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

D先生 ： “こういう視点が大切ですよね。技術開発のために、もっと金をつければいいのに・・・。ちなみに、このロボットを紹介しようとしたんですね。”

![image1-6-7](https://yaber1965.github.io/images/image1-6-7.jpg)

C部長 : “驚いた。本当に人の隣にロボットがいる・・・。”

QEU:FOUNDER ： “Collaborative Robot・・・。これはIndustry5.0のトレンドですね。人の隣でロボットが働くことは、2016年にISOになっています。”

![image1-6-8](https://yaber1965.github.io/images/image1-6-8.jpg)

C部長 : “意外と、最近になって標準化されたんですね。”

D先生 ： “これが標準化されるのは地味にすごいことですね。コレ(↑)、あとでもう少し突っ込みたいなぁ・・・。”

QEU:FOUNDER ： “J国はロボットの面ですでに世界から遅れてきているんじゃないでしょうか・・・。”


