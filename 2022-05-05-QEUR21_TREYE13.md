## QEUR21_TREYE13:　予備実験～片目法（その3）

## ～　これだけ凄ければ「MT法でも？」・・・、と言えるわね（笑）　～

QEU:FOUNDER ： “さあて、これが実質上のクライマックスになります。「マハラノビス距離によるFeature Engineeringによって、どのような**特徴量マップ**が得られるか」です・・・。”

D先生 ： “何も言うことはないんで、これからプログラムの紹介にはいりましょう。相関逆行列はCSVファイルから読み込むんですか？”

```python
# ---------------------------
# CSVファイルに学習結果を出力する
#=================================================
# OUT CSV FUNCTION(1)
#=================================================
# CSVファイルに出力する(相関逆行列)
def save_invcorr(mx_result): 

    # ---------------------------
    # データフレームを作成
    arr_index = list(range(12))
    arr_columns = list(range(12))
    df_metrics = pd.DataFrame(mx_result, index=arr_index, columns=arr_columns)

    # ---------------------------
    print("------------ 相関逆行列のデータフレーム -------------")  
    print(df_metrics) 
    # CSV ファイル (distance.csv) として出力
    file_csvout = foldername + "RTm_invcorr.csv" # ファイルパス名の生成
    df_metrics.to_csv(file_csvout)
    print("CSVファイルの出力完了 : {}".format(file_csvout)) 
    
    return df_metrics

# ---------------------------
# CSVファイルに出力する(相関逆行列)
# ---------------------------
save_invcorr(cov_i)

#=================================================
# OUT CSV FUNCTION(2)
#=================================================
# CSVファイルに出力する(単位空間の中心)
def save_taniXs(mx_result): 

    # ---------------------------
    # データフレームを作成
    arr_columns = list(range(12))
    df_metrics = pd.DataFrame(mx_result, columns=arr_columns)

    # ---------------------------
    print("------------ 単位空間の中心のデータフレーム -------------")  
    print(df_metrics) 
    # CSV ファイル (distance.csv) として出力
    file_csvout = foldername + "RTm_taniXs.csv" # ファイルパス名の生成
    df_metrics.to_csv(file_csvout)
    print("CSVファイルの出力完了 : {}".format(file_csvout)) 
    
    return df_metrics

# ---------------------------
# CSVファイルに出力する(単位空間の中心)
# ---------------------------
save_taniXs([arr_Xs_tani])

```

QEU:FOUNDER ： “それがいいと思います。前回のプログラムにCSV出力の命令を加えれば、指定されたフォルダに学習データが出力されます。そして、今回の検査用のプログラムではそれを読み込みます。それでは、プログラムをドン！！”

```python
# ------------------
# 畳み込みRT法の予備実験
# testNO3_inspection_featuremap.py
# モジュールのインポート
import cv2
from fastai.vision.all import *
import seaborn as sns
import pandas as pd
import numpy as np
from scipy.spatial import distance
import matplotlib.pyplot as plt

#=================================================
# CHOSE PIC 
#=================================================
# 読み込み先（フォルダと画像）
foldername = "./ARRAY_RTCNN/"
#pic_name = "camera0_0_0_89_0_0_0.png"   # 正常
#pic_name = "camera0_0_0_89_0_0_1_X10.png"   # PINNO3-1端子抜け
pic_name = "camera0_0_0_89_0_0_2_Y10.png"   # PINNO4-1端子抜け
filename = foldername + pic_name

#=================================================
# READ CSV_FILE FUNCTION
#=================================================
# ファイルを読み込み表示する(相関逆行列)
def read_invcorr(file_readcsv): 
 
    # 画像異常検出ファイルの読み込み
    df = pd.read_csv(file_readcsv) 
    #print(df)
    # ------------------
    # 選択項目の読み込み
    # Xsマトリックス
    mx_Xs = df.loc[:,"0":"11"].values
    #print("----- mx_Xs -----")
    #print(mx_Xs)
  
    return mx_Xs

# ------------------
# ファイルを読み込み表示する(相関逆行列)
file_cnv_input = foldername + "RTm_invcorr.csv"  # ファイルパス名の生成 
cov_i = read_invcorr(file_cnv_input)
print(cov_i)
   
# ------------------
# ファイルを読み込み表示する(単位空間の中心)
def read_taniXs(file_readcsv): 
 
    # 画像異常検出ファイルの読み込み
    df = pd.read_csv(file_readcsv) 
    #print(df)
    # ------------------
    # 選択項目の読み込み
    # Xsマトリックス
    mx_Xs = df.loc[:,"0":"11"].values
    #print("----- mx_Xs -----")
    #print(mx_Xs)
  
    return mx_Xs.flatten()

# ------------------
# ファイルを読み込み表示する(単位空間の中心)
file_cnv_input = foldername + "RTm_taniXs.csv"  # ファイルパス名の生成 
arr_Xs_tani = read_taniXs(file_cnv_input)
print(arr_Xs_tani)

# ------------------
# 実験パターンファイルを読み込み表示する
def read_csvfile(file_readcsv, max_idx, max_col): 
 
    # 画像異常検出ファイルの読み込み
    df = pd.read_csv(file_readcsv) 
    #print(df)
    # ------------------
    # 選択項目の読み込み
    # Xsマトリックス
    mx_Xs = df.loc[:,"col1":"col10"].values
    #print("----- mx_Xs -----")
    #print(mx_Xs)
  
    return mx_Xs
    
# ------------------
# パラメタの設定
max_cnv_parts  = 8
# 画像サンプルのサイズ
max_sp_idx     = 150
max_sp_col     = 450
# 畳み込み部品のサイズ
max_cnv_idx    = 10
max_cnv_col    = 10
# スキップ量
skip_cnv_idx   = 10
skip_cnv_col   = 10

# ------------------
nam_cnv_input = "基準用CSVデータ" 
code_cnv_input = ["NA"] * 8 # CSVコードの指定
code_cnv_input[0] = "bend1_cnv" # CSVコードの指定
code_cnv_input[1] = "bend2_cnv" # CSVコードの指定
code_cnv_input[2] = "bend3_cnv" # CSVコードの指定
code_cnv_input[3] = "bend4_cnv" # CSVコードの指定
code_cnv_input[4] = "line1_cnv" # CSVコードの指定
code_cnv_input[5] = "line2_cnv" # CSVコードの指定
code_cnv_input[6] = "datum1_cnv" # CSVコードの指定
code_cnv_input[7] = "datum2_cnv" # CSVコードの指定
print("---- 入力:畳み込み用CSVファイル名 ----")
print(code_cnv_input)
print("-------------------------------")

# ------------------
# 畳み込み処理を実施する
for i in range(max_cnv_parts):

    # ---------------------------
    # CSVファイル(実験)情報を読み込み表示する
    # 畳み込みファイル
    file_cnv_input = foldername + code_cnv_input[i] + ".csv"  # ファイルパス名の生成 
    mx_conv = read_csvfile(file_cnv_input, max_cnv_idx, max_cnv_col)
    if i == 0:    
        tensor_bend1 = tensor(mx_conv).float()
    elif i == 1:
        tensor_bend2 = tensor(mx_conv).float()
    elif i == 2:
        tensor_bend3 = tensor(mx_conv).float()
    elif i == 3:
        tensor_bend4 = tensor(mx_conv).float()
    elif i == 4:
        tensor_line1 = tensor(mx_conv).float()
    elif i == 5:
        tensor_line2 = tensor(mx_conv).float()
    elif i == 6:
        tensor_datum1 = tensor(mx_conv).float()
    elif i == 7:
        tensor_datum2 = tensor(mx_conv).float()
# ---------------------------
# カーネルの生成  
signal_kernels = torch.stack([tensor_bend1, tensor_bend2, tensor_bend3, tensor_bend4, tensor_line1, tensor_line2])
tani_kernel = (tensor_datum1 + tensor_datum2)*0.5
# 結果の出力
print(signal_kernels.shape)
print("----- signal_kernels -----")
print(signal_kernels)
print("----- tani_kernel -----")
print(tani_kernel)

#=================================================
# PIC -> TENSOR　PROGRAM
#=================================================
# 画像を読み込む
img = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)
img_crop = img[212:856,47:1867]

# リサイズ
newsize = (450, 150)
img_resize = cv2.resize(img_crop , newsize)
# 画像出力
#cv2.imshow("resized_image", img_resize)
#print(img_resize.shape)
#cv2.waitKey(0)
#cv2.destroyAllWindows()

# ------------------
# 画像データのテンソル化
img_tensor = tensor(img_resize/255)
print(img_tensor)

#=================================================
# MAIN PROGRAM(1) : CALC CONVOLUTION PARTS
#=================================================
# 画像の処理(for)開始点のベクトルを生成
idx_range = []
sum_idx   = 0
while sum_idx <= max_sp_idx-max_cnv_idx:
    idx_range.append(sum_idx)
    sum_idx  += skip_cnv_idx
print(idx_range)

# -----
col_range = []
sum_col   = 0
while sum_col <= max_sp_col-max_cnv_col:
    col_range.append(sum_col)
    sum_col  += skip_cnv_col
print(col_range)

# ---------------------------
# 畳み込み処理を実施する
# 関数の定義
def apply_kernel(row, col, kernel):
    return (img_tensor[row:row+max_cnv_idx,col:col+max_cnv_col] * kernel).sum()

# ---------------------------
# 単位空間用の畳み込み処理を実施する
kernel = tani_kernel
tani_timage = tensor([[apply_kernel(i,j,kernel) for j in col_range] for i in idx_range])

# ------------------
# 信号空間用の畳み込み処理を実施する
for i in range(6):

    # ---------------------------
    # CSVファイル(実験)情報を読み込み表示する
    kernel = signal_kernels[i]
    calc_conv = tensor([[apply_kernel(i,j,kernel) for j in col_range] for i in idx_range])
    # 結果の出力
    #print(calc_conv.shape)
    #print("----- calc_conv -----")
    #print(calc_conv)

    if i == 0:    
        tsr_cvbend1 = tensor(calc_conv).float()
    elif i == 1:
        tsr_cvbend2 = tensor(calc_conv).float()
    elif i == 2:
        tsr_cvbend3 = tensor(calc_conv).float()
    elif i == 3:
        tsr_cvbend4 = tensor(calc_conv).float()
    elif i == 4:
        tsr_cvline1 = tensor(calc_conv).float()
    elif i == 5:
        tsr_cvline2 = tensor(calc_conv).float()
# ---------------------------
# 畳み込みテンソルイメージの生成  
signal_timages = torch.stack([tsr_cvbend1, tsr_cvbend2, tsr_cvbend3, tsr_cvbend4, tsr_cvline1, tsr_cvline2])
# 結果の出力
print(signal_timages.shape)
print("----- signal_timages[0] -----")
print(signal_timages[0])
print("----- tani_timage -----")
print(tani_timage)

#=================================================
# CALCULATION FUNCTIONS
#=================================================
# RTメトリックスを計算する(テンソル活用版)
def calc_RTmetrics(len_temp, max_jy_index, tsr_sig_matrix, tsr_tani_array): 

    # ---------------------------
    # 変数の初期化
    lnr_yarray, btY1_yarray = [], []
    st_yarray, sb_yarray, se_yarray, ve_yarray = [], [], [], []
    yita_yarray, Y2_yarray = [], []

    # 有効除数の計算
    yuko = torch.dot(tsr_tani_array, tsr_tani_array)
    #print(yuko)

    # 線形式の計算
    for i in range(len_temp):
        lnr_yitem  = torch.dot(tsr_sig_matrix[i], tsr_tani_array)
        btY1_yitem = lnr_yitem / yuko
        lnr_yarray.append(lnr_yitem.item())
        btY1_yarray.append(btY1_yitem.item())
    #print(lnr_yarray)
    #print(btY1_yarray)

    # 全変動ST及び各種中間指標SB,SE,VE,η
    for i in range(len_temp):
        sum_item  = torch.dot(tsr_sig_matrix[i], tsr_sig_matrix[i])
        st_yarray.append(sum_item.item())
        sb_yarray.append(lnr_yarray[i] ** 2 / yuko.item())
        se_yarray.append(st_yarray[i] - sb_yarray[i])
    #print(st_yarray)
    #print(sb_yarray)
    #print(se_yarray)

        # 異常処理
        temp_ve = se_yarray[i] / float(max_jy_index - 1.0)
        if temp_ve < 0.0001:
            comment = 'ゼロ異常発生！！'
            print(comment)
            ve_yarray.append(-1.0)   
            yita_yarray.append(-1.0)  
            Y2_yarray.append(-1.0) 
        else:
            temp_Y2 = math.sqrt(temp_ve)
            ve_yarray.append(temp_ve)   
            yita_yarray.append(1.0 / temp_ve)  
            Y2_yarray.append(temp_Y2) 
    #print(btY1_yarray)
    #print(Y2_yarray)

    return btY1_yarray, Y2_yarray

# ---------------------------
# テンソルイメージ処理のパラメタ
max_tsr_idx   = 15
max_tsr_col   = 45
# スキップ量
skip_tsr_idx  = 5
skip_tsr_col  = 5
# RT法処理のサイズ
rtm_tsr_idx   = 5
rtm_tsr_col   = 5
# RTベクトル長と信号空間長
max_jy_index  = 5*5
len_temp      = 6

# ---------------------------
# テンソル行列の処理(for)開始点のベクトルを生成
idx_range = []
sum_idx   = 0
while sum_idx <= max_tsr_idx-rtm_tsr_idx:
    idx_range.append(sum_idx)
    sum_idx  += skip_tsr_idx
#print(idx_range)
# -----
col_range = []
sum_col   = 0
while sum_col <= max_tsr_col-rtm_tsr_col:
    col_range.append(sum_col)
    sum_col  += skip_tsr_col
#print(col_range)

#=================================================
# MAIN PROGRAM(2) : MAX_POOLING
#=================================================
# RT法によるプーリング計算
arr_row = []
arr_col = []
mx_Y2_pool = np.zeros([3,9])
# ----
arr_btY1_p0 = []
arr_btY1_p1 = []
arr_btY1_p2 = []
arr_btY1_p3 = []
arr_btY1_p4 = []
arr_btY1_p5 = []
# ----
arr_Y2_p0 = []
arr_Y2_p1 = []
arr_Y2_p2 = []
arr_Y2_p3 = []
arr_Y2_p4 = []
arr_Y2_p5 = []
# ---
cnt_row = 0
for row in idx_range:
    cnt_col = 0
    for col in col_range:
    
        # ------
        # 単位空間の空間ベクトルを生成する
        tsr_tani_array = tani_timage[row:row+rtm_tsr_idx,col:col+rtm_tsr_col].flatten()
        print(tsr_tani_array)

        # ------
        # 信号空間の空間マトリックスを生成する
        temp_matrix = signal_timages[0]
        tsr_sig_p0 = temp_matrix[row:row+rtm_tsr_idx,col:col+rtm_tsr_col].flatten()
        temp_matrix = signal_timages[1]
        tsr_sig_p1 = temp_matrix[row:row+rtm_tsr_idx,col:col+rtm_tsr_col].flatten()
        temp_matrix = signal_timages[2]
        tsr_sig_p2 = temp_matrix[row:row+rtm_tsr_idx,col:col+rtm_tsr_col].flatten()
        temp_matrix = signal_timages[3]
        tsr_sig_p3 = temp_matrix[row:row+rtm_tsr_idx,col:col+rtm_tsr_col].flatten()
        temp_matrix = signal_timages[4]
        tsr_sig_p4 = temp_matrix[row:row+rtm_tsr_idx,col:col+rtm_tsr_col].flatten()
        temp_matrix = signal_timages[5]
        tsr_sig_p5 = temp_matrix[row:row+rtm_tsr_idx,col:col+rtm_tsr_col].flatten()
        # -----
        tsr_sig_matrix = torch.stack([tsr_sig_p0, tsr_sig_p1, tsr_sig_p2, tsr_sig_p3, tsr_sig_p4, tsr_sig_p5])
        #print("----- tsr_sig_matrix -----")
        #print(tsr_sig_matrix)
        # ------
        # RTメトリックスを計算する
        btY1_yarray, Y2_yarray = calc_RTmetrics(len_temp, max_jy_index, tsr_sig_matrix, tsr_tani_array)
        # ------
        # 信号空間の空間マトリックスを生成する
        mx_Y2_pool[cnt_row, cnt_col] = round(np.max(Y2_yarray),3)
        # ------
        # 各要素のベクトルを生成する
        arr_row.append(row)
        arr_col.append(col)
        # ---
        arr_btY1_p0.append(btY1_yarray[0])
        arr_btY1_p1.append(btY1_yarray[1])
        arr_btY1_p2.append(btY1_yarray[2])
        arr_btY1_p3.append(btY1_yarray[3])
        arr_btY1_p4.append(btY1_yarray[4])
        arr_btY1_p5.append(btY1_yarray[5])
        # ---
        arr_Y2_p0.append(Y2_yarray[0])
        arr_Y2_p1.append(Y2_yarray[1])
        arr_Y2_p2.append(Y2_yarray[2])
        arr_Y2_p3.append(Y2_yarray[3])
        arr_Y2_p4.append(Y2_yarray[4])
        arr_Y2_p5.append(Y2_yarray[5])
        # ------
        # COUNT UP
        print(cnt_row, cnt_col)
        cnt_col = cnt_col + 1
    # ------
    # COUNT UP
    cnt_row = cnt_row + 1

# ---------------------------
# 結果のテキスト出力する
#print(arr_row)
#print(arr_row)
#print(mx_Y2_pool)

# ---------------------------
# 結果をヒートマップに出力する(MAX_POOLING)
df = pd.DataFrame(mx_Y2_pool)
plt.figure(figsize=(14,6))
plt.title("max_pooling_{}".format(pic_name))
sns.heatmap(df, annot=True, cbar=True, cmap='Blues', fmt='.2f')
plt.show()

#=================================================
# MAIN PROGRAM(3) : MAHARANOBIS　FEATURE　ENGINEERING
#=================================================
# マハラノビスマトリックスとグラフ作画準備
max_iRow_cells = 12
max_jCol_cells = 3*9
mx_Xs_sig      = np.zeros([max_iRow_cells, max_jCol_cells])
# ------
mx_Xs_sig[0]  = arr_btY1_p0
mx_Xs_sig[1]  = arr_btY1_p1
mx_Xs_sig[2]  = arr_btY1_p2
mx_Xs_sig[3]  = arr_btY1_p3
mx_Xs_sig[4]  = arr_btY1_p4
mx_Xs_sig[5]  = arr_btY1_p5
mx_Xs_sig[6]  = arr_Y2_p0
mx_Xs_sig[7]  = arr_Y2_p1
mx_Xs_sig[8]  = arr_Y2_p2
mx_Xs_sig[9]  = arr_Y2_p3
mx_Xs_sig[10] = arr_Y2_p4
mx_Xs_sig[11] = arr_Y2_p5
#print(mx_Xs_sig.shape)

# ------------------
# 2つの標本 [X_tani, X_sig] と [(mean)arr_X_tani] のマハラノビス距離を計算する
arr_d = []
for jCol in range(max_jCol_cells):
    d = distance.mahalanobis(mx_Xs_sig[:,jCol], arr_Xs_tani, cov_i)
    if d > 100: d = 100
    arr_d.append(round(d,4))
    #print("jCol:{}, マハラノビス距離の計算結果:{}".format(jCol,d))
# ------
print(arr_d)
mx_MHdist = np.reshape(np.array(arr_d), (3, 9))
print("---- mx_MHdist ----")
print(mx_MHdist)

# ------------------
# マハラノビス距離のマトリックスを作画する(信号空間)
arr_index   = list(range(3))
arr_columns = list(range(9))
df_maha = pd.DataFrame(mx_MHdist, index=arr_index, columns=arr_columns)
#print("---- df_maha ----")
#print(df_maha)

# ------------------
# ヒートマップへ出力(信号空間)
fig = plt.figure(figsize=(12, 5))
ax = fig.add_subplot(1, 1, 1)
ax.set_title("Maharanobis Distance(SIGNAL)")
sns.heatmap(df_maha, ax=ax, annot=True, cbar=True, fmt='.2f')
plt.show()

```

QEU:FOUNDER ： “まずは念のために、端子抜けのない画像を入力し、特徴量マップを比較しましょう。”

![image3-33-1](https://yaber1965.github.io/images/image3-33-1.jpg)

D先生 ： “両者はほとんど同じです。小数点2桁目の数字に違いがみられますが・・・。”

QEU:FOUNDER ： “いちおうプログラムがOKであるとみなしましょう。それでは端子抜け不良が起こした画像について計算をしました。**「max_pooling」と「マハラノビス距離」の2種類の方法で比較**しています。”

![image3-33-2](https://yaber1965.github.io/images/image3-33-2.jpg)

D先生 ： “う～ん、（マハラノビス距離は）見事なパフォーマンスです。”

QEU:FOUNDER ： “あってよかったマハラノビス距離・・・（笑）。それでは、次の不良品の画像を入力してみましょう。”

![image3-33-3](https://yaber1965.github.io/images/image3-33-3.jpg)

D先生 ： “なぜ1本のピンだけを不良にしたのに2つのセルの特徴量がおかしくなったのかが不思議でしたが、いまその理由がわかりました・・・。”

QEU:FOUNDER ： “本来は１つのセル内で起こった不良なのに、2つのセルが異常になったのは端子が傾いていたからです。この傾きにより、２つのセルの画像がかわってしまったのです。”

D先生 ： “ここまで検出性能が良ければ、MT法で不良検出をできませんか・・・？”

QEU:FOUNDER ： “すべてのセルの合否閾値が同じであればね。でも、どうしても値がセル毎に変わっちゃうんですよね。そうすれば、SVM（サポートベクトルマシン）で学習したほうが簡単になっちゃう・・・。”

D先生 ： “じゃあ、次はSVMによる学習に行きましょう。”

## ～　まとめ　～

D先生 : “ちょっと遅いですが、2022年の機械学習のトレンドを読みましょう。”

![image3-33-4](https://yaber1965.github.io/images/image3-33-4.jpg)

QEU:FOUNDER ： “我々がやっていることは**「TinyML」**に当たるかな？”

D先生 ： “今回開発中のプログラムは「エッジデバイス上の小さな機械学習技術」になるんでしょう。予測通り、うまく「波」が来るといいですね。”

QEU:FOUNDER ： “その前に**「TinyML」**ってなに・・・？”

![image3-33-5](https://yaber1965.github.io/images/image3-33-5.jpg)

D先生 ： “FOUNDERが好きな、Kaggleによれば・・・。”

![image3-33-6](https://yaber1965.github.io/images/image3-33-6.jpg)

QEU:FOUNDER ： “今やっているのはコレ（↑TinyML）だね。”

D先生 ： “参考までに、AutoMLの紹介を見てみましょう。”

![image3-33-7](https://yaber1965.github.io/images/image3-33-7.jpg)

QEU:FOUNDER ： “え～っつ！？なんというか・・・、これは矛盾じゃない？データラベリングの手間については大いに認めるけど・・・。”

D先生 ： “私もそう思いました。まあいいじゃない、まだ詳しく調べてないんですから・・・。最後にMLOpsについて紹介します。・・・ドン！！”

![image3-33-8](https://yaber1965.github.io/images/image3-33-8.jpg)

QEU:FOUNDER ： “こういうの(統合環境)があるといいなァ・・・。・・・としか言えない（笑）。”

D先生 ： “・・・でも、全体を見てみると、**世の中全体として「民主化」にむけて機械学習が動いている**ことがわかりますね。・・・普及に向けて、（機械学習）技術を供給する準備が整いました。あとは受入れる経営側がどう動くのか・・・？”

QEU:FOUNDER ： “・・・人手不足です、さらに人件費が上がってどうしよう・・・。でも、新しいこと（機械学習）をやりたくない・・・。”

D先生 ： “じゃあ、滅べ！！”

