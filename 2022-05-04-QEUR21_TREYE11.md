## QEUR21_TREYE11:　予備実験～片目法（その１）

## ～　特徴量抽出（max pooling）の限界・・・　～

D先生 ： “すでに、我々は形状における異常を検出する手段としてあ「チョコレート検査」という方法を確立しております。今回も畳み込みRT法(Conv-RT)を使うので、大きな試行錯誤はなさそうですね。”

[QEUR21_VINSP5:　 RT-Conv法（その4）～条件を変えて再トライ](https://jpnqeur21vinsp.blogspot.com/2022/02/qeur21vinsp4-rt-conv3_18.html)

![image3-31-1](https://yaber1965.github.io/images/image3-31-1.jpg)

QEU:FOUNDER ： “むしろ、今回の場合のほうが検査としては楽でしょう。違いとしては、fastaiのノウハウを使って、プログラムを改良するぐらいじゃないでしょうか。・・・というわけで、これ以上は特にいうことはありません。それではプログラムをドン！！”

```python
# ------------------
# 畳み込みRT法の予備実験
# testNO1_convRT_metrics.py
# モジュールのインポート
import cv2
from fastai.vision.all import *

# ------------------
# 読み込み先
base_path = "./"
pic_name = "camera0_0_0_89_0_0_0.png"   # 正常
#pic_name = "camera0_0_0_89_0_0_1_X10.png"   # PINNO3-1端子抜け
#pic_name = "camera0_0_0_89_0_0_2_Y10.png"   # PINNO4-1端子抜け
filename = base_path + pic_name

# ------------------
img = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)
img_crop = img[212:856,47:1867]
# 画像出力
#cv2.imshow("image", img_crop)
#print(img_crop.shape)
#cv2.waitKey(0)
#cv2.destroyAllWindows()

# リサイズ
newsize = (450, 150)
img_resize = cv2.resize(img_crop , newsize)
# 画像出力
#cv2.imshow("image", img_resize)
#print(img_resize.shape)
#cv2.waitKey(0)
#cv2.destroyAllWindows()

# ------------------
# 画像データのテンソル化
img_tensor = tensor(img_resize/255)
print(img_tensor)

# ------------------
# 畳み込み部品を読み込む
import pandas as pd
import numpy as np

#=================================================
# READ CSV FI
#=================================================
# 実験パターンファイルを読み込み表示する
def read_csvfile(file_readcsv, max_idx, max_col): 
 
    # 画像異常検出ファイルの読み込み
    df = pd.read_csv(file_readcsv) 
    #print(df)
    # ------------------
    # 選択項目の読み込み
    # Xsマトリックス
    mx_Xs = df.loc[:,"col1":"col10"].values
    #print("----- mx_Xs -----")
    #print(mx_Xs)
  
    return mx_Xs
    
# ------------------
# パラメタの設定
max_cnv_parts = 8

# 画像サンプルのサイズ
max_sp_idx     = 150
max_sp_col     = 450
# 畳み込み部品のサイズ
max_cnv_idx    = 10
max_cnv_col    = 10
# スキップ量
skip_cnv_idx   = 10
skip_cnv_col   = 10

# ------------------
# フォルダ名の指定
foldername = "./ARRAY_RTCNN/"  # My project folder

# ------------------
nam_cnv_input = "基準用CSVデータ" 
code_cnv_input = ["NA"] * 8 # CSVコードの指定
code_cnv_input[0] = "bend1_cnv" # CSVコードの指定
code_cnv_input[1] = "bend2_cnv" # CSVコードの指定
code_cnv_input[2] = "bend3_cnv" # CSVコードの指定
code_cnv_input[3] = "bend4_cnv" # CSVコードの指定
code_cnv_input[4] = "line1_cnv" # CSVコードの指定
code_cnv_input[5] = "line2_cnv" # CSVコードの指定
code_cnv_input[6] = "datum1_cnv" # CSVコードの指定
code_cnv_input[7] = "datum2_cnv" # CSVコードの指定
print("---- 入力:畳み込み用CSVファイル名 ----")
print(code_cnv_input)
print("-------------------------------")

# ------------------
# 畳み込み処理を実施する
for i in range(max_cnv_parts):

    # ---------------------------
    # CSVファイル(実験)情報を読み込み表示する
    # 畳み込みファイル
    file_cnv_input = foldername + code_cnv_input[i] + ".csv"  # ファイルパス名の生成 
    mx_conv = read_csvfile(file_cnv_input, max_cnv_idx, max_cnv_col)
    if i == 0:    
        tensor_bend1 = tensor(mx_conv).float()
    elif i == 1:
        tensor_bend2 = tensor(mx_conv).float()
    elif i == 2:
        tensor_bend3 = tensor(mx_conv).float()
    elif i == 3:
        tensor_bend4 = tensor(mx_conv).float()
    elif i == 4:
        tensor_line1 = tensor(mx_conv).float()
    elif i == 5:
        tensor_line2 = tensor(mx_conv).float()
    elif i == 6:
        tensor_datum1 = tensor(mx_conv).float()
    elif i == 7:
        tensor_datum2 = tensor(mx_conv).float()
# ---------------------------
# カーネルの生成  
signal_kernels = torch.stack([tensor_bend1, tensor_bend2, tensor_bend3, tensor_bend4, tensor_line1, tensor_line2])
tani_kernel = (tensor_datum1 + tensor_datum2)*0.5

# ---------------------------
# 画像の処理(for)開始点のベクトルを生成
idx_range = []
sum_idx   = 0
while sum_idx <= max_sp_idx-max_cnv_idx:
    idx_range.append(sum_idx)
    sum_idx  += skip_cnv_idx
print(idx_range)

# -----
col_range = []
sum_col   = 0
while sum_col <= max_sp_col-max_cnv_col:
    col_range.append(sum_col)
    sum_col  += skip_cnv_col
print(col_range)

# ---------------------------
# 畳み込み処理を実施する
# 関数の定義
def apply_kernel(row, col, kernel):
    return (img_tensor[row:row+max_cnv_idx,col:col+max_cnv_col] * kernel).sum()

# ---------------------------
# 単位空間用の畳み込み処理を実施する
kernel = tani_kernel
tani_timage = tensor([[apply_kernel(i,j,kernel) for j in col_range] for i in idx_range])

# ------------------
# 信号空間用の畳み込み処理を実施する
for i in range(max_cnv_parts-2):

    # ---------------------------
    # CSVファイル(実験)情報を読み込み表示する
    kernel = signal_kernels[i]
    calc_conv = tensor([[apply_kernel(i,j,kernel) for j in col_range] for i in idx_range])
    # 結果の出力
    #print(calc_conv.shape)
    #print("----- calc_conv -----")
    #print(calc_conv)

    if i == 0:    
        tsr_cvbend1 = tensor(calc_conv).float()
    elif i == 1:
        tsr_cvbend2 = tensor(calc_conv).float()
    elif i == 2:
        tsr_cvbend3 = tensor(calc_conv).float()
    elif i == 3:
        tsr_cvbend4 = tensor(calc_conv).float()
    elif i == 4:
        tsr_cvline1 = tensor(calc_conv).float()
    elif i == 5:
        tsr_cvline2 = tensor(calc_conv).float()
# ---------------------------
# 畳み込みテンソルイメージの生成  
signal_timages = torch.stack([tsr_cvbend1, tsr_cvbend2, tsr_cvbend3, tsr_cvbend4, tsr_cvline1, tsr_cvline2])

# ---------------------------
# RTメトリックスを計算する(テンソル活用版)
def calc_RTmetrics(len_temp, max_jy_index, tsr_sig_matrix, tsr_tani_array): 

    # ---------------------------
    # 変数の初期化
    lnr_yarray, btY1_yarray = [], []
    st_yarray, sb_yarray, se_yarray, ve_yarray = [], [], [], []
    yita_yarray, Y2_yarray = [], []

    # 有効除数の計算
    yuko = torch.dot(tsr_tani_array, tsr_tani_array)
    #print(yuko)

    # 線形式の計算
    for i in range(len_temp):
        lnr_yitem  = torch.dot(tsr_sig_matrix[i], tsr_tani_array)
        btY1_yitem = lnr_yitem / yuko
        lnr_yarray.append(lnr_yitem.item())
        btY1_yarray.append(btY1_yitem.item())
    #print(lnr_yarray)
    #print(btY1_yarray)

    # 全変動ST及び各種中間指標SB,SE,VE,η
    for i in range(len_temp):
        sum_item  = torch.dot(tsr_sig_matrix[i], tsr_sig_matrix[i])
        st_yarray.append(sum_item.item())
        sb_yarray.append(lnr_yarray[i] ** 2 / yuko.item())
        se_yarray.append(st_yarray[i] - sb_yarray[i])
    #print(st_yarray)
    #print(sb_yarray)
    #print(se_yarray)

        # 異常処理
        temp_ve = se_yarray[i] / float(max_jy_index - 1.0)
        if temp_ve < 0.0001:
            comment = 'ゼロ異常発生！！'
            print(comment)
            ve_yarray.append(-1.0)   
            yita_yarray.append(-1.0)  
            Y2_yarray.append(-1.0) 
        else:
            temp_Y2 = math.sqrt(temp_ve)
            ve_yarray.append(temp_ve)   
            yita_yarray.append(1.0 / temp_ve)  
            Y2_yarray.append(temp_Y2) 
    #print(btY1_yarray)
    #print(Y2_yarray)

    return btY1_yarray, Y2_yarray

# ---------------------------
# テンソルイメージ処理のパラメタ
max_tsr_idx   = 15
max_tsr_col   = 45
# スキップ量
skip_tsr_idx  = 5
skip_tsr_col  = 5
# RT法処理のサイズ
rtm_tsr_idx   = 5
rtm_tsr_col   = 5
# RTベクトル長と信号空間長
max_jy_index  = 5*5
len_temp      = 6

# ---------------------------
# テンソル行列の処理(for)開始点のベクトルを生成
idx_range = []
sum_idx   = 0
while sum_idx <= max_tsr_idx-rtm_tsr_idx:
    idx_range.append(sum_idx)
    sum_idx  += skip_tsr_idx
print(idx_range)

# -----
col_range = []
sum_col   = 0
while sum_col <= max_tsr_col-rtm_tsr_col:
    col_range.append(sum_col)
    sum_col  += skip_tsr_col
print(col_range)

# ---------------------------
# RT法によるプーリング計算
arr_row = []
arr_col = []
arr_btY1_pool = []
arr_Y2_pool = []
mx_Y2_pool = np.zeros([3,9])
# ---
cnt_row = 0
for row in idx_range:
    cnt_col = 0
    for col in col_range:
    
        # ------
        # 単位空間の空間ベクトルを生成する
        tsr_tani_array = tani_timage[row:row+rtm_tsr_idx,col:col+rtm_tsr_col].flatten()
        print(tsr_tani_array)

        # ------
        # 信号空間の空間マトリックスを生成する
        temp_matrix = signal_timages[0]
        tsr_sig_p0 = temp_matrix[row:row+rtm_tsr_idx,col:col+rtm_tsr_col].flatten()
        temp_matrix = signal_timages[1]
        tsr_sig_p1 = temp_matrix[row:row+rtm_tsr_idx,col:col+rtm_tsr_col].flatten()
        temp_matrix = signal_timages[2]
        tsr_sig_p2 = temp_matrix[row:row+rtm_tsr_idx,col:col+rtm_tsr_col].flatten()
        temp_matrix = signal_timages[3]
        tsr_sig_p3 = temp_matrix[row:row+rtm_tsr_idx,col:col+rtm_tsr_col].flatten()
        temp_matrix = signal_timages[4]
        tsr_sig_p4 = temp_matrix[row:row+rtm_tsr_idx,col:col+rtm_tsr_col].flatten()
        temp_matrix = signal_timages[5]
        tsr_sig_p5 = temp_matrix[row:row+rtm_tsr_idx,col:col+rtm_tsr_col].flatten()
        # -----
        tsr_sig_matrix = torch.stack([tsr_sig_p0, tsr_sig_p1, tsr_sig_p2, tsr_sig_p3, tsr_sig_p4, tsr_sig_p5])
        #print("----- tsr_sig_matrix -----")
        #print(tsr_sig_matrix)

        # ------
        # RTメトリックスを計算する
        btY1_yarray, Y2_yarray = calc_RTmetrics(len_temp, max_jy_index, tsr_sig_matrix, tsr_tani_array)

        # ------
        # 信号空間の空間マトリックスを生成する
        arr_row.append(row)
        arr_col.append(col)
        arr_btY1_pool.append(np.max(btY1_yarray))
        arr_Y2_pool.append(np.max(Y2_yarray))
        mx_Y2_pool[cnt_row, cnt_col] = round(np.max(Y2_yarray),3)
        # ------
        # COUNT UP
        print(cnt_row, cnt_col)
        cnt_col = cnt_col + 1
    # ------
    # COUNT UP
    cnt_row = cnt_row + 1

# ---------------------------
# 結果をヒートマップに出力する
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.DataFrame(mx_Y2_pool)
plt.figure(figsize=(14,6))
plt.title(pic_name)
sns.heatmap(df, annot=True, cbar=True, cmap='Blues', fmt='.2f')
plt.show()

```

QEU:FOUNDER ： “それでは画像をインプットした解析結果をみてみましょう。まずは端子抜けがない良品の場合です。ヒートマップの形で表現しています。各セルのSN比の値が1つの端子の状態を代表していると考えてください。”

![image3-31-2](https://yaber1965.github.io/images/image3-31-2.jpg)

QEU:FOUNDER ： “つぎにPINNO3-1における端子抜けの場合を見てみましょう。・・・ドン！！”

![image3-31-3](https://yaber1965.github.io/images/image3-31-3.jpg)

D先生 ： “欠陥がある部分の値が小さくなっています。欠陥検出は一応できているようですね。”

QEU:FOUNDER ： “次はPINNOが4-1の場合です。”

![image3-31-4](https://yaber1965.github.io/images/image3-31-4.jpg)

D先生 ： “欠陥部でこれだけ明確な変動があればSVMでも不良検出は難なくできますが、ちょっとねえ・・・。全部のピンは同じく良品なので、すべてが同じ数字になっているのが理想ですよね。いまの特徴量は「MAXプーリング」でしょ？”

QEU:FOUNDER ： “実は大事な情報を捨てています。それも踏まえて、次にいきましょうか・・・。”

## ～　まとめ　～

C部長 ： “イケメン・バトルをやりましょう。皆さん、「（バトル）カード」を提出ください・・・。”

![image3-31-5](https://yaber1965.github.io/images/image3-31-5.jpg)

D先生 : “私のイケメン（←）については、最近、あまり大きな動きはないなぁ。所属する組織については、なにかとにぎやかなんですが・・・。”

<iframe width="560" height="315" src="https://www.youtube.com/embed/D2Fi-hAyHb8" ti-tle="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; en-crypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

C部長： “Google Trendsで調べてみました。”

![image3-31-6](https://yaber1965.github.io/images/image3-31-6.jpg)

QEU:FOUNDER ： “じゃあ、好感度を比較してみましょう。”

![image3-31-7](https://yaber1965.github.io/images/image3-31-7.jpg)

D先生 ： “一応、週刊誌とはいえ、新聞系か・・・。私のイケメンはかろうじて入っていますが、FOUNDERのごひいきは入っていませんね。”

QEU:FOUNDER
![image3-31-8](https://yaber1965.github.io/images/image3-31-8.jpg)

D先生 ： “ヨシ！私のイケメンが一位です。これは、ようするにメディアへの露出率ランキングでしょ？”

QEU:FOUNDER ： “よく頑張った（笑）！！・・・で、最後は古いものです。”

![image3-31-9](https://yaber1965.github.io/images/image3-31-9.jpg)

D先生 ： “FOUNDERのイケメンがネガティブに登場（笑）！！なんというか、メディアや調べ方でランキングが変わるもんだなと思いました。”

QEU:FOUNDER ： “こんなもん、「あてにならない」のが結論ですね (笑)。”

