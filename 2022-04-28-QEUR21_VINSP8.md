## QEUR21_VINSP8: オリエンテーション ～ 旧プロジェクト技術明細書(Double-eye-method, English ver.)

## ～　Preface　～

### [Technology background]

Various computer-based image recognition schemes have been developed through AI contests, etc., and deep learning has recently been highly evaluated as high-performance engine (Fig. 1).

**(Fig.1: Changes in Image Recognition Technology)**

![image2-08A-3](https://yaber1965.github.io/images/image2-08A-3.jpg)

The analysis flow of machine learning is shown in the following figure (Fig. 2). Preprocessing of input da-ta has been little progress although it is also an important technology as well as recognition engine for recognition technology.

**(Fig.2: Machine Learning Workflow)**

![image2-08A-4](https://yaber1965.github.io/images/image2-08A-4.jpg)

The popular methods of data preprocessing are shown in the table below(Figs. 3 and 4). As for method of compressing image, it is currently common to remove high-order principal components having low contri-bution rate by principal component analysis (PCA).

**(Fig.3: Types of preprocessing in machine learning)**

![image2-08A-5](https://yaber1965.github.io/images/image2-08A-5.jpg)

**(Fig.4: Preprocessing in Image Discrimination)**

![image2-08A-6](https://yaber1965.github.io/images/image2-08A-6.jpg)

## [Abstract of the invention]
### [Problems to be solved by the invention]

Performance of image recognition (discrimination accuracy) by computers is improving year by year, but it is because of learning method (core technology), and it is hardly found that recognition performance had been improved by preprocessing scheme.

Furthermore, the current performance of image recognition is mainly based on still images, and in the case of automatic driving of automobiles, it is necessary to consider more types of noise and stereoscopic im-ages.


### [Means to solve problems]

This invention improves __RT (Recognition Taguchi) method__, which is one of the Taguchi methods used for quality improvement and quality improvement and applies the method as preprocessing process for image recognition. Whereas RT method uses a metric called RT Distance (D) as an index of similarity between an object and unit space (object) like Mahalanobis distance (Fig. 5).

**(Fig.5: Concept of distance calculation)**

![image2-08A-7](https://yaber1965.github.io/images/image2-08A-7.jpg)

This invention has adopted error factor by changing the definitions of sensitivity (β) and SN ratio (η) of conventional RT method (Figs. 6 and 7). Hereinafter, the conventional RT method will be referred to as single-eye scheme, and RT method of present invention will be referred to as double-eye scheme.

**(Fig. 6: Single-eye scheme - Definition of SN ratio in conventional RT method)**

![image2-08A-8](https://yaber1965.github.io/images/image2-08A-8.jpg)

**(Fig. 7: Double-eye method - Definition of SN ratio of RT method in this invention)**

![image2-08A-9](https://yaber1965.github.io/images/image2-08A-9.jpg)

By the way, the error factor of this invention can be arbitrarily set according to user‘s need, but it is de-fined for image recognition of three-dimensional object in this document(Fig. 8). Then, three cameras are installed as shown in the figure below, and images are taken from different angles. The conventional "Sin-gle-eye scheme" uses only one CENTER camera. On the other hand, the "Double-eyed scheme" in this in-vention uses three types of cameras (CENTER, LEFT, RIGHT).

**(Fig.8: Cameras Placement)**

![image2-08A-10](https://yaber1965.github.io/images/image2-08A-10.jpg)

The analysis flows of image recognition using single-eye scheme, double-eye scheme as well as the RT multi-method are shown below respectively (Fig. 9). Both of analysis flows looks the same, but the types and numbers of image data and the definitions of metric of sensitivity and SN ratio are different.

**(Fig. 9: Analysis flow of SN ratio of conventional single-eye RT (multi) method)**

![image2-08A-11](https://yaber1965.github.io/images/image2-08A-11.jpg)

**(Fig. 10: Analysis flow of double-eye RT (multi) method of this invention)**

![image2-08A-12](https://yaber1965.github.io/images/image2-08A-12.jpg)

The unit space image is obtained by averaging a plurality of images selected by user as images from CEN-TER camera (Fig. 11,12).

**(Fig. 11: Unit space averaging process)**

![image2-08A-13](https://yaber1965.github.io/images/image2-08A-13.jpg)

**(Fig. 12: Unit space output)**

![image2-08A-14](https://yaber1965.github.io/images/image2-08A-14.jpg)

Multi-RT method output matrix of RT Distances as an intermediate output by dividing image appropriately to generate matrix (Figs. 13 and 14). In the example below, the image is divided into 4x4 = 16 to calculate RT Distance in each region.

**(Fig. 13: Split design)**

![image2-08A-15](https://yaber1965.github.io/images/image2-08A-15.jpg)

**(Fig. 14: RT Distance matrix)**

![image2-08A-16](https://yaber1965.github.io/images/image2-08A-16.jpg)

The final output of multi-RT method is obtained by recalculating RT Distance value via RT Distance ma-trix generated at step 1. The amount of RT Distance is low if the features of object are similar to one of unit space, and large otherwise. In other words, it is possible to recognize which object is most similar to object by preparing unit spaces for multiple objects, (Fig. 15).

**(Fig. 15: Comparison of similarity)**

![image2-08A-17](https://yaber1965.github.io/images/image2-08A-17.jpg)

## [Example_1]

An example applying this invention to automation of visual inspection is shown below. 3D CAD and CG software can prepare unit spaces before launch of mass production as for automation of visual inspection. In this case, Blender as 3D CG software, is applied (Fig. 16). 3D CG software can take pictures by multiple cameras in the virtual space at the same time (Fig. 17). 

**(Fig.16: Blender Application Examples)**

![image2-08A-18](https://yaber1965.github.io/images/image2-08A-18.jpg)

**(Fig.17: Image [left-center-right])**

![image2-08A-19](https://yaber1965.github.io/images/image2-08A-19.jpg)

This case study modified the three-dimensional effect of a part of a three-dimensional object without changing its appearance as much as possible. In this monkey head model, its eyes and nose were modified to protrude slightly (Figs. 18, 19, 20). it attempted detect these changes in the shape of an object by con-ventional preprocess (single-eye scheme) and one of this invention (two-eyed scheme). 

**(Fig.18: Normal image)**

![image2-08A-20](https://yaber1965.github.io/images/image2-08A-20.jpg)

**(Fig.19: Abnormal Image[1])**

![image2-08A-21](https://yaber1965.github.io/images/image2-08A-21.jpg)

**(Fig.20: Abnormal Image[2])**

![image2-08A-22](https://yaber1965.github.io/images/image2-08A-22.jpg)

A matrix calculation results of step 1 (intermediate) RT Distance with conventional single-eye RT method shown below (Figs. 21 and 22). Since a small portion of eyes and nose are changed in 3D CG model, the values of distances in cells around the matrix do not change significantly before and after model change (their ratios are around 1.0).

**(Fig.21: Image Comparison)**

![image2-08A-23](https://yaber1965.github.io/images/image2-08A-23.jpg)

**(Fig.22: RT Distance Comparison)**

![image2-08A-24](https://yaber1965.github.io/images/image2-08A-24.jpg)

The result of calculating RT Distance in step 2 (final stage) using single-eye method is shown in the figure below (Fig. 23). Whereas metrics Y1 and Y2 are derivatives of sensitivity (β) and signal-to-noise ratio (η) for calculating RT Distance. In the case of single-eye method, distribution of scatter plot shows non-linear behavior. 

**(Fig.23: Distribution of RT distance)**

![image2-08A-25](https://yaber1965.github.io/images/image2-08A-25.jpg)

Matrix calculation results of RT Distance at step 1 (intermediate) using double-eye RT method of this in-vention are shown below (Figs. 24 and 25). Since calculation methods of metrics Y1 and Y2 are different, value of double-eye scheme is difference from one of single-eye scheme. Although cell values in peripher-al part are consistent, one at the center has been changed. This trend is the same as single-eye method. 

**(Fig.24: Comparison of Stereo images [Normal - Abnormal])**

![image2-08A-26](https://yaber1965.github.io/images/image2-08A-26.jpg)

**(Fig.25: Stereo RT distance comparison [normal-abnormal])**

![image2-08A-27](https://yaber1965.github.io/images/image2-08A-27.jpg)

The result of RT Distance at step 2 (final stage) using double-eye scheme is shown in the figure below (Fig. 26). Whereas, Y1-Y2 scatter plot has linear distribution. 

**(Fig.26: Distribution of Stereo RT distance [both eyes])**

![image2-08A-28](https://yaber1965.github.io/images/image2-08A-28.jpg)

In addition, the difference between single-eyed and double-eyed scheme are compared in RT Distance at step 2 (final stage) in order to evaluate a likelihood of misjudgment (Figs. 12 and 13). The variation in RT Distance of double-eye scheme is less than one of single-eye scheme. Therefore, the possibility of error (misjudgment) using double-eye scheme is less than one of single-eyed scheme. 

**(Fig. 27: Comparison of RT Distance in single-eye scheme)**

![image2-08A-29](https://yaber1965.github.io/images/image2-08A-29.jpg)

**(Fig. 28: Comparison of RT Distance in double-eye scheme)**

![image2-08A-30](https://yaber1965.github.io/images/image2-08A-30.jpg)

## [Industrial applicability]

This invention (double-eye scheme) can be applied to various industrial computer recognition techniques by defining error factors. In particular, it is applied to automatic visual inspection and automatic driving technology of vehicle as recognition of three-dimensional object. 

When recognizing object with image, it may not be possible to make a correct judgment with just one image. For example, three persons are shown in an image below. It is considered that a person in the middle is smaller (Fig. 29). However, it is also considered that a person in the middle is far from the camera (Fig. 30).

**(Fig. 29: What you can see in one image)**

![image2-08A-31](https://yaber1965.github.io/images/image2-08A-31.jpg)

**(Fig. 30: Actual three-dimensional situation)**

![image2-08A-32](https://yaber1965.github.io/images/image2-08A-32.jpg)

Although evaluating distance between objects is important in autonomous driving, it is difficult with cur-rent technology. This invention can improve safety of automatic driving since this invention can evaluate the distance between objects and object simultaneously.

This invention is also very effective when applied to visual inspection machine. Defect of dimension at pins and bosses in products (or parts) are difficult to find by computer processing with one image. only a defective portion is different and rest of them are exactly the same because most of products are manufac-tured by transfer processing. It is easy to find abnormalities by comparing two images taken from different angles.


