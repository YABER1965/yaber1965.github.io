## QEUR21_FATOY16:　協調フィルタリング(その2)

## ～　全く違った「視点」から解析する　～

### ・・・　はっきりいって、「お遊びレベル」だけどね　・・・

D先生 ： “FOUNDER・・・、やっぱり今度も協調フィルタリングの代わりにT法(2)を使うんですか？”

![image1-61-1](https://yaber1965.github.io/images/image1-61-1.jpg)

QEU:FOUNDER ： “そう。前回のプロジェクトも同じですからね。”

D先生 ： “そしたら、もしベクトルを作るとなると複数の応答変数(Ys)が必要です。どうしますか？”

![image1-61-2](https://yaber1965.github.io/images/image1-61-2.jpg)

QEU:FOUNDER ： “映画には「ジャンル(genres)」があります。これを使いましょう。”

```python
genre_cols  = ['genre_unknown', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy',
'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror',
'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']

```

D先生 ： “全部で19水準ですね。マイナーなジャンルを消しても15水準ぐらいにはなりそうですね。”

QEU:FOUNDER ： “知らん・・・。あとはプログラムをドン・・・。”

```python
# ---------------------------
# 協調フィルタリングのマネをT法でやってみる
# データベースの準備
# t2m_movies_ratings_prepare.py
# 参考：https://www.youtube.com/watch?v=cE7sXEjQMUg
# ---------------------------
import math
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
plt.style.use('ggplot')

# -----
# pick any other dataset instead
# 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'
df_ratings = pd.read_csv('./ratings.csv') 
df_movies = pd.read_csv('./movies.csv') 
df_movies.head()

num_movies = len(df_movies)
print("num_movies:", num_movies)
num_ratings = len(df_ratings)
print("num_ratings:", num_ratings)

#  ジャンルリストを作成する
arr_genres = df_movies['genres'].values
print("arr_genres:", arr_genres)

#  movies データフレームを作成する
genre_cols  = ['genre_unknown', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy',
'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror',
'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']
num_genre   = len(genre_cols)
print("num_genre:", num_genre)

# ---------------------------
# 正規表現を活用する
import re

# -----
# ジャンルのコラムを追加する
mx_genres = np.zeros([num_movies, num_genre])

for i in range(num_movies):

    # ジャンル
    str_genre   = arr_genres[i]
    icount  = 0

    for j in range(num_genre):

        # ジャンル
        pattern = genre_cols[j]
        # searchなら、存在するだけで結果が出る
        search_result = re.search(pattern, str_genre)
        # 行列要素の追加
        if search_result != None:
            #print("i:{},genres:{},pattern:{},result:{}".format(i, str_genre, pattern, search_result))
            mx_genres[i,j] = 1
            icount  = icount  + 1
    # -----
    # ジャンルの情報がない場合
    if i == num_movies and icount == 0:
        mx_genres[i,0] = 1
# -----
# 結果行列の表示
print(mx_genres)

# データフレームを生成する
df_genres = pd.DataFrame(mx_genres, columns=genre_cols)
df_genres.describe()

# 統計の表示と寄与の低いジャンルを削除する
del df_genres['genre_unknown']
del df_genres['Film-Noir']
del df_genres['Western']
#df_genres.head()
genre_cols = df_genres.columns.values
print("genre_cols:", genre_cols)
num_genres = len(genre_cols)
print("num_genres:", num_genres)

# ２つのデータフレームの結合してnew_moviesを作成
df_new_movies = pd.concat([df_movies, df_genres], axis=1)
df_new_movies.head(10)

# ---------------------------
# レーティングDBを生成する
del df_ratings['timestamp']
#df_ratings.head()

# レーティング・マトリックスの初期化
mx_ratings  = np.zeros([num_ratings, num_genres])
print(mx_ratings)

# -----
# レーティングDBから検索する
for i in range(num_ratings):    # num_ratings
    
    val_movieId = df_ratings.loc[i,'movieId']
    val_rating  = df_ratings.loc[i,'rating']
    tmp_genres  = df_new_movies[df_new_movies['movieId'] == val_movieId]
    idx_genres  = tmp_genres.loc[:,'Action':'War'].values.flatten() * val_rating
    mx_ratings[i,:] = idx_genres
    #print("i:{}, val_movieId:{}, idx_genres:{}".format(i,val_movieId, idx_genres))

# -----
# データフレームを生成する
df_temp_ratings = pd.DataFrame(mx_ratings, columns=genre_cols)
#df_temp_ratings.head()

# ２つのデータフレームの結合してnew_moviesを作成
df_new_ratings = pd.concat([df_ratings, df_temp_ratings], axis=1)
df_new_ratings.head()

# ---------------------------
# ユニークなユーザIDリストを生成する
list_userId     = df_ratings.loc[:,'userId'].values
unique_userId   = list(set(list_userId))
num_userId      = len(unique_userId)

# MOVIE・集計マトリックスの初期化
mx_agg_movies  = np.zeros([num_userId, num_movies])
print(mx_agg_movies.shape)
# RATING・集計マトリックスの初期化
mx_agg_ratings  = np.zeros([num_userId, num_genres])
print(mx_agg_ratings.shape)
# movieIdのリスト
arr_idx_movieId   = df_movies.loc[:,'movieId'].values

# userId毎に集計(aggregate)する
for i in range(num_userId):    # num_userId
    
    ix = unique_userId[i]
    df_tmp_agg      = df_new_ratings[df_new_ratings['userId'] == ix]
    arr_tmp_movieId = df_tmp_agg.loc[:,'movieId'].values.tolist()
    # -----
    # movieマトリックス
    for j in arr_tmp_movieId: 
        idx_movieId   = arr_idx_movieId.index(j)
        mx_agg_movies[i,idx_movieId] = 1
    # -----
    # ratingマトリックス
    df_tmp_sum      = df_tmp_agg.sum()
    arr_tmp_sum = df_tmp_sum['Action':].values
    mx_agg_ratings[i,:]  = arr_tmp_sum
# ----
# 計算結果(Xs,Ys)の表示
# movieマトリックス
print("--- ムービー(Xs) ---")
print(mx_agg_movies)
# ratingマトリックス
print("--- レーティング(Ys) ---")
print(mx_agg_ratings)

# ---------------------------
# データフレームを生成する
# ムービー別
movie_cols = []
for i in arr_idx_movieId:
    movie_cols.append("s{}".format(i))
#print(movie_cols)
df_agg_movies = pd.DataFrame(mx_agg_movies, columns=movie_cols)
df_agg_movies.head()
# ジャンル別
df_agg_ratings = pd.DataFrame(mx_agg_ratings, columns=genre_cols)
df_agg_ratings.head()

# ２つのデータフレームの結合してnew_moviesを作成
df_agg_data = pd.concat([df_agg_movies, df_agg_ratings], axis=1)
df_agg_data.head(10)

# ---------------------------
# 解析結果をCSVファイルに保存する
df_agg_data.to_csv("t2m_table_movie_rating.csv")

```

QEU:FOUNDER ： “このコードをそのまま実行すると、以下の結果がでてきます。”

![image1-61-3](https://yaber1965.github.io/images/image1-61-3.jpg)

D先生 ： “いままでさんざんやったことですし・・・、特にコメントはないです。”

QEU:FOUNDER ： “まあ、中間データの加工だけだからね。じゃあ最後にCSVファイル出力について紹介しますね。”

![image1-61-4](https://yaber1965.github.io/images/image1-61-4.jpg)

D先生 ： “すごく大きなマトリックスになりましたね。”

QEU:FOUNDER ： “マトリックスの行が610で、映画の数量（X）が9700あるからね・・・。”

D先生 ： “これを使って各映画ごとにベクトルを生成すればいいわけですね。”

QEU:FOUNDER ： “そういうこと。次回につづく・・・。”


## ～　まとめ　～

### ・・・　つづきです　・・・

QEU:FOUNDER ： “このJeremyさんのインタビュー動画（↓）を見てつくづく思いました。彼がインタビューしたのは24歳の若者、Kaggleのグランドマスターです。（彼が）初めてKaggleに参加したのは19歳という・・・。”

<iframe width="560" height="315" src="https://www.youtube.com/embed/g_6nQBsE4pU" ti-tle="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; en-crypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

D先生 ： “Kaggleは運営がオープンですよね、だからこそ天才を発掘できます。・・・だけど、なぜブログにこだわるんですか？論文検査システム?-stageとか、pdf形式で見れるでしょ？“

![image1-61-5](https://yaber1965.github.io/images/image1-61-5.jpg)

QEU:FOUNDER ： “それはなんといっても、Rachelさんが「ブログを書け」と言っているから、冗談だけど・・・（笑）。pdf形式って、すごく使いにくいんですよ・・・。”

![image1-61-6](https://yaber1965.github.io/images/image1-61-6.jpg)

QEU:FOUNDER ： “(pdfは)基本、印刷物なので・・・。これは読むためのもので、「コピペ」するためのものじゃないんです。”

C部長 : “コピペ・・・？”

QEU:FOUNDER ： “**論文なんかは同業者が見る**でしょ？・・・というか、普通は「わかっている人」、「読み込める人」が読みます。pdf形式でかかれた文書は、その点で見ればまとまっていて読みやすいでしょうね。でも、**もしも読む人が「（記述している分野を）わかっていない人」だったら？**小生みたいに・・・。”

C部長 : “困りますね・・・。”

QEU:FOUNDER ： “そういう場合、最初に適当に20記事位を検索し、(MS)WORDにコピペします。そうすればWORDファイルは5MBぐらいになるかな？そして、中身を軽く読む・・・。もちろん、何を言っているのかわからない。でも、**「どのような語彙が使われるか」**がわかります。そして、再度G検索する。それで得たブログをWORDにコピペする・・・。”

C部長 : “コピペした後のWORDファイルのサイズは？“

QEU:FOUNDER ： “少なくとも100MBにはなる。あとはWORDファイルの内容を徐々に削ります。WORDにコピペした後、文書内でキーワード検索すれば簡単に注意すべき部分が見つかります。”

D先生 ： “まあ、本当に必要な情報まではわからないが、いらない情報は分かるようになりますね。“

QEU:FOUNDER ： “あとはGithubで関連するプログラムをダウンロードして必要なパーツを拾い出す。”

D先生 ： “まだブログの内容はわかっていないの？ “

QEU:FOUNDER ： “**「技術がわかることとプログラムを作ることは別」**です。プログラムはこの程度の理解度で十分につくれます。だから、簡単にコピペできるブログがたくさん手に入ることが重要なんです。この前WORDファイルの中の言語別シェアを調べたら、J語の記事はたったの10％程度でした。残りはC語が30％で、E語は60％です。J国語だけでシステムを開発しようとしたら、まさにお話になりません。”

