## QEUR21_TREYE24:　本実験～両目法（その3）: マハラノビス距離の出力

## ～　この結果の見方は様々だが・・・　～

QEU:FOUNDER ： “すでに予備実験でほとんど解説しているので、今回は一気に画像からマハラノビス距離（特徴量マップ）を出力するところまでいきましょう。”

D先生 ： “まずはマハラノビス距離を計算するための相関行列の学習プログラムです。これは予備実験とほとんど同じです。”

```python
# -------------------- プログラムの始まり -------------------
# -*- coding: utf-8 -*-
# filename: testDE3_maharanobis_FeatureEngineering.py
# RT畳み込みマトリックスをマハラノビス距離に変換してマトリックス形成する（ヒートマップに出力） 
# ---------------------------------------------------
import numpy as np
import pandas as pd
import math
import seaborn as sns
from scipy.spatial import distance
import matplotlib.pyplot as plt

#=================================================
# READ CSV_FILE FUNCTION
#=================================================
# CSVファイルを読み込み表示する
def read_csvfile(file_readcsv): 
 
    # 画像異常検出ファイルの読み込み
    df = pd.read_csv(file_readcsv) 
    num_df  = len(df)
    #print(df)
    # --------------------------------------------------
    # 選択項目の読み込み
    #　Xsマトリックス
    mx_Xs   = df.loc[:,"0":"8"].values
    arr_Xs  = mx_Xs.flatten()
    #print("----- mx_Xs -----")
    #print(mx_Xs)
    #print(arr_Xs)

    return mx_Xs, arr_Xs

# ------------------
# フォルダ名の指定
foldername = "./ARRAY_RTCNN/"  # My project folder
# ------------------
nam_met_input   = "基準用CSVデータ" 
code_pY1_input  = ["NA"] * 6 # CSVコードの指定
code_pY2_input  = ["NA"] * 6 # CSVコードの指定
# ---
code_pY1_input[0] = "RTm_p0Y1" #  beta_cnv CSVコードの指定
code_pY1_input[1] = "RTm_p1Y1" #  beta_cnv CSVコードの指定
code_pY1_input[2] = "RTm_p2Y1" #  beta_cnv CSVコードの指定
code_pY1_input[3] = "RTm_p3Y1" #  beta_cnv CSVコードの指定
code_pY1_input[4] = "RTm_p4Y1" #  beta_cnv CSVコードの指定
code_pY1_input[5] = "RTm_p5Y1" #  beta_cnv CSVコードの指定
# ---
code_pY2_input[0] = "RTm_p0Y2" #  snr_cnv CSVコードの指定
code_pY2_input[1] = "RTm_p1Y2" #  snr_cnv CSVコードの指定
code_pY2_input[2] = "RTm_p2Y2" #  snr_cnv CSVコードの指定
code_pY2_input[3] = "RTm_p3Y2" #  snr_cnv CSVコードの指定
code_pY2_input[4] = "RTm_p4Y2" #  snr_cnv CSVコードの指定
code_pY2_input[5] = "RTm_p5Y2" #  snr_cnv CSVコードの指定
print("---- 入力:マハラノビス計算用CSVファイル名 ----")
print(code_pY1_input)
print("-------------------------------")

# ---------------------------
# メトリックス類のデータを読み込む
# 感度類(pY1)
mx_pY1s = np.zeros([6, 27])
for i in range(6):
    file_met_input = foldername + code_pY1_input[i] + ".csv"  # ファイルパス名の生成 
    mx_Xs, arr_Xs = read_csvfile(file_met_input)
    mx_pY1s[i] = arr_Xs
# ---
mx_pY1s = mx_pY1s.T
print("---- mx_pY1s ----")
print(mx_pY1s)
# -----
# SN比類(pY2)
mx_pY2s = np.zeros([6, 27])
for i in range(6):
    file_met_input = foldername + code_pY2_input[i] + ".csv"  # ファイルパス名の生成 
    mx_Xs, arr_Xs = read_csvfile(file_met_input)
    mx_pY2s[i] = arr_Xs
# ---
mx_pY2s = mx_pY2s.T
print("---- mx_pY2s ----")
print(mx_pY2s)
# ---------------------------
# メトリックス類のデータを読み込む
mx_metrics = np.concatenate([mx_pY1s, mx_pY2s],axis=1)
#print(mx_metrics.shape)   # (27, 12)
#print("---- mx_metrics ----")
#print(mx_metrics)

# ------------------
# マハラノビスマトリックスとグラフ作画準備
max_iRow_cells = 3*9
max_jCol_cells = 12

# ------------------
iRow_sig    = []
jCol_sig    = []
X_sig   = []
Y_sig   = []
# ------
X_tani  = []
Y_tani  = []
# ------
arr_index   = list(range(max_iRow_cells))
arr_columns = list(range(max_jCol_cells))
mx_maha     = np.zeros([max_iRow_cells, max_jCol_cells])
# ------
mx_Xs_tani  = mx_metrics.copy()
arr_Xs_tani = []
for kItem in range(max_jCol_cells):
    # 中央値を計算する
    mean_X_tani = np.mean(mx_Xs_tani[:, kItem])
    arr_Xs_tani.append(mean_X_tani)
#print(arr_Xs_tani)

# ------------------
# 単位空間を用いた学習
# 分散共分散行列を計算する
cov = np.cov(mx_Xs_tani.T)
# 分散共分散行列の逆行列を計算する
cov_i = np.linalg.pinv(cov)
# ------
# 2つの標本 [X_tani, X_tani(sig)] と [(mean)arr_X_tani] のマハラノビス距離を計算する
mx_Xs_sig  = mx_metrics.copy()
arr_d = []
for i in range(max_iRow_cells):
    d = distance.mahalanobis(mx_Xs_sig[i,:], arr_Xs_tani, cov_i)
    if d > 100: d = 100
    arr_d.append(round(d,4))
    #print("i:{}, マハラノビス距離の計算結果:{}".format(i,d))
# ------
#print(arr_d)
mx_MHdist = np.reshape(np.array(arr_d), (3, 9))
print("---- mx_MHdist ----")
print(mx_MHdist)

# ---------------------------
# マハラノビス距離のマトリックスを作画する(単位空間)
arr_index   = list(range(3))
arr_columns = list(range(9))
df_maha = pd.DataFrame(mx_MHdist, index=arr_index, columns=arr_columns)
#print("---- df_maha ----")
#print(df_maha)

# ---------------------------
# ヒートマップへ出力(単位空間)
fig = plt.figure(figsize=(12, 5))
ax = fig.add_subplot(1, 1, 1)
ax.set_title("Maharanobis Distance(TANI)")
sns.heatmap(df_maha, ax=ax, annot=True, cbar=True, cmap='Blues', fmt='.2f')
plt.show()

# ---------------------------
# CSVファイルに学習結果を出力する
#=================================================
# OUT CSV FUNCTION(1)
#=================================================
# CSVファイルに出力する(相関逆行列)
def save_invcorr(mx_result): 

    # ---------------------------
    # データフレームを作成
    arr_index = list(range(12))
    arr_columns = list(range(12))
    df_metrics = pd.DataFrame(mx_result, index=arr_index, columns=arr_columns)

    # ---------------------------
    print("------------ 相関逆行列のデータフレーム -------------")  
    print(df_metrics) 
    # CSV ファイル (distance.csv) として出力
    file_csvout = foldername + "RTm_invcorr.csv" # ファイルパス名の生成
    df_metrics.to_csv(file_csvout)
    print("CSVファイルの出力完了 : {}".format(file_csvout)) 
    
    return df_metrics

# ---------------------------
# CSVファイルに出力する(相関逆行列)
# ---------------------------
save_invcorr(cov_i)

#=================================================
# OUT CSV FUNCTION(2)
#=================================================
# CSVファイルに出力する(単位空間の中心)
def save_taniXs(mx_result): 

    # ---------------------------
    # データフレームを作成
    arr_columns = list(range(12))
    df_metrics = pd.DataFrame(mx_result, columns=arr_columns)

    # ---------------------------
    print("------------ 単位空間の中心のデータフレーム -------------")  
    print(df_metrics) 
    # CSV ファイル (distance.csv) として出力
    file_csvout = foldername + "RTm_taniXs.csv" # ファイルパス名の生成
    df_metrics.to_csv(file_csvout)
    print("CSVファイルの出力完了 : {}".format(file_csvout)) 
    
    return df_metrics

# ---------------------------
# CSVファイルに出力する(単位空間の中心)
# ---------------------------
save_taniXs([arr_Xs_tani])

```

QEU:FOUNDER ： “次が、画像を入力し、それら（3枚画像）と相関逆行列データからマハラノビス距離の分布を出力するプログラムです。それでは、よ～いドン！！長いよ・・・。”

```python
# ---------------------------
# 両目畳み込みRT法の本実験
# testDE4_inspection_featuremap.py
# ---------------------------
# モジュールのインポート
import cv2
from fastai.vision.all import *
import seaborn as sns
import pandas as pd
import numpy as np
from scipy.spatial import distance
import matplotlib.pyplot as plt

# ---------------------------
# 読み込み先の指定
foldername = "./ARRAY_RTCNN/"
newsize = (900, 300)
#pic_nameL = "camera0_0_0_88_005_00_0_OK.png"   # 左カメラ画像(普通色)
#pic_nameC = "camera1_0_0_88_005_00_0_OK.png"   # 中央カメラ画像(普通色)
#pic_nameR = "camera2_0_0_88_005_00_0_OK.png"   # 右カメラ画像(普通色)
pic_nameL = "camera0_0_0_88_m003_007_0_COLOR.png"   # 左カメラ画像(色変更)
pic_nameC = "camera1_0_0_88_m003_007_0_COLOR.png"   # 中央カメラ画像(色変更)
pic_nameR = "camera2_0_0_88_m003_007_0_COLOR.png"   # 右カメラ画像(色変更)

#=================================================
# READ CSV_FILE FUNCTION
#=================================================
# 畳み込みファイルを読み込み表示する
def read_csvfile(file_readcsv): 
 
    # 畳み込みファイルの読み込み
    df = pd.read_csv(file_readcsv) 
    # ------------------
    # 選択項目の読み込み
    # Xsマトリックス
    mx_Xs = df.loc[:,"col1":"col5"].values
    #print("----- mx_Xs -----")
    #print(mx_Xs)
  
    return mx_Xs

# ---------------------------
# LCR画像ファイルを読んで、テンソルを出力する
def read_LCRpics(pic_nameL, pic_nameC, pic_nameR): 

    # ------------------
    # 左(L)画像
    filename = foldername + pic_nameL
    imgL = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)
    img_cropL = imgL[212:856,47:1867]
    # リサイズ
    img_resizeL = cv2.resize(img_cropL , newsize)

    # ------------------
    # 中央(C)画像
    filename = foldername + pic_nameC
    imgC = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)
    img_cropC = imgC[212:856,47:1867]
    # リサイズ
    img_resizeC = cv2.resize(img_cropC , newsize)

    # ------------------
    # 右(R)画像
    filename = foldername + pic_nameR
    imgR = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)
    img_cropR = imgR[212:856,47:1867]
    # リサイズ
    img_resizeR = cv2.resize(img_cropR , newsize)
    # 画像出力
    #cv2.imshow("image(Right)", img_resizeR)
    #cv2.waitKey(0)
    #cv2.destroyAllWindows()

    # ------------------
    # 画像データのテンソル化(L,C,R)
    img_tensorL = tensor(img_resizeL/255)  # 信号空間
    img_tensorC = tensor(img_resizeC/255)  # 単位空間（標準ベクトル）
    img_tensorR = tensor(img_resizeR/255)  # 信号空間
    
    return img_tensorL, img_tensorC, img_tensorR

# ---------------------------
# 両目法RTメトリックスを計算する(テンソル活用版)
def calc_deyeRTmet(len_temp, max_jy_index, tsr_sig_matrix, tsr_tani_array): 

    # ---------------------------
    # 変数の初期化
    lnr_yarray, btY1_yarray = [], []
    st_yarray, sb_yarray, se_yarray, ve_yarray = [], [], [], []
    yita_yarray, Y2_yarray = [], []

    # 有効除数の計算
    yuko = torch.dot(tsr_tani_array, tsr_tani_array)
    #print(yuko)

    # 線形式の計算
    for i in range(len_temp):
        lnr_yitem  = torch.dot(tsr_sig_matrix[i], tsr_tani_array)
        btY1_yitem = lnr_yitem / yuko
        lnr_yarray.append(lnr_yitem.item())
        btY1_yarray.append(btY1_yitem.item())
    #print(lnr_yarray)
    #print(btY1_yarray)

    # 全変動ST及び各種中間指標SB,SE,VE,η
    for i in range(len_temp):
        sum_item  = torch.dot(tsr_sig_matrix[i], tsr_sig_matrix[i])
        st_yarray.append(sum_item.item())
        sb_yarray.append(lnr_yarray[i] ** 2 / yuko.item())
        se_yarray.append(st_yarray[i] - sb_yarray[i])
    #print(st_yarray)
    #print(sb_yarray)
    #print(se_yarray)

        # 異常処理
        temp_ve = se_yarray[i] / float(max_jy_index - 1.0)
        if temp_ve < 0.0001:
            #comment = 'ゼロ異常発生！！'
            #print(comment)
            ve_yarray.append(0.0)   
            yita_yarray.append(0.0)  
            Y2_yarray.append(0.0) 
        else:
            temp_Y2 = math.sqrt(temp_ve)
            ve_yarray.append(temp_ve)   
            yita_yarray.append(1.0 / temp_ve)  
            Y2_yarray.append(temp_Y2) 
    #print(btY1_yarray)
    #print(Y2_yarray)

    return round(Y2_yarray[0] - Y2_yarray[1], 5)

# ---------------------------
# 畳み込み処理を実施する
def apply_kernel(row, col, kernel, img_tensor):
    return (img_tensor[row:row+max_cnv_row,col:col+max_cnv_col] * kernel).sum()

# ---------------------------
# RTメトリックスを計算する(テンソル活用版)
def calc_RTmetrics(len_temp, max_jy_index, tsr_sig_matrix, tsr_tani_array): 

    # ---------------------------
    # 変数の初期化
    lnr_yarray, btY1_yarray = [], []
    st_yarray, sb_yarray, se_yarray, ve_yarray = [], [], [], []
    yita_yarray, Y2_yarray = [], []

    # 有効除数の計算
    yuko = torch.dot(tsr_tani_array, tsr_tani_array)
    #print(yuko)

    # 線形式の計算
    for i in range(len_temp):
        lnr_yitem  = torch.dot(tsr_sig_matrix[i], tsr_tani_array)
        btY1_yitem = lnr_yitem / yuko
        lnr_yarray.append(lnr_yitem.item())
        btY1_yarray.append(btY1_yitem.item())
    #print(lnr_yarray)
    #print(btY1_yarray)

    # 全変動ST及び各種中間指標SB,SE,VE,η
    for i in range(len_temp):
        sum_item  = torch.dot(tsr_sig_matrix[i], tsr_sig_matrix[i])
        st_yarray.append(sum_item.item())
        sb_yarray.append(lnr_yarray[i] ** 2 / yuko.item())
        se_yarray.append(st_yarray[i] - sb_yarray[i])
    #print(st_yarray)
    #print(sb_yarray)
    #print(se_yarray)

        # 異常処理
        temp_ve = se_yarray[i] / float(max_jy_index - 1.0)
        if temp_ve < 0.0001:
            comment = 'ゼロ異常発生！！'
            print(comment)
            ve_yarray.append(-1.0)   
            yita_yarray.append(-1.0)  
            Y2_yarray.append(-1.0) 
        else:
            temp_Y2 = math.sqrt(temp_ve)
            ve_yarray.append(temp_ve)   
            yita_yarray.append(1.0 / temp_ve)  
            Y2_yarray.append(temp_Y2) 
    #print(btY1_yarray)
    #print(Y2_yarray)

    return btY1_yarray, Y2_yarray

#=================================================
# MAIN PROGRAM(1) : 両目RTメトリックス
#=================================================
# LCR画像ファイルを読んで、テンソルを出力する
img_tensorL, img_tensorC, img_tensorR = read_LCRpics(pic_nameL, pic_nameC, pic_nameR)
#print(img_tensorC)

# ---------------------------
# テンソルイメージ処理のパラメタ
max_tsr_row   = newsize[1]  #(900, 300)
max_tsr_col   = newsize[0]  #(900, 300)
# ストライド量
stride_tsr_row  = 5
stride_tsr_col  = 5
# RT法処理のサイズ
rtm_tsr_row   = 5
rtm_tsr_col   = 5
# RTベクトル長と信号空間長
max_jy_index  = 5*5
len_temp      = 2  # 右と左

# ---------------------------
# テンソル行列の処理(for)開始点のベクトルを生成
row_range, col_range = [], []
sum_row   = 0
while sum_row <= max_tsr_row-rtm_tsr_row:
    row_range.append(sum_row)
    sum_row  += stride_tsr_row
#print(row_range)    # len 60
# -----
sum_col   = 0
while sum_col <= max_tsr_col-rtm_tsr_col:
    col_range.append(sum_col)
    sum_col  += stride_tsr_col
#print(col_range)    # len 180

# ---------------------------
# 両目RT法によるマトリックスの生成
num_rows = len(row_range)
num_cols = len(col_range)
arr_row, arr_col = [], []
deyeY2_pool = []
# ------
cnt_row = 0
for row in row_range:
    cnt_col = 0
    for col in col_range:
        # ------
        # 単位空間の空間ベクトルを生成する
        tsr_tani_array = img_tensorC[row:row+rtm_tsr_row,col:col+rtm_tsr_col].flatten()
        #print(tsr_tani_array)
        # ------
        # 信号空間の空間マトリックスを生成する
        tsr_sigL = img_tensorL[row:row+rtm_tsr_row,col:col+rtm_tsr_col].flatten()
        tsr_sigR = img_tensorR[row:row+rtm_tsr_row,col:col+rtm_tsr_col].flatten()
        # -----
        tsr_sig_matrix = torch.stack([tsr_sigL, tsr_sigR])
        #print("----- tsr_sig_matrix -----")
        #print(tsr_sig_matrix)
        # ------
        # 両目法RTメトリックスを計算する
        deyeY2 = calc_deyeRTmet(len_temp, max_jy_index, tsr_sig_matrix, tsr_tani_array)
        #print(deyeY2)
        # ------
        # 信号空間の空間マトリックスを生成する
        arr_row.append(row)
        arr_col.append(col)
        deyeY2_pool.append(deyeY2)
        # ------
        # COUNT UP
        cnt_col = cnt_col + 1
    # ------
    # COUNT UP.append
    cnt_row = cnt_row + 1

# ---------------------------
# 結果のテキスト出力する
#print(arr_row)
#print(arr_row)
#print(deyeY2_pool)
mx_deyeY2 = np.array(deyeY2_pool).reshape([num_rows, num_cols])
tensor_deyeY2 = tensor(mx_deyeY2)
#print(tensor_deyeY2)

#=================================================
# MAIN PROGRAM(2) : 畳み込みメトリックス
#=================================================
# パラメタの設定
max_cnv_parts  = 8
# 画像サンプルのサイズ
max_sp_row     = 60
max_sp_col     = 180
# 畳み込み部品のサイズ
max_cnv_row    = 5
max_cnv_col    = 5
# ストライド量
stride_cnv_row = 5
stride_cnv_col = 5
# ------------------
nam_cnv_input = "基準用CSVデータ" 
code_cnv_input = ["NA"] * 8 # CSVコードの指定
code_cnv_input[0] = "bend1_cnv" # CSVコードの指定
code_cnv_input[1] = "bend2_cnv" # CSVコードの指定
code_cnv_input[2] = "bend3_cnv" # CSVコードの指定
code_cnv_input[3] = "bend4_cnv" # CSVコードの指定
code_cnv_input[4] = "line1_cnv" # CSVコードの指定
code_cnv_input[5] = "line2_cnv" # CSVコードの指定
code_cnv_input[6] = "datum1_cnv" # CSVコードの指定
code_cnv_input[7] = "datum2_cnv" # CSVコードの指定
#print("---- 入力:畳み込み用CSVファイル名 ----")
#print(code_cnv_input)
#print("-------------------------------")

# ------------------
# 畳み込み処理を実施する
for i in range(max_cnv_parts):
    # ---------------------------
    # CSVファイル(実験)情報を読み込み表示する
    # 畳み込みファイル
    file_cnv_input = foldername + code_cnv_input[i] + ".csv"  # ファイルパス名の生成 
    mx_conv = read_csvfile(file_cnv_input)
    if i == 0:    
        tensor_bend1 = tensor(mx_conv).float()
    elif i == 1:
        tensor_bend2 = tensor(mx_conv).float()
    elif i == 2:
        tensor_bend3 = tensor(mx_conv).float()
    elif i == 3:
        tensor_bend4 = tensor(mx_conv).float()
    elif i == 4:
        tensor_line1 = tensor(mx_conv).float()
    elif i == 5:
        tensor_line2 = tensor(mx_conv).float()
    elif i == 6:
        tensor_datum1 = tensor(mx_conv).float()
    elif i == 7:
        tensor_datum2 = tensor(mx_conv).float()
# ---------------------------
# カーネルの生成
signal_kernels  = torch.stack([tensor_bend1, tensor_bend2, tensor_bend3, tensor_bend4, tensor_line1, tensor_line2])
tani_kernel     = tensor_datum1 + tensor_datum2
# 結果の出力
#print(signal_kernels.shape)
#print("----- signal_kernels -----")
#print(signal_kernels)
#print("----- tani_kernel -----")
#print(tani_kernel)

# ---------------------------
# 画像の処理(for)開始点のベクトルを生成
row_range, col_range = [], []
sum_row   = 0
while sum_row <= max_sp_row-max_cnv_row:
    row_range.append(sum_row)
    sum_row  += stride_cnv_row
#print(row_range)
# -----
sum_col   = 0
while sum_col <= max_sp_col-max_cnv_col:
    col_range.append(sum_col)
    sum_col  += stride_cnv_col
#print(col_range)

# ---------------------------
# 単位空間用の畳み込み処理を実施する
kernel = tani_kernel
tani_timage = tensor([[apply_kernel(i,j,kernel, tensor_deyeY2) for j in col_range] for i in row_range])

# ------------------
# 信号空間用の畳み込み処理を実施する
for i in range(max_cnv_parts-2):
    # ---------------------------
    # CSVファイル(実験)情報を読み込み表示する
    kernel = signal_kernels[i]
    calc_conv = tensor([[apply_kernel(i,j,kernel, tensor_deyeY2) for j in col_range] for i in row_range])
    # -----
    if i == 0:    
        tsr_cvbend1 = tensor(calc_conv).float()
    elif i == 1:
        tsr_cvbend2 = tensor(calc_conv).float()
    elif i == 2:
        tsr_cvbend3 = tensor(calc_conv).float()
    elif i == 3:
        tsr_cvbend4 = tensor(calc_conv).float()
    elif i == 4:
        tsr_cvline1 = tensor(calc_conv).float()
    elif i == 5:
        tsr_cvline2 = tensor(calc_conv).float()
# ---------------------------
# 畳み込みテンソルイメージの生成  
signal_timages = torch.stack([tsr_cvbend1, tsr_cvbend2, tsr_cvbend3, tsr_cvbend4, tsr_cvline1, tsr_cvline2])
# 結果の出力
print(signal_timages.shape)     # torch.Size([6, 12, 36])
print("----- signal_timages[0] -----")
print(signal_timages[0])
print("----- tani_timage -----")
print(tani_timage)

#=================================================
# MAIN PROGRAM(3) : 畳み込みRTメトリックス
#=================================================
# テンソルイメージ処理のパラメタ
max_tsr_row   = 12
max_tsr_col   = 36
# ストライド量
stride_tsr_row  = 4
stride_tsr_col  = 4
# RT法処理のサイズ
rtm_tsr_row   = 4
rtm_tsr_col   = 4
# RTベクトル長と信号空間長
max_jy_index  = 4*4
len_temp      = 6

# ---------------------------
# テンソル行列の処理(for)開始点のベクトルを生成
row_range, col_range = [], []
sum_row   = 0
while sum_row <= max_tsr_row-rtm_tsr_row:
    row_range.append(sum_row)
    sum_row  += stride_tsr_row
#print(row_range)
# -----
sum_col   = 0
while sum_col <= max_tsr_col-rtm_tsr_col:
    col_range.append(sum_col)
    sum_col  += stride_tsr_col
#print(col_range)

# ---------------------------
# RT法によるプーリング計算
arr_row, arr_col = [], []
# ----
arr_btY1_p0 = []
arr_btY1_p1 = []
arr_btY1_p2 = []
arr_btY1_p3 = []
arr_btY1_p4 = []
arr_btY1_p5 = []
# ----
arr_Y2_p0 = []
arr_Y2_p1 = []
arr_Y2_p2 = []
arr_Y2_p3 = []
arr_Y2_p4 = []
arr_Y2_p5 = []
# ---
cnt_row = 0
for row in row_range:
    cnt_col = 0
    for col in col_range:
    
        # ------
        # 単位空間の空間ベクトルを生成する
        tsr_tani_array = tani_timage[row:row+rtm_tsr_row,col:col+rtm_tsr_col].flatten()
        print(tsr_tani_array)

        # ------
        # 信号空間の空間マトリックスを生成する
        temp_matrix = signal_timages[0]
        tsr_sig_p0 = temp_matrix[row:row+rtm_tsr_row,col:col+rtm_tsr_col].flatten()
        temp_matrix = signal_timages[1]
        tsr_sig_p1 = temp_matrix[row:row+rtm_tsr_row,col:col+rtm_tsr_col].flatten()
        temp_matrix = signal_timages[2]
        tsr_sig_p2 = temp_matrix[row:row+rtm_tsr_row,col:col+rtm_tsr_col].flatten()
        temp_matrix = signal_timages[3]
        tsr_sig_p3 = temp_matrix[row:row+rtm_tsr_row,col:col+rtm_tsr_col].flatten()
        temp_matrix = signal_timages[4]
        tsr_sig_p4 = temp_matrix[row:row+rtm_tsr_row,col:col+rtm_tsr_col].flatten()
        temp_matrix = signal_timages[5]
        tsr_sig_p5 = temp_matrix[row:row+rtm_tsr_row,col:col+rtm_tsr_col].flatten()
        # -----
        tsr_sig_matrix = torch.stack([tsr_sig_p0, tsr_sig_p1, tsr_sig_p2, tsr_sig_p3, tsr_sig_p4, tsr_sig_p5])
        #print("----- tsr_sig_matrix -----")
        #print(tsr_sig_matrix)
        # ------
        # RTメトリックスを計算する
        btY1_yarray, Y2_yarray = calc_RTmetrics(len_temp, max_jy_index, tsr_sig_matrix, tsr_tani_array)
        # ------
        # 各要素のベクトルを生成する
        arr_row.append(row)
        arr_col.append(col)
        # ---
        arr_btY1_p0.append(btY1_yarray[0])
        arr_btY1_p1.append(btY1_yarray[1])
        arr_btY1_p2.append(btY1_yarray[2])
        arr_btY1_p3.append(btY1_yarray[3])
        arr_btY1_p4.append(btY1_yarray[4])
        arr_btY1_p5.append(btY1_yarray[5])
        # ---
        arr_Y2_p0.append(Y2_yarray[0])
        arr_Y2_p1.append(Y2_yarray[1])
        arr_Y2_p2.append(Y2_yarray[2])
        arr_Y2_p3.append(Y2_yarray[3])
        arr_Y2_p4.append(Y2_yarray[4])
        arr_Y2_p5.append(Y2_yarray[5])
        # ------
        # COUNT UP
        #print(cnt_row, cnt_col)
        cnt_col = cnt_col + 1
    # ------
    # COUNT UP
    cnt_row = cnt_row + 1

# ---------------------------
# 結果のテキスト出力する
#print(arr_row)
#print(arr_row)
#print(arr_Y2_p0)

#=================================================
# READ CSV_FILE FUNCTION
#=================================================
# ファイルを読み込み表示する(相関逆行列)
def read_invcorr(file_readcsv): 
 
    # 相関逆行列ファイルの読み込み
    df = pd.read_csv(file_readcsv) 
    #print(df)
    # ------------------
    # 選択項目の読み込み
    # Xsマトリックス
    mx_Xs = df.loc[:,"0":"11"].values
    #print("----- mx_Xs -----")
    #print(mx_Xs)
  
    return mx_Xs

# ------------------
# ファイルを読み込み表示する(相関逆行列)
file_cnv_input = foldername + "RTm_invcorr.csv"  # ファイルパス名の生成 
cov_i = read_invcorr(file_cnv_input)
print(cov_i)
   
# ------------------
# ファイルを読み込み表示する(単位空間の中心)
def read_taniXs(file_readcsv): 
 
    # 単位空間の中心ファイルの読み込み
    df = pd.read_csv(file_readcsv) 
    #print(df)
    # ------------------
    # 選択項目の読み込み
    # Xsマトリックス
    mx_Xs = df.loc[:,"0":"11"].values
    #print("----- mx_Xs -----")
    #print(mx_Xs)
  
    return mx_Xs.flatten()

# ------------------
# ファイルを読み込み表示する(単位空間の中心)
file_cnv_input = foldername + "RTm_taniXs.csv"  # ファイルパス名の生成 
arr_Xs_tani = read_taniXs(file_cnv_input)
print(arr_Xs_tani)

#=================================================
# MAIN PROGRAM(3) : MAHARANOBIS　FEATURE　ENGINEERING
#=================================================
# マハラノビスマトリックスとグラフ作画準備
max_iRow_cells = 12
max_jCol_cells = 3*9
mx_Xs_sig      = np.zeros([max_iRow_cells, max_jCol_cells])
# ------
mx_Xs_sig[0]  = arr_btY1_p0
mx_Xs_sig[1]  = arr_btY1_p1
mx_Xs_sig[2]  = arr_btY1_p2
mx_Xs_sig[3]  = arr_btY1_p3
mx_Xs_sig[4]  = arr_btY1_p4
mx_Xs_sig[5]  = arr_btY1_p5
mx_Xs_sig[6]  = arr_Y2_p0
mx_Xs_sig[7]  = arr_Y2_p1
mx_Xs_sig[8]  = arr_Y2_p2
mx_Xs_sig[9]  = arr_Y2_p3
mx_Xs_sig[10] = arr_Y2_p4
mx_Xs_sig[11] = arr_Y2_p5
#print(mx_Xs_sig.shape)

# ------------------
# 2つの標本 [X_tani, X_sig] と [(mean)arr_X_tani] のマハラノビス距離を計算する
arr_d = []
for jCol in range(max_jCol_cells):
    d = distance.mahalanobis(mx_Xs_sig[:,jCol], arr_Xs_tani, cov_i)
    if d > 100: d = 100
    arr_d.append(round(d,4))
    #print("jCol:{}, マハラノビス距離の計算結果:{}".format(jCol,d))
# ------
print(arr_d)
mx_MHdist = np.reshape(np.array(arr_d), (3, 9))
print("---- mx_MHdist ----")
print(mx_MHdist)

# ------------------
# マハラノビス距離のマトリックスを作画する(信号空間)
arr_index   = list(range(3))
arr_columns = list(range(9))
df_maha = pd.DataFrame(mx_MHdist, index=arr_index, columns=arr_columns)
#print("---- df_maha ----")
#print(df_maha)

# ------------------
# ヒートマップへ出力(信号空間)
fig = plt.figure(figsize=(12, 5))
ax = fig.add_subplot(1, 1, 1)
ax.set_title("Maharanobis Distance(SIGNAL)")
sns.heatmap(df_maha, ax=ax, annot=True, cbar=True, fmt='.2f')
plt.show()

```

QEU:FOUNDER ： “まずは念のために、単位空間として使った画像の特徴量マップを見てみましょう。”

![image3-43-1](https://yaber1965.github.io/images/image3-43-1.jpg)

D先生 ： “片目メトリックスの場合とはかなり違いますね。コネクタの真ん中の部分の値が高くなります。もちろん、ワークの傾きや光の当たり方により微妙にかわりますが・・・。”

QEU:FOUNDER ： “次に、前回と同様に端子に色を塗りましたが、その特徴量を見てみましょう。”

![image3-43-2](https://yaber1965.github.io/images/image3-43-2.jpg)

D先生 ： “あれ？この**特徴量で色も見える**んじゃない？”

QEU:FOUNDER ： “現時点では断定できませんが、色の変化が小さな特徴量のシフトを引き起こしているように思います。”

D先生 ： “SVMの学習の前に、**ほかの端子抜け不良のモード**についても見てみませんか？”

QEU:FOUNDER ： “OK・・・。やってみましょう。”


## ～　まとめ　～

D先生 : “原発で成長か・・・。ちょっと驚きましたね。FOUNDERはもともと再稼働派でしょ？”

<iframe width="560" height="315" src="https://www.youtube.com/embed/fGx2FqYpFwM" ti-tle="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; en-crypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

QEU:FOUNDER ： “U国危機まではね・・・。さすがに、**原発が占拠された状態**を見た後では考え方をかえるよ。はぁ・・・。ただね、逆にこの話を思い出した。”

![image3-43-3](https://yaber1965.github.io/images/image3-43-3.jpg)

D先生 ： “これは2004年版ですね。これって、30年前にも出版しなかったっけ・・・。”

![image3-43-4](https://yaber1965.github.io/images/image3-43-4.jpg)

QEU:FOUNDER ： “なんか**「破滅が加速」**しているのがイヤだよね・・・。2004年版ではグラフにたくさんの線が描かれていますが、それは種々のシナリオが存在することを意味します。そして、グラフ下段の**「Welfare(福利)」は単位収入で手に入る幸福の指数**となっています。つまり、コストプッシュインフレの逆数だよね。”

D先生 ： “なんか、現状と一致しているようでイヤです・・・。でも、本の中の「このデータ（↓）」に興味がわきました。AWEAってアメリカ風工学会でしょ？”

![image3-43-5](https://yaber1965.github.io/images/image3-43-5.jpg)

QEU:FOUNDER ： “ほう・・・。D先生にそんな趣味が・・・。でも、**風力発電の発電コストは思ったよりも安い**よね。イメージと違っていておどろきました。”

![image3-43-6](https://yaber1965.github.io/images/image3-43-6.jpg)

D先生 ： “DマークやG国のコストが高いので、「再エネのコストが高い」と誤解しているが、どうやらちがうようです。現に、**A国も風力発電が普及しています**し・・・。”

![image3-43-7](https://yaber1965.github.io/images/image3-43-7.jpg)

QEU:FOUNDER ： “えっ？**A国の風力のシェアが7％なのに、J国が1.3％しかない**の？。”

<iframe width="560" height="315" src="https://www.youtube.com/embed/oxWi18bMzJs" ti-tle="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; en-crypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

D先生 ： “驚くでしょ？次回につづく・・・。”
