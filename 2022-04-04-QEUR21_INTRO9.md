## QEUR21_INTRO9:　NN’erのためのTM（その9）～超能力AIの開発(その3)

### ～　見た目は複雑になったが、実は考え方がシンプルになっている！　～

QEU:FOUNDER ： “じゃあ、これからが本題です。TTTNN(T法学習型ﾆｭｰﾗﾙﾈｯﾄﾜｰｸ: Training with T method Two for Neural Network)をやりましょう。TTTNNは「あてはめ」を2段階に分けます。第1段階はT法(2)を使い、それをもとにディープラーニングで予測します。”

![image1-9-1](https://yaber1965.github.io/images/image1-9-1.jpg)

D先生 ： “今風にいえば、名前はT3N2にしてもイケそうですね(笑)。私は分かっていますが、どうしてこのような「面倒」な方法を使うんですか？”

![image1-9-2](https://yaber1965.github.io/images/image1-9-2.jpg)

QEU:FOUNDER ： “いろいろな角度から説明ができます。NN’er側の説明として、「fast.aiのレッスン１」から引用しましょう。Jeremy Howardさんによると、プログラムを組むこととディープラーニングで学習することは同じです。・・・違うのはディープラーニングの場合にはデータから帰納的にプログラム（接続）生成するだけです。ただし、この方法で良好なプログラムを組む場合、「複雑なプログラムを組む場合には大量の学習データが必要」になります。D先生、今回の赤白ワインの品質予測の場合には複雑な疑似相関や交互作用があります。USIデータベースの6000件程度のデータでは足りている？”

D先生 ： “前回までの解析結果を見る限り、（データ量は）どうやら足りていないようです。ちゃんとやるには10万件ぐらいはいるんじゃないかねぇ・・・。”

![image1-9-3](https://yaber1965.github.io/images/image1-9-3.jpg)

QEU:FOUNDER ： “次に我々QEU側からみた説明です。QEU：ROUND2-1のテーマは「エネルギーの最小化」です。ディープラーニングは作業エネルギーは小さいが学習エネルギーが大きくなります。せっかく人間がいるのだから、DLのメリットと人間のもつ「演繹力」とコラボさせたい・・・。あともうひとつ・・・。”

D先生 ： “もうひとつあるんですか？”

QEU:FOUNDER ： “小生はTTTNNがT法の正当な後継手法であることを証明したい。”

D先生 ： “おっと、これは大きく出ましたね（笑）。”

![image1-9-4](https://yaber1965.github.io/images/image1-9-4.jpg)

QEU:FOUNDER ： “重回帰分析では学習データ全体の誤差の総和を最小とするから、赤い予測線は上下の点線の間を動きます。ここまでよいですか（理解できますか）？”

D先生 ： “いいですよ。重回帰分析は傾きと切片がアウトプットですからね。”

![image1-9-5](https://yaber1965.github.io/images/image1-9-5.jpg)

QEU:FOUNDER ： “一方、T法の場合には、予測線は単位空間を支点として回転します。これも、いいですね？”

D先生 ： “間違いありません。T法(2)には「切片に当たる」アウトプットはないですからね。”

![image1-9-6](https://yaber1965.github.io/images/image1-9-6.jpg)

QEU:FOUNDER ： “小生は「T法(2)は21世紀においても有数の大発明である」と思っています。この小生でも、T法(2)にはなんとも使いにくい部分というか不合理な部分があります。D先生、ここに示すグラフ（↑）のように計測値と真値が分布しています。このとき、T法をどのように使いたい？”

D先生 ： “あっちゃー！！これはきつい！これらを真値をまとめて1つの単位空間にするのは困る！！”

![image1-9-7](https://yaber1965.github.io/images/image1-9-7.jpg)

QEU:FOUNDER ： “じゃあ、考え方を切り換えてデータのもつ役割を見直しましょ。線形成分はT法、高次成分はディープラーニングに・・・。真値は単位空間にまとめず、信号空間にさせてT法にさせます。”

D先生 ： “なるほど・・・。TTTNNの適用で、どの程度の当てはめ向上の効果が出てくるか、興味が出てきますね。”


## ～　やってみる。どうなるか・・・　～

QEU:FOUNDER ： “データは今まで使用した（UCI-Kaggle）赤白ワインのDatasetを使います。そして、T法の情報は前回の解析結果を使います。いままでの説明につかれた(笑)。もう、プログラムにいこうか・・・。”

```python
# ---------------
# NN'erのためのタグチメソッド実験
# nn_tttnn_learn_batch.py
# 層別されたディープラーニングの第三段階です
# TTTNN(T法学習型ﾆｭｰﾗﾙﾈｯﾄﾜｰｸ: Training with T method Two for Neural Network)
# Kerasを使って、4層別 x 5つのデータセットのみを使った学習をやってみた
# ---------------
# import libraries
import math, random
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# --------------
# Import `Sequential` from `keras.models`
from keras.models import Sequential 
# Import `Dense` from `keras.layers`
from keras.layers import Dense

#=================================================
# difinition of function
#=================================================
# T2予測計算の関数定義
def func_prediction(len_signal, mx_Xs_norm):

    #print(mx_Xs_norm)

    # T法(2)の解析結果
    arr_items   = [1 ,2 ,4 ,10 ,11]
    #	        item1	item2	item4	item10	item11
    arr_beta    = [0.2558, -0.0321, -0.6173, 0.0487, 0.5521]
    arr_snr     = [0.0132, 0.0383, 0.0097, 0.054, 0.219 ]

    arr_pred    = np.zeros(len_signal)
    total_snr   = np.sum(arr_snr)

    for iRow in range(len_signal):
        temp_pred   = 0
        for jCol in range(len(arr_items)): 
            jCol_item   = arr_items[jCol]
            temp_pred   = temp_pred + arr_snr[jCol]/arr_beta[jCol]*mx_Xs_norm[iRow, jCol_item]
        arr_pred[iRow]  = temp_pred / total_snr

    return arr_pred

# --------------
# TTTNNのためのインプット
def func_tttnn_input(len_signal, mx_Xs_signal, arr_Y_signal):

    # --------------
    # データセット全体の単位空間情報
    arr_Xs_mean = np.array([0.654709, 8.678700, 0.310673, 0.444709, 4.607175, 0.071143, 23.181614, 74.816143, 0.996080, 3.222152, 0.682646, 11.029596])
    val_Y_mean  = 7.0

    # ノルム化
    mx_Xs_norm  = mx_Xs_signal - arr_Xs_mean
    arr_Y_norm  = arr_Y_signal - val_Y_mean
    #print(mx_Xs_norm)
    
    # -----
    # T法(2)で予測する
    arr_Y_pred  = func_prediction(len_signal, mx_Xs_norm)

    # [前回のアウトプット]T法(2)の解析結果
    # len_signal: 1447
    #	    item1	item2	item4	item10	item11
    #arr_beta = [ 0.2558 -0.0321 -0.6173  0.0487  0.5521]
    #arr_snr = [0.0132 0.0383 0.0097 0.054  0.219 ]

    # -----
    # 出力(y)のうち、予測(arr_Y_pred)分の値を削除する
    arr_Y_res   = np.zeros(len_signal)
    for iRow in range(len_signal):
        arr_Y_res[iRow]  = arr_Y_norm[iRow] - arr_Y_pred[iRow]

    return mx_Xs_norm, arr_Y_res

# --------------
# TTTNNのためのインプット
def func_output_tttnn(y_pred, len_signal, mx_Xs_norm, arr_Y_norm):

    # --------------
    # データセット全体の単位空間情報
    #arr_Xs_mean = np.array([0.654709, 8.678700, 0.310673, 0.444709, 4.607175, 0.071143, 23.181614, 74.816143, 0.996080, 3.222152, 0.682646, 11.029596])
    #val_Y_mean  = 7.0
    # ノルム化
    #mx_Xs_norm  = mx_Xs_signal - arr_Xs_mean
    #arr_Y_norm  = arr_Y_signal - val_Y_mean
    #print(mx_Xs_norm)    
    # -----
    # T法(2)で予測する
    arr_Y_pred  = func_prediction(len_signal, mx_Xs_norm)

    # [前回のアウトプット]T法(2)の解析結果
    # len_signal: 1447
    #	    item1	item2	item4	item10	item11
    #arr_beta = [ 0.2558 -0.0321 -0.6173  0.0487  0.5521]
    #arr_snr = [0.0132 0.0383 0.0097 0.054  0.219 ]
    # 出力(y)のうち、予測(arr_Y_pred)分の値を削除する
    with_Y_actual   = np.zeros(len_signal)
    with_y_pred     = np.zeros(len_signal)
    for iRow in range(len_signal):
        with_Y_actual[iRow] = arr_Y_norm[iRow] + arr_Y_pred[iRow]
        with_y_pred[iRow]   = y_pred[iRow] + arr_Y_pred[iRow]

    return with_y_pred, with_Y_actual

# --------------
# 履歴出力用の関数を設定する
def plot_history(history):
    hist = pd.DataFrame(history.history)
    hist['epoch'] = history.epoch
    # ----
    arr_epoch       = hist['epoch']
    arr_train_mae   = hist['mae']
    arr_vali_mae    = hist['val_mae']
    arr_train_mse   = hist['mse']
    arr_vali_mse    = hist['val_mse']

    # ----    
    fig = plt.figure(figsize=(12,6))
    ax1 = fig.add_subplot(1,2,1)
    ax1.plot(arr_epoch, arr_train_mae, label='Train Error')
    ax1.plot(arr_epoch, arr_vali_mae, label = 'Val Error')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Mean Abs Error')
    #ax1.ylim([3,5])
    ax1.legend()

    # ----    
    ax2 = fig.add_subplot(1,2,2)
    ax2.plot(arr_epoch, arr_train_mse, label='Train Error')
    ax2.plot(arr_epoch, arr_vali_mse, label = 'Val Error')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Mean Square Error')
    #plt.ylim([0,20])
    ax2.legend()
    fig.tight_layout()
    plt.show()

    return arr_epoch, arr_train_mse, arr_vali_mse 

# --------------
# SN比を計算する
def calc_snr(y_pred, y_actual):
    
    num_yy  = len(y_pred)
    arr_xx  = np.zeros(num_yy)
    arr_xy  = np.zeros(num_yy)
    res_yy  = np.zeros(num_yy)
    
    for i in range(num_yy):
        arr_xx[i]  = y_pred[i] * y_pred[i]
        arr_xy[i]  = y_pred[i] * y_actual[i]
    # ----
    # 感度を計算する
    val_beta    = np.sum(arr_xy)/np.sum(arr_xx)
    for i in range(num_yy):
        res_yy[i]  = (y_actual[i] - val_beta * y_pred[i])**2
    val_msd     = np.sum(res_yy)

    # ----
    # SN比を計算する
    val_snr     = val_beta**2 / val_msd

    return round(val_beta,6), round(val_msd,6), round(val_snr,4)

#=================================================
# Calculation class
#=================================================
# KerasのDLで機械学習を行う
class calc_optimization():

    def __init__(self):

        # --------------
        # Initialize the constructor
        self.model = Sequential()
         
        # Add an input layer(1)
        self.model.add(Dense(128, activation ='relu', input_shape =(12, )))
        # Add one hidden layer(2)
        self.model.add(Dense(128, activation ='relu'))
        # Add one hidden layer(3)
        self.model.add(Dense(128, activation ='relu'))
        # Add one hidden layer(4)
        self.model.add(Dense(128, activation ='relu'))
        # Add an output layer
        self.model.add(Dense(1))

        # Model output shape
        self.model.output_shape
         
        # Model summary
        self.model.summary()
         
        # Model config
        self.model.get_config()

        # --------------
        # 出力用配列の定義
        batch_epoch         = np.zeros(5)
        batch_train_mse     = np.zeros(5)
        batch_vali_mse      = np.zeros(5)
        batch_metrics_wo    = np.zeros([5,3])
        batch_with_metrics  = np.zeros([5,3])

        for i in range(5):  # 5

            # --------------
            file_csv_input = folder_input + arr_code_input[i]  # ファイルパス名の生成 
            print("入力用CSVファイル名 ：{0}".format(file_csv_input))

            # loading the data
            df = pd.read_csv(file_csv_input)

            # --------------
            # コラム名を変更する
            # 変更前：type, fixed acidity,volatile acidity,citric acid,residual sugar,chlorides,free sulfur di-oxide,
            #       total sulfur dioxide,density,pH,sulphates,alcohol  ,(quality)
            # 変更後：item0, 　item1      ,item2           ,item3      ,item4         ,item5    ,item6              
            #       item7               ,item8  ,item9 ,item10 ,item11 ,(quality)
            df2 = df.copy()
            df2.columns = ['item0','item1','item2','item3','item4','item5','item6','item7','item8','item9','item10','item11','quality','attr','attr2']
            #print(df2)

            # --------------
            # レコードを学習・検証用と最終評価用に分ける
            # 学習(training) -> 1
            # 検証(validation) -> 2
            # 評価(test) -> 3
            # --------------
            # トレーニング用のデータセット
            df_train    = df2[df2['attr2']==1]
            #print(df_train)

            num_df_train = len(df_train)
            print('num_df_train:',num_df_train)

            self.mx_Xs_train = df_train.loc[:,"item0":"item11"].values
            #print(self.mx_Xs_train)
            self.arr_Y_train = df_train.loc[:,"quality"].values
            #print(self.arr_Y_train)

            # TTTNNのためのインプット(Training)
            self.mx_Xs_train, self.arr_Y_train   = func_tttnn_input(num_df_train, self.mx_Xs_train, self.arr_Y_train)

            # --------------
            # 検証用のデータセット
            df_vali    = df2[df2['attr2']==2]
            #print(df_vali)

            num_df_vali = len(df_vali)
            print('num_df_vali:',num_df_vali)

            self.mx_Xs_vali = df_vali.loc[:,"item0":"item11"].values
            #print(self.mx_Xs_vali)
            self.arr_Y_vali = df_vali.loc[:,"quality"].values
            #print(self.arr_Y_vali)

            # TTTNNのためのインプット(Validation)
            self.mx_Xs_vali, self.arr_Y_vali   = func_tttnn_input(num_df_vali, self.mx_Xs_vali, self.arr_Y_vali)

            # --------------
            # 評価用のデータセット
            df_test    = df2[df2['attr2']==3]
            #print(df_test)

            self.num_df_test = len(df_test)
            print('num_df_test:',self.num_df_test)

            self.mx_Xs_test = df_test.loc[:,"item0":"item11"].values
            self.arr_type_test = df_test.loc[:,"item0"].values
            self.arr_Y_test = df_test.loc[:,"quality"].values

            # TTTNNのためのインプット(Test)
            self.mx_Xs_test, self.arr_Y_test   = func_tttnn_input(self.num_df_test, self.mx_Xs_test, self.arr_Y_test)

            # ----------------
            # データセットを処理する
            val_epoch, mean_train_mse, mean_vali_mse, arr_metrics_wo, arr_with_metrics = self.calc_dataset()
            # arr_metrics_wo    = [val_beta, val_msd, val_snr]
            # arr_with_metrics  = [val_beta, val_msd, val_snr]
 
            # --------------
            # バッチ配列への入力
            batch_epoch[i]     = val_epoch
            batch_train_mse[i] = mean_train_mse
            batch_vali_mse[i]  = mean_vali_mse
            batch_metrics_wo[i,:]   = arr_metrics_wo
            batch_with_metrics[i,:] = arr_with_metrics

        # --------------
        # バッチ配列への入力
        mx_epoch        = np.array([batch_epoch]).T
        mx_train_mse    = np.array([batch_train_mse]).T
        mx_vali_mse     = np.array([batch_vali_mse]).T
        mx_metrics_wo   = np.array(batch_metrics_wo)
        mx_with_metrics = np.array(batch_with_metrics)

        # ----------------
        # 解析結果をCSVファイルに保存する
        mx_output    = np.concatenate([mx_epoch, mx_train_mse, mx_vali_mse, mx_metrics_wo, mx_with_metrics], axis=1)
        print(mx_output)
        self.save_csvout(mx_output)

    # ----------------
    # データセットを処理する
    def calc_dataset(self):
    
        # --------------
        # トレーニング用のデータセット
        #self.mx_Xs_train = df_train.loc[:,"item0":"item11"]
        #self.arr_Y_train = df_train.loc[:,"quality"]
        # 検証用のデータセット
        #self.mx_Xs_vali = df_vali.loc[:,"item0":"item11"]
        #self.arr_Y_vali = df_vali.loc[:,"quality"]
        # --------------
        # List all weight tensors
        self.model.get_weights()
        self.model.compile(loss ='mse', optimizer ='adam', metrics=['mae', 'mse'])

        # Training Model
        history = self.model.fit(self.mx_Xs_train, self.arr_Y_train, validation_data=(self.mx_Xs_vali, self.arr_Y_vali),
                    epochs = num_EPOCH, batch_size = 1, verbose = 1)
          
        # Predicting the Value
        y_pred = self.model.predict(self.mx_Xs_test).flatten()
        #print(y_pred)

        # ----------------
        # 学習履歴を出力する
        arr_epoch, arr_train_mse, arr_vali_mse = plot_history(history)

        # 代表値を引き渡す
        val_epoch       = round(arr_epoch[num_EPOCH-1],4)
        mean_train_mse  = round(np.mean(arr_train_mse[num_EPOCH-5:num_EPOCH-1]),4)
        mean_vali_mse   = round(np.mean(arr_vali_mse[num_EPOCH-5:num_EPOCH-1]),4)
        
        # ----------------
        # T法(2)補正を含まない
        # 正確度を散布図で作画する
        add_comment = "without T2m correction(before)"
        self.plot_stratification(y_pred, self.num_df_test, self.arr_Y_test, self.arr_type_test, add_comment)

        # 感度とSN比を計算する
        val_beta, val_msd, val_snr = calc_snr(y_pred, self.arr_Y_test)
        #print("log_beta:{}, log_snr:{}".format(log_beta, log_snr))
        print("--- metrics {} ---".format(add_comment))
        print("val_epoch:{}, mean_train_mse:{}, mean_vali_mse:{}".format(val_epoch, mean_train_mse, mean_vali_mse))
        print("val_beta:{}, val_msd:{}, val_snr:{}".format(val_beta, val_msd, val_snr))
        arr_metrics_wo    = [val_beta, val_msd, val_snr]

        # ----------------
        # T法(2)補正を含む
        # TTTNNのためのアウトプット(Test)
        with_y_pred, self.arr_Y_test   = func_output_tttnn(y_pred, self.num_df_test, self.mx_Xs_test, self.arr_Y_test)
        
        # 正確度を散布図で作画する
        add_comment = "with T2m correction(after)"
        self.plot_stratification(with_y_pred, self.num_df_test, self.arr_Y_test, self.arr_type_test, add_comment)

        # 感度とSN比を計算する
        val_beta, val_msd, val_snr = calc_snr(with_y_pred, self.arr_Y_test)
        #print("log_beta:{}, log_snr:{}".format(log_beta, log_snr))
        print("--- metrics {} ---".format(add_comment))
        print("val_epoch:{}, mean_train_mse:{}, mean_vali_mse:{}".format(val_epoch, mean_train_mse, mean_vali_mse))
        print("val_beta:{}, val_msd:{}, val_snr:{}".format(val_beta, val_msd, val_snr))
        arr_with_metrics      = [val_beta, val_msd, val_snr]

        return val_epoch, mean_train_mse, mean_vali_mse, arr_metrics_wo, arr_with_metrics

    # ----------------
    # 正確度を「赤白層別により」散布図で作画する
    def plot_stratification(self, y_pred, num_df_test, arr_Y_test, arr_type_test, add_comment):

        # 層別の基準
        # type : 0 →　赤ワイン
        # type : 1 →　白ワイン
        arr_P_red   = []
        arr_Y_red   = []
        arr_P_white = []
        arr_Y_white = []
        for i in range(num_df_test):
            if arr_type_test[i] == 0:
                arr_P_red.append(y_pred[i])
                arr_Y_red.append(arr_Y_test[i]+random.random())
            else:
                arr_P_white.append(y_pred[i])
                arr_Y_white.append(arr_Y_test[i]+random.random())

        # 予測精度を確認する
        fig2 = plt.figure(figsize=(8,5))

        # 散布図の作画
        ax3 = fig2.add_subplot(1,1,1)
        ax3.scatter(arr_P_red, arr_Y_red, color="red", label="red")
        ax3.scatter(arr_P_white, arr_Y_white, color="blue", label="white")
        ax3.set_title('accuracy between pred and actual {}'.format(add_comment), fontsize=16)
        ax3.set_xlabel('Prediction')
        ax3.set_ylabel('Actual')
        ax3.legend(loc='upper left', fontsize=10)
        fig2.tight_layout()
        plt.show()

    # ----------------
    # 解析結果をCSVファイルに保存する
    def save_csvout(self, mx_output): 

        # ----------------
        # データフレームを作成
        arr_columns = ["epoch","train_mse","vali_mse","beta_wo","msd_wo","snr_wo","w_beta","w_msd","w_snr"]

        # 解析結果をCSVファイルに保存する
        df_csvout   = pd.DataFrame(mx_output, columns=arr_columns)

        # ----------------
        df_csvout.to_csv(file_csvout, index=False)

#=================================================
# main function            
#=================================================
if __name__  == '__main__':

    # ---------------------------
    # フォルダ指定
    folder_input    = "./"  # My project folder
    folder_csvout   = "./"  # My project folder

    # ---------------------------
    # リストを初期化する
    arr_code_input  = ['NA']*5

    # ---------------------------
    # EPOCHの定義
    num_EPOCH       = 100

    # ---------------------------
    # 機械学習用のCSVファイルを定義する
    nam_csv_input       = "機械学習のCSVデータ" 
    arr_code_input[0]   = "train_wineq_train1.csv" # CSVコードの指定
    arr_code_input[1]   = "train_wineq_train2.csv" # CSVコードの指定
    arr_code_input[2]   = "train_wineq_train3.csv" # CSVコードの指定
    arr_code_input[3]   = "train_wineq_train4.csv" # CSVコードの指定
    arr_code_input[4]   = "train_wineq_train5.csv" # CSVコードの指定
    #print(arr_code_input)

    # ---------------------------
    # 出力用のCSVファイルを定義する
    nam_csvout  = "出力用CSVデータ" 
    code_csvout = "metrics_TTTNN_node128x2_epoch50.csv" # CSVコードの指定
    file_csvout = folder_csvout + code_csvout  # ファイルパス名の生成
    print("------------ 計測データ出力用のCSV名 -------------")   
    print("出力用CSVファイル名 ：{0}".format(file_csvout))

    # ---------------------------
    # 機械学習を行う
    calc_optimization()

```

QEU:FOUNDER ： “それでは予測値のバラツキ具合をTTTNNと従来の手法の間で比較しましょう。”

### (従来の手法：NNのみ)
![image1-9-8](https://yaber1965.github.io/images/image1-9-8.jpg)

### (新しい手法：TTTNN)
![image1-9-9](https://yaber1965.github.io/images/image1-9-9.jpg)

D先生 ： “う～ん・・・、これは微妙な差ですね。客観的に評価したいのでメトリックス化できませんか？”

QEU:FOUNDER ： “じゃあ、静特性と動特性のSN比で比較してみましょう。”

![image1-9-10](https://yaber1965.github.io/images/image1-9-10.jpg)

D先生 ： “やっぱり動特性SN比では差が出なくて、静特性で差が出てきましたか・・・。”

QEU:FOUNDER ： “TTTNNって、おもしろいでしょ？”

D先生 ： “TTTNNの当てはめがうまく行ったとして、これで「超能力AI」ができるんですか？”

### （内側構造）　～　（外側構造）

__ロバスト因子（item3,5）　～　g( [ XCs:回帰因子群] x [XBｓ：交互作用因子群] )__

QEU:FOUNDER ： “多分、以前考えていたよりも簡単になると思うよ・・・。今回の近似で十分かどうかは分からないが、やってみましょうか・・・。”


## ～　まとめ　～

### ・・・　ちょっと以前のブログに戻って、（それからの）つづきです　・・・

C部長 : “J国はCobotへのケアがなされていないなど、「ロボット後進国化」している。D先生の意見は、こういう考え方でいいんですか？”

![image1-9-11](https://yaber1965.github.io/images/image1-9-11.jpg)

D先生 ： “ロボットの定義次第じゃないかなァ・・・。FOUNDERは、このロボット（↓）をどう思います？”

<iframe width="560" height="315" src="https://www.youtube.com/embed/nk0RYtEyIbo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

QEU:FOUNDER ： “これは立派にロボットと言えるんじゃない？実際のところ、FOXC〇〇社の言っているロボットって、これに毛の生えたものが大半だろうし・・・。ちょっと、「お上」が生真面目に考えすぎというか・・・。”

D先生 ： “・・・というか、ただ単にロボットに対する「民主化」と「りた（て）らしー」のレベルが・・・。”

![image1-9-12](https://yaber1965.github.io/images/image1-9-12.jpg)

QEU:FOUNDER ： “ビルの清掃マシンなんか、海外では普通にうごいているよ。ほら・・・、この前に撮ってきた・・・。”

[動画（関連ブログを参照）](https://jpnqeur21intro.blogspot.com/2022/02/qeur21intro9nnertm9ai3.html)

C部長 : “昔、故本田宗一郎が「治具が大事」といっていました。そのジグがロボットに変わっただけ・・・？”

QEU:FOUNDER ： “そんなモン・・・、難しく考えることない・・・・。ちなみに、ディープラーニングも難しくない。我々の取り組みのレベルを見ればわかるでしょ？”

C部長 : “そりゃそうだ・・・（笑）。”

D先生 ： “1990年代から「高度なモノだけ自分で作って、ボリュームゾーンは他の国でつくる」という「無意味な重点指向」が（J国の経済）非常事態を招いたんです。「ピラミッドみたいに底面が大きいと頂点が高くなる」、これは当たり前のクラッカー・・・。J国の30年の歴史は「ピラミッドの底面を削る歴史」です。そのうち、J国には「食い物しか売り物」がなくなるよ・・・。”

C部長 : “取り合えず、食べ物はおいしいヨ・・・。”

![image1-9-13](https://yaber1965.github.io/images/image1-9-13.jpg)

D先生 ： “でもね・・・。T〇Pとかいう枠組みで自動車を優遇するかわりに農業をぎゃく待したんでしょ？その割には、関税撤廃の時期が遅いことと、ＥＶ化の流れでメリットを享受できないという・・・。”

<iframe width="560" height="315" src="https://www.youtube.com/embed/VkfKGpRDCcY" ti-tle="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; en-crypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

QEU:FOUNDER ： “へへへ・・・。実は意外と食い物も大したことがないんじゃない？これはメディアの問題だが、Ｊ国メディアさんも食い物の撮り方をイチから勉強したら（笑）？”

