## QEUR21_INTRO20:　Optimization for coders（その1）～Computational Approachのイントロダクション

### ～　PYTHONで楽にやりましょうよ、らくに・・・　～

D先生 ： “さあ、QEUシステムにおける最適化、Computational Approach(CA)をやりましょう。”

QEU:FOUNDER ： “いや・・・、この名前を変えていい？**「Optimization for coders」**にしたい。高等な数学知識もいらない。高価なコンピューターもいらない。タグチメソッドなんか全～然知らなくていい（笑）。ただプログラミングを少しだけ知っていればよい。”

![image1-20-1](https://yaber1965.github.io/images/image1-20-1.jpg)

D先生 ： “へっ・・・、なにそれ・・・？”

QEU:FOUNDER ： “これから我々が行う実験はすべてPythonコード上で行われます。そこで「fast.ai」に倣って、「Optimization for coders」と命名したいんです。”

![image1-20-2](https://yaber1965.github.io/images/image1-20-2.jpg)

QEU:FOUNDER ： “まあ、これは冗談だけど・・・(笑)。CAの処理スキームは以下の通りだが、ほとんどのデータ処理はCode（プログラム）内で行われます。”

![image1-20-3](https://yaber1965.github.io/images/image1-20-3.jpg)

D先生 ： “あれ？フローチャートには、いきなり「望大か望小」という言葉があります。望大(望小)SN比を使うんですか？”

QEU:FOUNDER ： “いや・・・、それら（望大SN比etc）は使いません。繰り返し計算を2か所で行います。図中の赤と青の2種類の「Feedback」がポイントです。赤色の「Feedback」は（自動化はできないことはないが）手作業と主とし、青色のそれはPYTHONのプログラムで自動化されています。”

D先生 ： “プログラムでは、どんな繰り返し計算（Computational Approach）をするんですか？”

![image1-20-4](https://yaber1965.github.io/images/image1-20-4.jpg)

QEU:FOUNDER ： “計測したデータをもとに、単位空間を順次入れ換えて「あるテクノメトリックス」を生成します。これからは事例で説明したほうがいいよね・・・。今回のデータは望小特性をもった、このデータ（↑）にしましょう。”

![image1-20-5](https://yaber1965.github.io/images/image1-20-5.jpg)

D先生 ： “あぁ・・・、この「おススメ本」(↑)からの引用ですね。もし、これから使うツールがEXCELでなくPYTHONでなければ私としては爆上げ推薦をしたいところです。”

QEU:FOUNDER ： “D先生・・・、pythonを勉強しないと時代から取り残されますよ。なにはともあれ、これからプログラムを作って動かしてみましょう。”


```python
# ---------------------------
# T法を使った最適化実験
# comp_app_Lower_isB(sono2).py
# Cumputational Approach(計算繰り返しによる最適化)実験
# 望小特性で予備実験をします（まだCAじゃない）
# ---------------------------
# import libraries
import math
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

# ---------------------------
# T2メトリックス計算の関数定義
def calc_metricsT2m(len_items, mx_Xs_norm, arr_Y_norm):
    # -----
    # データ長さの設定
    len_signal  = len(arr_Y_norm)
    # 感度とSN比
    arr_beta    = np.zeros(len_items)
    arr_snr     = np.zeros(len_items)
    
    # -----
    # 有効除数の計算
    yuko = 0.0
    for iRow in range(len_signal):
        yuko += float(arr_Y_norm[iRow]) ** 2
    # print('有効除数=:{0:.4f}'.format(yuko))
    
    # -----
    if yuko > 0.0:
    
        for jCol in range(len_items):
    
            # -----
            # AVE_Y1とAVE_Y2を計算する
            # 線形式の計算
            sum_array = 0.0
            for iRow in range(len_signal):
                sum_array += float(arr_Y_norm[iRow]) * mx_Xs_norm[iRow][jCol]
            # print('配列ix={0},jy={1}の合計値{2}'.format(iRow,iRow,sum_array))
            lnr_yvalue = sum_array
            beta_yvalue = sum_array / float(yuko)
            # print('レコードix={0}の線形式：{1}'.format(iRow,lnr_yvalue[0:5]))
            # print('レコードix={0}の感度：{1}'.format(iRow,beta_yvalue[0:5]))
            # -----
            # 全変動ST及び各種中間指標SB,SE,VE,η
            sum_array = 0.0
            for iRow in range(len_signal):
                sum_array += float(mx_Xs_norm[iRow][jCol]) ** 2
                # print('配列i={0},jy={1}の合計値{2}'.format(iRow,iRow,sum_array))
            st_yvalue = sum_array
            sb_yvalue = lnr_yvalue ** 2 / float(yuko)
            se_yvalue = st_yvalue - sb_yvalue
            # -----
            ve_yvalue = se_yvalue / float(len_signal - 1.0)
            # print('レコードix={0}の比例項変動：{1}'.format(iRow,sb_yvalue[0:5]))
            # print('レコードix={0}の感度：{1}'.format(iRow,beta_yvalue[0:5]))
            # -----
            # 代入
            arr_beta[jCol]    = round(beta_yvalue, 4)
            arr_snr[jCol]     = round(sb_yvalue / se_yvalue, 4)
    
        return len_signal, arr_beta, arr_snr

    else:
        # -----
        # 異常処理
        return len_signal, [0], [0]

# ---------------------------
# SN比(望小)を計算する
def calc_snr(y_actual):
    
    num_yy  = len(y_actual)
    snr_sum = 0
    for i in range(num_yy):
        snr_sum  = snr_sum + y_actual[i]**2
    snr_sum  = snr_sum / float(num_yy)
    snr_log  = -1*math.log10(snr_sum)

    return round(snr_log ,6)

# ---------------------------
# フォルダ指定
folder_input    = "./"  # My project folder

# ---------------------------
# 機械学習用のCSVファイルを定義する(1)
nam_csv_input    = "制御側ののCSVデータ" 
nam_code_input   = "lower_is_better.csv" # CSVコードの指定
file_csv_input = folder_input + nam_code_input  # ファイルパス名の生成 
print("入力用CSVファイル名 ：{0}".format(file_csv_input))

# loading the data
df1 = pd.read_csv(file_csv_input)
#print('--- dataset ---')
#print(df1)

mx_Xs       	= df1.loc[:,"A":"G2"].values
mx_Ys       	= df1.loc[:,"N1":"N4"].values
arr_vSNR    	= df1.loc[:,"SNR"].values
arr_mean    	= df1.loc[:,"SNR"].values
index_maxsnr    = np.argmax(arr_snr)

# ---------------------------
# Computational Approachの実行
def calc_CA(numb_tani):

    # ----------------
    # 単位空間を形成する
    df_tani = df1[df1["NO"]==numb_tani]
    arr_Xs_tani   = df_tani.loc[:,"A":"G2"].values.flatten()
    arr_Ys_tani   = df_tani.loc[:,"N1":"N4"].values.flatten()
    val_Ys_tani   = arr_Ys_tani[0]
    print("arr_Xs_tani:{}, arr_Ys_tani:{}, val_Ys_tani:{}".format(arr_Xs_tani, arr_Ys_tani, val_Ys_tani))
    val_snr_tani     = df_tani.loc[:,"SNR"].values.flatten()
    val_mean_tani    = df_tani.loc[:,"MEAN"].values.flatten()
    #print("val_snr_tani:{}, val_mean_tani:{}".format(val_snr_tani[0], val_mean_tani[0]))

    # ---------------------------
    # 信号空間を形成する
    df_signal = df1[df1["NO"]!=numb_tani]
    #print(df_signal)

    mx_Xs_signal    = df_signal.loc[:,"A":"G2"].values
    mx_Ys_signal    = df_signal.loc[:,"N1":"N4"].values
    arr_snr_signal  = df_signal.loc[:,"SNR"].values
    arr_mean_signal = df_signal.loc[:,"SNR"].values

    # ---------------------------
    # ノルム計算
    mx_Xs_norm      = mx_Xs_signal - arr_Xs_tani
    arr_snr_norm  = arr_snr_signal - val_snr_tani
    #print("arr_snr_norm:",arr_snr_norm)
    arr_Ys_norm_N1  = df_signal.loc[:,"N1"].values - val_Ys_tani
    arr_Ys_norm_N2  = df_signal.loc[:,"N2"].values - val_Ys_tani
    arr_Ys_norm_N3  = df_signal.loc[:,"N3"].values - val_Ys_tani
    arr_Ys_norm_N4  = df_signal.loc[:,"N4"].values - val_Ys_tani

    # ---------------------------
    # T2メトリックス計算
    # SN比の場合
    len_signal, arr_betaT2m, arr_snrT2m = calc_metricsT2m(len_items, mx_Xs_norm, arr_snr_norm)
    val_sumsnr  = round(np.sum(arr_snrT2m),4)
    print("arr_betaA:",arr_betaT2m)
    print("arr_snrA:",arr_snrT2m)
    print("numb_tani:{}, 全有効SN比:{}".format(numb_tani, val_sumsnr))

    # 出力(N1)の場合
    len_signal, arr_beta_N1, arr_snr_N1 = calc_metricsT2m(len_items, mx_Xs_norm, arr_Ys_norm_N1)
    val_sumN1  = round(np.sum(arr_snr_N1),4)
    print("arr_beta_N1:",arr_beta_N1)
    print("arr_snr_N1:",arr_snr_N1)
    print("numb_tani:{}, 全有効SN比:{}".format(numb_tani, val_sumN1))

    # 出力(N2)の場合
    len_signal, arr_beta_N2, arr_snr_N2 = calc_metricsT2m(len_items, mx_Xs_norm, arr_Ys_norm_N2)
    val_sumN2   = round(np.sum(arr_snr_N2),4)

    # 出力(N3)の場合
    len_signal, arr_beta_N3, arr_snr_N3 = calc_metricsT2m(len_items, mx_Xs_norm, arr_Ys_norm_N3)
    val_sumN3   = round(np.sum(arr_snr_N3),4)

    # 出力(N4)の場合
    len_signal, arr_beta_N4, arr_snr_N4 = calc_metricsT2m(len_items, mx_Xs_norm, arr_Ys_norm_N4)
    val_sumN4   = round(np.sum(arr_snr_N4),4)

    return val_sumsnr, val_sumN1, val_sumN2, val_sumN3, val_sumN4, arr_betaT2m, arr_snrT2m

# ---------------------------
# 初期化
len_items   = 13
mx_t2m_beta = np.zeros([18,len_items])
mx_t2m_snr  = np.zeros([18,len_items])

# ---------------------------
# Computational Approachの実行
arr_no      = []
arr_sumsnr  = []
arr_sumN1   = []
arr_sumN2   = []
arr_sumN3   = []
arr_sumN4   = []
icount      = 0
for numb_tani in range(1,19):
    print("++++++++++++++++++ NO:{} ++++++++++++++++++".format(numb_tani))
    val_sumsnr, val_sumN1, val_sumN2, val_sumN3, val_sumN4, arr_betaT2m, arr_snrT2m = calc_CA(numb_tani)
    # ---
    mx_t2m_beta[icount ,:] = arr_betaT2m
    mx_t2m_snr[icount ,:]  = arr_snrT2m
    # ---
    arr_no.append(numb_tani)
    arr_sumsnr.append(val_sumsnr)
    arr_sumN1.append(val_sumN1)
    arr_sumN2.append(val_sumN2)
    arr_sumN3.append(val_sumN3)
    arr_sumN4.append(val_sumN4)
    icount  = icount + 1
# ----------------
# 出力用マトリックスへの入力
print("--- mx_t2m_beta ---")
print(mx_t2m_beta)
print("--- mx_t2m_snr ---")
print(mx_t2m_snr)
mx_vSNR     = np.array([arr_vSNR]).T

# ----------------
# 解析結果をCSVファイルに保存する
mx_output1  = np.concatenate([mx_t2m_beta, mx_t2m_snr, mx_vSNR], axis=1)
print(mx_output1)

# ----------------
# データフレームを作成
arr_columns1 = ["b_A","b_B1","b_B1","b_C1","b_C2","b_D1","b_D2","b_E1","b_E2","b_F1","b_F2","b_G1","b_G2"]
arr_columns2 = ["s_A","s_B1","s_B1","s_C1","s_C2","s_D1","s_D2","s_E1","s_E2","s_F1","s_F2","s_G1","s_G2","SNR"]
arr_columns  = arr_columns1 + arr_columns2

# ----------------
# 解析結果をCSVファイルに保存する
df_csvout1   = pd.DataFrame(mx_output1, columns=arr_columns)
print(df_csvout1)
#df_csvout1.to_csv("./t2m_coef_output1.csv", index=False)

# ----------------
# 全有効項目SN比のプロット
fig = plt.figure(figsize=(8,5))

# 散布図の作画
ax1 = fig.add_subplot(1,1,1)
ax1.plot(arr_no, arr_sumsnr, color="red", label="SN-Ratio")
ax1.plot(arr_no, arr_sumN1, color="blue", label="Noise-N1")
ax1.plot(arr_no, arr_sumN2, color="green", label="Noise-N2")
ax1.plot(arr_no, arr_sumN3, color="yellow", label="Noise-N3")
ax1.plot(arr_no, arr_sumN4, color="orange", label="Noise-N4")
ax1.set_title('Meaning of Total Effective SNR', fontsize=16)
ax1.set_xlabel('Experiment Number')
ax1.set_ylabel('Total Effective SN Ratio')
ax1.set_xlim(left=1, right=18)  # x範囲
ax1.legend(loc='upper left', fontsize=10)
fig.tight_layout()
plt.show()

# ----------------
# 望小SN比のプロット
fig2 = plt.figure(figsize=(8,5))

# 散布図の作画
ax1 = fig2.add_subplot(1,1,1)
ax1.plot(arr_no, arr_snr, color="red", label="SN-Ratio")
ax1.set_title('SNR', fontsize=16)
ax1.set_xlabel('Experiment Number')
ax1.set_ylabel('SN Ratio')
ax1.set_xlim(left=1, right=18)  # x範囲
ax1.legend(loc='upper left', fontsize=10)
fig2.tight_layout()
plt.show()

# ----------------
# 出力用マトリックスへの入力
mx_vSNR     = np.array([arr_vSNR]).T
mx_sumsnr   = np.array([arr_sumsnr]).T
mx_sumN1    = np.array([arr_sumN1]).T
mx_sumN2    = np.array([arr_sumN2]).T
mx_sumN3    = np.array([arr_sumN3]).T
mx_sumN4    = np.array([arr_sumN4]).T

# ----------------
# 解析結果をCSVファイルに保存する
mx_output2    = np.concatenate([mx_Xs, mx_vSNR, mx_sumsnr, mx_sumN1, mx_sumN2, mx_sumN3, mx_sumN4], axis=1)
print(mx_output2)

# ----------------
# データフレームを作成
arr_columns = ["A","B1","B1","C1","C2","D1","D2","E1","E2","F1","F2","G1","G2","SNR","siSR","srN1","srN2","srN3","srN4"]

# ----------------
# 解析結果をCSVファイルに保存する
df_csvout2   = pd.DataFrame(mx_output2, columns=arr_columns)
df_csvout2.to_csv("./optimization_output2.csv", index=False)

```

QEU:FOUNDER ： “まずは、このような（↓）CSVファイルが出力されます。ポイントは全有効（項目）SN比です。”

![image1-20-6](https://yaber1965.github.io/images/image1-20-6.jpg)

D先生 ： “全有効SN比というテクノメトリックス・・・。”

![image1-20-7](https://yaber1965.github.io/images/image1-20-7.jpg)

QEU:FOUNDER ： “T法の推定式の分母がCA特有のテクノメトリックスである「全有効（項目）SN比」です。この値の大きさが推定式の「当てはまりの良さ」を示します。そして、単位空間が種々動きまわって実験毎のテクノメトリックスが比較されます。例えば、この図（↓）は左上のグラフは各実験(条件)の全有効（項目）SN比の動きです。T法の応答変数を望小SN比にしてみたり、各誤差因子の出力（N1～N4）に変えています。一方、右下のグラフは各実験で得られた望小SN比の値です。”

![image1-20-8](https://yaber1965.github.io/images/image1-20-8.jpg)

D先生 ： “この図（↑）、なんか面白そうだけど、わかりにくいです・・・。実験6と実験15が面白い動きをしているということがわかるだけで・・・。”

QEU:FOUNDER ： “それでは、このデータをもとに散布図を取ってみましょう。横(X)軸が実験で得られた望小SN比の値で、縦(Y)軸がT法で計算した全有効（項目）SN比の値です。これを見て、ちょっと「腰を抜かさない」？”

![image1-20-9](https://yaber1965.github.io/images/image1-20-9.jpg)

D先生 ： “そりゃあもう・・・、いきなり「損失関数（放物線）」がでてきて驚きました。そうか、タグチ先生はT法を考案したとき、こういっていました。「単位空間をデータ群内のバラツキの中間にいれると予測精度があがるよ」って・・・。”

QEU:FOUNDER ： “多分、そういうことなんだろうね・・・。でも、T法に入力する応答変数（Y）をテクノメトリックスではなく生データにすると全く違った傾向になるんだよね。この傾向を見ると、N1～N4の計測値を使うと、全有効SN比が小さい実験では望小SN比が高くなりそうです。”

D先生 ： “ここらへんの理解を踏まえて、**「望小実験」**をしてみましょう。”


## ～　まとめ　～

### ・・・　CAは従来のパラメタ設計とは考え方が正反対　・・・

QEU:FOUNDER ： “小生は改めて問いたい、Computational Approach(CA)はなぜ必要かを・・・。”

D先生 : “この問いに対する答えは簡単です、パラメタの最適化作業を楽にしたいだけです。そもそも、タグチメソッドはプロセスの因果関係を内側直交表と外側直交表で評価すると簡単になることから発展しました。”

![image1-20-10](https://yaber1965.github.io/images/image1-20-10.jpg)

QEU:FOUNDER ： “最近では、直交表のかわりに「シャイニン法」とか、内側直交表を簡単にする試みがあります。さらにCS-T法では直交表がT法にかわりました。そして、最適化をさらに簡単にするには・・・？”

D先生 : “えっ？これ以上、最適化が簡単になるの・・・？”

QEU:FOUNDER ： “外側直交表のテクノメトリックスもやめちゃう！！”

![image1-20-11](https://yaber1965.github.io/images/image1-20-11.jpg)

D先生 ： “・・・でも、誤差因子のテクノメトリックスがなくなって、実験の負担が少なくなるのかなぁ・・・。”

QEU:FOUNDER ： “いやいや・・・。D先生の慧眼には参った。その見解は半分は当たっています。・・・でも、この議論は「製品(技術)開発の場合」と「プロセス開発の場合」に分けたほうがいいです。製品開発の場合、内側直交表側の実験条件がコスト増につながります。そして、誤差因子が「ストレステスト」になる場合には外側直交表の構築にはコストがあまりかかりません。一方、プロセス開発の場合には誤差因子を変えるのに「より大きなコストがかかる」んです。ある場合を除いて・・・。”

D先生 ： “「ある場合」って・・・？”

QEU:FOUNDER ： “プロセス開発の場合、**「製造バッチこそが究極の誤差因子」**だからね・・・。これから始まる「CAによるプロセス技術開発」を理解するにあたって、便宜的に「誤差因子とは製造バッチである」と考えてほしいんだ・・・。”

