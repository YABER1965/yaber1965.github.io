## QEUR21_RL2048P3:　RTメトリックスの最適化 (その3)

## ～　理屈上は「新RT法」はイケている　～

D先生 ： “じゃあ、いよいよ新RT法の開発に入りましょうか・・・。要するにRT法のY2メトリックスをマンハッタン距離に変えるということでしょう？”

**(理屈っぽく)**

![imageRL1-4-1](https://yaber1965.github.io/images/imageRL1-4-1.jpg)

**(直感的に)**

![imageRL1-4-2](https://yaber1965.github.io/images/imageRL1-4-2.jpg)

QEU:FOUNDER ： “細かいことを気にする方のために定義式を、「細かいことはいいんだよ」というような小生のようなタイプの方のために概念図を用意しました（笑）。ここで、「標準ベクトル」という言葉と「単位空間」という用語がガチャガチャになっています。ここらへんは歴史的なモノであり、まあ大目に見てください。個人的には標準SN比の考え方をベースとして、「標準ベクトル」の呼び方がいいとは思います。”

D先生 ： “概念図で直感的に見たほうが、わかりやすそう・・・。”

QEU:FOUNDER ： “これを見ると、Y2にマンハッタン距離を使う意味がよりわかりやすくなります。従来のRT法はY2の計算モジュールとしてL2（ユーグリッド）距離を使っているんです。ですから、**新RT法では図形（データ）をY1で回転させたのち、標準-計測間のL1(マンハッタン)距離をとればOK**です。なにはともあれ、プログラムをドン・・・。新RT法の関数は、Pytorchの関数を使って高速に計算されます。多分、従来のRT法よりも相当に早くなっていると思います。”

```python
# -------------------- プログラムの始まり -------------------
# -*- coding: utf-8 -*-
# filename: newRT_create_metrics.py
# newRTメトリックスの生成（移動と回転用）
# ---------------------------------------------------
# ライブラリをインポートする
import cv2
from fastai.vision.all import *
import seaborn as sns
import pandas as pd
import numpy as np
import joblib
from scipy.spatial import distance
import matplotlib.pyplot as plt

#=================================================
# READ CSV_FILE FUNCTION
#=================================================
# TS画像ファイルを読んで、TSテンソルを出力する
def read_TSpics(pic_tani, pic_signal): 

    # ------------------
    # 標準画像(Tani)
    filename = foldername + pic_tani
    img_tani = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)
    # リサイズ
    img_rezTani = cv2.resize(img_tani , newsize)

    # ------------------
    # 信号画像(Signal)
    filename = foldername + pic_signal
    img_signal = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)
    # リサイズ
    img_rezSig = cv2.resize(img_signal , newsize)

    # ------------------
    # 画像データのテンソル化(T,S)
    img_tensorT = tensor(1.0-img_rezTani/255)  # 標準画像(ポジ変換)
    img_tensorS = tensor(1.0-img_rezSig/255)  # 信号画像(ポジ変換)
    
    return img_tensorT, img_tensorS


# ---------------------------
# newRTメトリックスを計算する(テンソル活用版)
def calc_newRT(len_temp, max_jy_index, tsr_sig_matrix, tsr_tani_array): 

    # ---------------------------
    # 変数の初期化
    L1_loss = torch.nn.L1Loss()
    btY1_yarray, Y2_yarray = [], []

    # 繰り返し
    for i in range(len_temp):

        y = tsr_sig_matrix[i]
        x = tsr_tani_array

        xx = torch.dot(x,x)
        xy = torch.dot(x,y)
        beta = xy/xx
        #print("i:{}, beta:{}".format(i,beta))

        mDistance   = L1_loss(y, beta*x)
        #print("i:{}, beta:{}".format(i,beta))
        #print("mDistance: ", mDistance.item())
        #print("yres:{}".format(yres))
        
        btY1_yarray.append(beta)
        Y2_yarray.append(mDistance.item())

    return btY1_yarray, Y2_yarray


# ---------------------------
# RTメトリックスを計算する(テンソル活用版)
def calc_RTmetrics(len_temp, max_jy_index, tsr_sig_matrix, tsr_tani_array): 

    # ---------------------------
    # 変数の初期化
    lnr_yarray, btY1_yarray = [], []
    st_yarray, sb_yarray, se_yarray, ve_yarray = [], [], [], []
    yita_yarray, Y2_yarray = [], []

    # 有効除数の計算
    yuko = torch.dot(tsr_tani_array, tsr_tani_array)

    # 線形式の計算
    for i in range(len_temp):
        lnr_yitem  = torch.dot(tsr_sig_matrix[i], tsr_tani_array)
        btY1_yitem = lnr_yitem / yuko
        lnr_yarray.append(lnr_yitem.item())
        btY1_yarray.append(btY1_yitem.item())

    # 全変動ST及び各種中間指標SB,SE,VE,η
    for i in range(len_temp):
        sum_item  = torch.dot(tsr_sig_matrix[i], tsr_sig_matrix[i])
        st_yarray.append(sum_item.item())
        sb_yarray.append(lnr_yarray[i] ** 2 / yuko.item())
        se_yarray.append(st_yarray[i] - sb_yarray[i])

        # 異常処理
        temp_ve = se_yarray[i] / float(max_jy_index - 1.0)
        if temp_ve < 0.0000001:
            #comment = 'ゼロ異常発生！！'
            #print(comment)
            ve_yarray.append(-1.0)   
            yita_yarray.append(-1.0)  
            Y2_yarray.append(-1.0) 
        else:
            temp_Y2 = math.sqrt(temp_ve)
            ve_yarray.append(temp_ve)   
            yita_yarray.append(1.0 / temp_ve)  
            Y2_yarray.append(temp_Y2) 

    return btY1_yarray, Y2_yarray


#=================================================
# MAIN PROGRAM(1) : 読み込み画像の対象を設定する
#=================================================
# 読み込み先の指定
foldername = "./ARRAY_RTCNN/"
newsize = (900, 500)
# -----
# RTベクトル長と信号空間長
rmax_jy_idx, len_rmx  = newsize[0]*newsize[1], 9

# トーラスの場合
# 信号空間画像(計測ベクトル)
# 画像ファイル名(TORUS)
arr_nmSignal = ["NA"]*len_rmx
arr_nmSignal[0] = "camera6_1_0_0_82_0_125_7_torus.png"
arr_nmSignal[1] = "camera11_1_0_0_99_0_124_7_torus.png"
arr_nmSignal[2] = "camera16_1_0_0_83_0_176_7_torus.png"
arr_nmSignal[3] = "camera21_1_0_0_79_0_219_7_torus.png"
arr_nmSignal[4] = "camera26_1_0_0_80_0_m187_7_torus.png"
arr_nmSignal[5] = "camera31_1_0_0_82_0_m013_7_torus.png"
arr_nmSignal[6] = "camera36_1_0_0_84_0_m17_7_torus.png"
arr_nmSignal[7] = "camera41_1_0_0_83_0_143_7_torus.png"
arr_nmSignal[8] = "camera46_1_0_0_77_0_m172_7_torus.png"

# 移動量
arr_posdiff = [0.0]*len_rmx
arr_posdiff[0] = 1.25
arr_posdiff[1] = 1.24
arr_posdiff[2] = 1.76
arr_posdiff[3] = 2.19
arr_posdiff[4] = -1.87
arr_posdiff[5] = -0.13
arr_posdiff[6] = -1.7
arr_posdiff[7] = 1.43
arr_posdiff[8] = -1.72

# 回転量
arr_rotdiff = [0.0]*len_rmx
arr_rotdiff[0] = 0.0
arr_rotdiff[1] = 0.0
arr_rotdiff[2] = 0.0
arr_rotdiff[3] = 0.0
arr_rotdiff[4] = 0.0
arr_rotdiff[5] = 0.0
arr_rotdiff[6] = 0.0
arr_rotdiff[7] = 0.0
arr_rotdiff[8] = 0.0

# 単位空間画像(標準ベクトル)
#pic_tani = "average_bevelsq.png"
#pic_tani = "average_beveltri.png"
#pic_tani = "average_circle.png"
#pic_tani = "average_pentagon.png"
#pic_tani = "average_rectangle.png"
#pic_tani = "average_square.png"
pic_tani = "average_torus.png"
#pic_tani = "average_triangle.png"

# initialise
metrics_cos = torch.nn.CosineSimilarity(dim=0)
L1_loss     = torch.nn.L1Loss()
arr_cos     = []
arr_dist    = []

# -----
# メトリックスの画像毎の繰り返し
for i in range(len_rmx):

    #=================================================
    # MAIN PROGRAM(2) : 画像をテンソル化する(T,S)
    #=================================================
    # TS画像ファイルを読んで、TSテンソルを出力する
    img_tensorT, img_tensorS = read_TSpics(pic_tani, arr_nmSignal[i])
    print(img_tensorS)

    #=================================================
    # MAIN PROGRAM(3) : 畳み込みRTメトリックスを実行する
    #=================================================
    # ベクトル化
    img_arrayT = img_tensorT.flatten()
    #print(img_arrayT)
    img_arrayS = img_tensorS.flatten()
    # -----
    cSimilarity = metrics_cos(img_arrayS, img_arrayT)
    #print("cSimilarity: ", cSimilarity.item())
    mDistance = L1_loss(img_arrayS, img_arrayT)
    #print("mDistance: ", mDistance.item())
    # -----
    arr_cos.append(cSimilarity.item())
    arr_dist.append(mDistance.item())
    if i == 0:
        img_mxS = img_arrayS
    else:
        img_mxS = torch.vstack((img_mxS, img_arrayS))
# ------
# RTメトリックスを生成する
#print(img_mxS)
btY1_Parray, Y2_Parray = calc_RTmetrics(len_rmx, rmax_jy_idx, img_mxS, img_arrayT)
btY1_Narray, Y2_Narray = calc_newRT(len_rmx, rmax_jy_idx, img_mxS, img_arrayT)
print("btY1_Narray: ", btY1_Narray)
print("Y2_Narray: ", Y2_Narray)

#=================================================
# MAIN PROGRAM(4) : CSVファイルに出力する
#=================================================
mx_temp = np.vstack([arr_nmSignal, arr_posdiff, arr_rotdiff, btY1_Parray, Y2_Parray, btY1_Narray, Y2_Narray, arr_cos, arr_dist])
mx_output = mx_temp.T
#print(mx_output)

# データフレームを作成
arr_columns = ["picname", "posdiff", "rotdiff", "primY1", "primY2", "newY1", "newY2", "cos", "dist"]
df_metrics = pd.DataFrame(mx_output, columns=arr_columns)
print("------------ primitiveRTメトリックスのデータフレーム -------------")  
print(df_metrics) 

# CSV ファイル (newRT_{}.csv.csv) として出力
file_csvout = foldername + "newRT_{}_only.csv".format(pic_tani.replace(".png","")) # ファイルパス名の生成
df_metrics.to_csv(file_csvout)
print("CSVファイルの出力完了 : {}".format(file_csvout))  

```

QEU:FOUNDER ： “今回は説明の順番を逆にして、図形の移動と回転の効果から見てみましょう。Y1は従来と新は全く同じなので、Y2のみを比較します。”

**（移動）**

![imageRL1-4-3](https://yaber1965.github.io/images/imageRL1-4-3.jpg)

**（回転）**

![imageRL1-4-4](https://yaber1965.github.io/images/imageRL1-4-4.jpg)

D先生 ： “この実験では、同一の図形(torus,rectangle)を移動や回転させて計測しているんでしたよね。これらの実験結果によると、新RT法のY2は移動に対してさらにロバストになっています。そのほかに大きな変化は感じられません。”

QEU:FOUNDER ： “じゃあ、次に図形判別の実験をやってみましょう。”

![imageRL1-4-5](https://yaber1965.github.io/images/imageRL1-4-5.jpg)

D先生 ： “上のフリップにグラフと表がでてきましたが、どのように比較すると「図形認識のレベルが上がった」といえるんですか？”

QEU:FOUNDER ： “グラフをボーッと見ただけだと、両者Y2は「ほとんど同じモノ」という結論しかでてきません。そこで、**従来と新のY2メトリックスの比率(B/A)**をとってみました。そうすると、標準（ベクトル）図形が類似しているものは新Y2値がより小さく、図形の性質が大きく違うものに対しては値がより大きくなるという特性を発見しました。”

D先生 ： “だから**「新RTのY2は認識精度のレベルが上がった」**という結論ね。なるほど・・・。でも、この微妙な差異が全体の画像認識システムの認識精度にどの程度の影響を与えるのか・・・。”

**（単純な端子後退）**

![imageRL1-4-6](https://yaber1965.github.io/images/imageRL1-4-6.jpg)

**（端子の微妙な後退と傾き）**

![imageRL1-4-7](https://yaber1965.github.io/images/imageRL1-4-7.jpg)

QEU:FOUNDER ： “前回の外観検査機での問題はY2でマハラノビス距離を取ったときの特徴検出力が低かったことです。今回の知見で改善効果がどうなるかは、もういちど（前回と同様に）外観検査自動機のプロジェクトをやってみるしかないよね。”

**(見逃し率の計算)**

![imageRL1-4-8](https://yaber1965.github.io/images/imageRL1-4-8.jpg)

D先生 ： “前回のトライアルでは見逃し率は17％ぐらいです。**もう5％ぐらいは改善**しないものか・・・。つきましてはカンパください！！”

### [＞寄付のお願い(Donate me)＜](https://www.paypal.com/paypalme/QEUglobal?v=1&utm_source=unp&utm_medium=email&utm_campaign=RT000481&utm_unptid=29844400-7613-11ec-ac72-3cfdfef0498d&ppid=RT000481&cnac=HK&rsta=en_GB%28en-HK%29&cust=5QPFDMW9B2T7Q&unptid=29844400-7613-11ec-ac72-3cfdfef0498d&calc=f860991d89600&unp_tpcid=ppme-social-business-profile-creat-ed&page=main%3Aemail%3ART000481&pgrp=main%3Aemail&e=cl&mchn=em&s=ci&mail=sys&appVersion=1.71.0&xt=104038)

QEU:FOUNDER ： “お願いします。”

## ～　まとめ　～

C部長 : “イケメン・バトルはリニューアル、ドン・・・！！”

![imageRL1-4-9](https://yaber1965.github.io/images/imageRL1-4-9.jpg)

D先生 : “オイ！！私のイケメン（左側）の顔が見えなくなってきたじゃないか！！”

C部長 : “新イケメンに対する、フォロー担当者の指名をいかがしましょうか。FOUNDER・・・。”

QEU:FOUNDER ： “D先生でいいよ・・・。”

<iframe width="560" height="315" src="https://www.youtube.com/embed/jesnr0ErDXE" ti-tle="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; en-crypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

D先生 : “じゃあ、それでいいや・・・（笑）。**私のイケメンも今やフェードアウトしてきたし・・・。**”


