## QEUR21_VINSP2:　RT-Conv法（その１）～畳み込み(Convolution)のみを行う

### ～　ちょっとだけ「進化する」つもり・・・　～

QEU:FOUNDER ： “ROUND1シリーズでは、「ロボティックス」編で登場したRT-Conv法を外観検査に使います。ちょっと進歩・・・(笑)。ついでに、Conv部品も昔よりも「ちょっとだけ」変えます。”

D先生 ： “どう変えるんですか？”

QEU:FOUNDER ： “**Conv部品の一部にマイナス値を付けました**。こうすれば、RTメトリックス計算時に「傾き」が明確に出てくるでしょう。”

**（その１）**
![image2-2-1](https://yaber1965.github.io/images/image2-2-1.jpg)

**（その２）**
![image2-2-2](https://yaber1965.github.io/images/image2-2-2.jpg)

**（その３）**
![image2-2-3](https://yaber1965.github.io/images/image2-2-3.jpg)

D先生 ： “なるほど、こういう感じでマイナス値を付けたんですね・・・。それでも、Datum系はマイナスをつけていないですね。”

QEU:FOUNDER ： “Datum系は内積で0になっちゃう可能性がありますので・・・。ちなみに、「畳み込み(Convolution)という処理とは何か」は自分で調べてください。画像を分析するときに使用するディープラーニングの一種であるCNN（Convolutional Neural network）で使われる技術です。あまり難しくないので安心して・・・（笑）。あとは、プログラムをドン・・・。”

```python
# -------------------- プログラムの始まり -------------------
# -*- coding: utf-8 -*-
# filename: create_convolution_matrix.py
# 畳み込みマトリックスを形成する（ヒートマップに出力） 
# ---------------------------------------------------
import numpy as np
import pandas as pd
import math
import cv2  #OpenCVのインポート
import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline

#=================================================
# READ CSV FI
#=================================================
# 実験パターンファイルを読み込み表示する
def read_csvfile(file_readcsv,max_idx,max_col): 
 
    # 画像異常検出ファイルの読み込み
    df = pd.read_csv(file_readcsv) 
    print(df)
    # --------------------------------------------------
    # 選択項目の読み込み
    #　Xsマトリックス
    mx_Xs = df.loc[:,"col1":"col10"].values
    print("----- mx_Xs -----")
    print(mx_Xs)
  
    return mx_Xs

# ---------------------------
# 畳み込みの計算
def metrics_conv(mx_trim, mx_conv, max_cnv_idx, max_cnv_col): 

    # ---------------------------
    # 畳み込み計算
    dot_product = 0
    for iRow in range(max_cnv_idx):    
        for jCol in range(max_cnv_col):
            dot_product = dot_product + mx_trim[iRow,jCol]*mx_conv[iRow,jCol]

    return dot_product

# ---------------------------
# 畳み込みのまとめ
def summary_metrics(mx_sample, mx_conv, max_cnv_idx, max_cnv_col, trans_idx, trans_col):   

    # ---------------------------
    # マトリックス初期化
    mx_metrics = np.zeros([trans_idx, trans_col])
    
    for iRow in range(trans_idx):
        for jCol in range(trans_col):

            # 開始行、列
            i_start = 10*iRow
            j_start = 10*jCol

            # トリミング
            mx_trim = mx_sample[i_start:i_start+10, j_start:j_start+10]
            #print(mx_trim.shape)
            #print("----- mx_trim -----")
            #print(mx_trim)
                
            # ---------------------------
            # マトリックス初期化
            dot_product = metrics_conv(mx_trim, mx_conv, max_cnv_idx, max_cnv_col)
            #print("iRow:{}, jCol:{}, dot_product:{}".format(iRow, jCol, dot_product))
            mx_metrics[iRow, jCol] = dot_product
            
    return mx_metrics

#=================================================
# Calculation class
#=================================================
# 畳み込みのクラス
class calc_convolution():

    def __init__(self, mx_sample):

        # ---------------------------
        # サンプル情報
        self.mx_sample = mx_sample

        # ---------------------------
        # 畳み込みマトリックスのパラメタ
        # サンプル
        self.max_sp_idx     = 900
        self.max_sp_col     = 1200
        # 畳み込み部品
        self.max_cnv_idx    = 10
        self.max_cnv_col    = 10
        # スキップ
        self.skip_cnv_idx   = 10
        self.skip_cnv_col   = 10

        # ---------------------------
        # 畳み込み後のマトリックス次元
        self.trans_idx = int(self.max_sp_idx / self.max_cnv_idx)
        self.trans_col = int(self.max_sp_col / self.max_cnv_col)

        # ---------------------------
        # 畳み込み処理を実施する
        #for i in range(max_cnv_parts):
        i = 1
        self.cnv_process(i)    # iのファイルを処理する

    # ---------------------------
    # 畳み込み処理を実施する
    def cnv_process(self, i): 

        # ---------------------------
        # CSVファイル(実験)情報を読み込み表示する
        #　畳み込みファイル
        file_cnv_input = foldername + code_cnv_input[i] + ".csv"  # ファイルパス名の生成 
        mx_conv = read_csvfile(file_cnv_input, self.max_cnv_idx, self.max_cnv_col)

        # ---------------------------
        # 畳み込み計算
        self.mx_metrics = summary_metrics(self.mx_sample, mx_conv, self.max_cnv_idx, self.max_cnv_col, self.trans_idx, self.trans_col)    # 畳込みマトリックスの出力
        print(self.mx_metrics.shape)
        print("----- mx_metrics -----")
        print(self.mx_metrics)

        # ---------------------------
        # 畳み込み計算結果をヒートマップ出力し、かつCSVファイルに保存する
        self.save_convcsv(i)    # 畳み込みの値

    # ---------------------------
    # 畳み込み計算結果をヒートマップ出力し、かつCSVファイルに保存する
    def save_convcsv(self, i): 

        # ---------------------------
        # データフレームを作成
        arr_index = list(range(self.trans_idx))
        arr_columns = list(range(self.trans_col))
        df_metrics = pd.DataFrame(self.mx_metrics, index=arr_index, columns=arr_columns)

        # ---------------------------
        # ヒートマップへ出力
        fig = plt.figure(figsize=(14, 8))
        ax = fig.add_subplot(1, 1, 1)
        ax.set_title("Convolution by {0}".format(code_cnv_input[i]))
        sns.heatmap(df_metrics, ax=ax, annot=True)
        plt.show()
        #file_mapout = foldername + "pic" + code_cnv_input[i]  + ".png" # ファイルパス名の生成
        #plt.savefig(file_mapout)

        # ---------------------------
        print("------------ 畳み込みマトリックスのデータフレーム -------------")  
        print(df_metrics) 
        # CSV ファイル (distance.csv) として出力
        #file_csvout = foldername + "csv" + code_cnv_input[i]  + ".csv" # ファイルパス名の生成
        #df_metrics.to_csv(file_csvout)

#=================================================
# main function            
#=================================================
if __name__  == '__main__':

    # ------------------
    # パラメタの設定
    max_cnv_parts = 8

    # ------------------
    # フォルダ名の指定
    foldername = "C:/Users/Yabe Ryuji/ARRAY_RTCNN/"  # My project folder

    # ------------------
    nam_cnv_input = "基準用CSVデータ" 
    code_cnv_input = ["NA"] * 8 # CSVコードの指定
    code_cnv_input[0] = "bend1_cnv" # CSVコードの指定
    code_cnv_input[1] = "bend2_cnv" # CSVコードの指定
    code_cnv_input[2] = "bend3_cnv" # CSVコードの指定
    code_cnv_input[3] = "bend4_cnv" # CSVコードの指定
    code_cnv_input[4] = "line1_cnv" # CSVコードの指定
    code_cnv_input[5] = "line2_cnv" # CSVコードの指定
    code_cnv_input[6] = "datum1_cnv" # CSVコードの指定
    code_cnv_input[7] = "datum2_cnv" # CSVコードの指定
    print("---- 入力:畳み込み用CSVファイル名 ----")
    print(code_cnv_input)
    print("----------------------")

    # ------------------
    code_sp_input = "conv_sample_no1"
    file_input = foldername + code_sp_input  + ".jpg" # ファイルパス名の生成
    img = cv2.imread(file_input, cv2.IMREAD_GRAYSCALE)
    img_norm = 1 - img/255
    print(img_norm.shape)

    # ------------------
    #cv2.imshow("image", img)
    #cv2.waitKey(0)
    #cv2.destroyAllWindows()

    # ---------------------------
    # 計算の実行
    calc_convolution(img_norm)      # 畳み込みのクラス

```

QEU:FOUNDER ： “この画像（↓）をインプットしてみました。”

![image2-2-4](https://yaber1965.github.io/images/image2-2-4.jpg)

D先生 ： “そして、これがアウトプットの一例ですか。ヒートマップの形で出力されていますね。ヒートマップの形は同じですが、「色合い」が微妙に違う2種の画像になっていますね・・・。”

![image2-2-5](https://yaber1965.github.io/images/image2-2-5.jpg)

QEU:FOUNDER ： “ヒートマップのスケールをみれば違いが判ります。プラス側に数値が伸びているのか、マイナス側なのかの違いですね。これは、畳み込み部品の値に由来しています。今のところは、ここまでしかわかんないと思うよ・・・。”

D先生 ： “RT法でメトリックスをつくらないと、効果がわからないですよね。”

QEU:FOUNDER ： “じゃあ、今回は中間報告。ここまでにしましょう。”


## ～　まとめ　～

### ・・・　前回のつづきです　・・・

QEU:FOUNDER ： “そもそも「レフト」の定義からわからない・・・（笑）。単に**「保守の軸がシフトしてきただけ」**だと思うがね・・・。これは、「欧米を中心で起きている」というのがポイントだよね。”

![image2-2-6](https://yaber1965.github.io/images/image2-2-6.jpg)

C部長 : “アメリカって、そもそも「レフト好き」じゃないんですか？”

![image2-2-7](https://yaber1965.github.io/images/image2-2-7.jpg)

QEU:FOUNDER ： “いやいや・・・、それはむしろ逆でしょうに・・・。20年前、バーニー、サン〇ース（民主党）はメジャーな人だった？社会が変わってきているんです。これは「パワー・シフト」ってやつ・・・。”

C部長 : “そういえば、とフラーさんは「21世紀は知力と情報力が支配力を持つ時代に変わっていく」と・・・。”

QEU:FOUNDER ： “あの本が書かれた時期は1990年でしょ？ディープ・ラーニングがまだ出現していません。あのとき、彼は今、本当に何が起こりつつあるのかはわかっていない。すなわち「知力とはなにか」・・・。”

![image2-2-8](https://yaber1965.github.io/images/image2-2-8.jpg)

QEU:FOUNDER ： “「Making neural nets uncool again」・・・。ここで、なぜ**「uncool」**なのか・・・？”

C部長 : “「cool」じゃないんでしょうね・・・。”

![image2-2-9](https://yaber1965.github.io/images/image2-2-9.jpg)

QEU:FOUNDER ： “fast.aiのレッスン動画(Lesson1)を見てほしい。この動画はAIに興味のない人でも、本当におススメだ・・・。C部長が今しがた言ってくれた**「知力の作り方が変わった」**んです。昔はいわゆる「エリートさま」がプログラムを作って、それが社会を動かすと思っていました。このような共通認識があったので、2000年代の初めは新自由主義とエリート主義が一体となった「妙な感覚」があったでしょ？”

![image2-2-10](https://yaber1965.github.io/images/image2-2-10.jpg)

C部長 : “そういえば、こんな変なのが（↑）ありました・・・（笑）。”

QEU:FOUNDER ： “このころの経営者の考え方全般にちょっと問題があったんじゃない？一体、どんな世代だ？・・・でもね、エリートが絶妙なプログラムを書いて、そのプログラムで動くコンピュータが世界を動かすと思っているのであれば、そういう気分は分からないでもない。そういう意味では。すごく「COOLな時代」だったんですよ・・・。”

##C部長 : “これからは「UNCOOL」・・・？”

QEU:FOUNDER ： “まさにそれ、「UNCOOL」な時代が来ます。・・・というか、すでにUNCOOLになっています。ニューラルネットがデータを学習し、**エリートが作った「プログラム」をはるかに超える「モデル」を形成して世の中を動かす**時代がきました。モデルを形成するためのFast.aiは別に難しくないです。Pythonをかける高校生であれば、だれでも学ぶことができます。”

![image2-2-11](https://yaber1965.github.io/images/image2-2-11.jpg)

C部長 : “なるほど・・・。**本当に価値があるのは、データの方です**。”

![image2-2-12](https://yaber1965.github.io/images/image2-2-12.jpg)

QEU:FOUNDER ： “**最も価値の高いデータを得る仕事をしている人の年収が200万円台であり、年収2000万円のエリート様が「ノリ弁」を作って価値あるデータを消しています**。この社会的な矛盾を考えることが「レフト」なのか？単に、「保守のパワーシフト」が起こっているだけじゃないの？”


