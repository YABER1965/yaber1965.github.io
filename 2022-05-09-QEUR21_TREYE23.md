## QEUR21_TREYE23:　本実験～両目法（その2）：畳み込みRTメトリックスを出力する

## ～　プログラムが長くなったかなァ・・・　～

QEU:FOUNDER ： “今回は中間段階として、「両目畳み込みRTメトリックス」をCSVファイルに出力します。しかし、長いメトリックス名・・・（笑）。”

D先生 ： “技術解説は予備実験と同じなので、今回は特に言うことはなし・・・。それではプログラムをドン！！”

```python
# ---------------------------
# 両目畳み込みRT法の本実験
# testDE2_convRT_CSVout.py
# ---------------------------
# モジュールのインポート
import cv2
from fastai.vision.all import *
# ---------------------------
# 結果をヒートマップに出力する
import seaborn as sns
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# ---------------------------
# 読み込み先の指定
foldername = "./ARRAY_RTCNN/"
newsize = (900, 300)
pic_nameL = "camera0_0_0_88_005_00_0_OK.png"   # 左カメラ画像(普通色)
pic_nameC = "camera1_0_0_88_005_00_0_OK.png"   # 中央カメラ画像(普通色)
pic_nameR = "camera2_0_0_88_005_00_0_OK.png"   # 右カメラ画像(普通色)
#pic_nameL = "camera0_0_0_88_m003_007_0_COLOR.png"   # 左カメラ画像(色変更)
#pic_nameC = "camera1_0_0_88_m003_007_0_COLOR.png"   # 中央カメラ画像(色変更)
#pic_nameR = "camera2_0_0_88_m003_007_0_COLOR.png"   # 右カメラ画像(色変更)

#=================================================
# READ CSV_FILE FUNCTION
#=================================================
# 畳み込みファイルを読み込み表示する
def read_csvfile(file_readcsv): 
 
    # 畳み込みファイルの読み込み
    df = pd.read_csv(file_readcsv) 
    # ------------------
    # 選択項目の読み込み
    # Xsマトリックス
    mx_Xs = df.loc[:,"col1":"col5"].values
    #print("----- mx_Xs -----")
    #print(mx_Xs)
  
    return mx_Xs

# ---------------------------
# LCR画像ファイルを読んで、テンソルを出力する
def read_LCRpics(pic_nameL, pic_nameC, pic_nameR): 

    # ------------------
    # 左(L)画像
    filename = foldername + pic_nameL
    imgL = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)
    img_cropL = imgL[212:856,47:1867]
    # リサイズ
    img_resizeL = cv2.resize(img_cropL , newsize)

    # ------------------
    # 中央(C)画像
    filename = foldername + pic_nameC
    imgC = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)
    img_cropC = imgC[212:856,47:1867]
    # リサイズ
    img_resizeC = cv2.resize(img_cropC , newsize)

    # ------------------
    # 右(R)画像
    filename = foldername + pic_nameR
    imgR = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)
    img_cropR = imgR[212:856,47:1867]
    # リサイズ
    img_resizeR = cv2.resize(img_cropR , newsize)
    # 画像出力
    #cv2.imshow("image(Right)", img_resizeR)
    #cv2.waitKey(0)
    #cv2.destroyAllWindows()

    # ------------------
    # 画像データのテンソル化(L,C,R)
    img_tensorL = tensor(img_resizeL/255)  # 信号空間
    img_tensorC = tensor(img_resizeC/255)  # 単位空間（標準ベクトル）
    img_tensorR = tensor(img_resizeR/255)  # 信号空間
    
    return img_tensorL, img_tensorC, img_tensorR

# ---------------------------
# RTメトリックスを計算する(テンソル活用版)
def calc_deyeRTmet(len_temp, max_jy_index, tsr_sig_matrix, tsr_tani_array): 

    # ---------------------------
    # 変数の初期化
    lnr_yarray, btY1_yarray = [], []
    st_yarray, sb_yarray, se_yarray, ve_yarray = [], [], [], []
    yita_yarray, Y2_yarray = [], []

    # 有効除数の計算
    yuko = torch.dot(tsr_tani_array, tsr_tani_array)
    #print(yuko)

    # 線形式の計算
    for i in range(len_temp):
        lnr_yitem  = torch.dot(tsr_sig_matrix[i], tsr_tani_array)
        btY1_yitem = lnr_yitem / yuko
        lnr_yarray.append(lnr_yitem.item())
        btY1_yarray.append(btY1_yitem.item())
    #print(lnr_yarray)
    #print(btY1_yarray)

    # 全変動ST及び各種中間指標SB,SE,VE,η
    for i in range(len_temp):
        sum_item  = torch.dot(tsr_sig_matrix[i], tsr_sig_matrix[i])
        st_yarray.append(sum_item.item())
        sb_yarray.append(lnr_yarray[i] ** 2 / yuko.item())
        se_yarray.append(st_yarray[i] - sb_yarray[i])
    #print(st_yarray)
    #print(sb_yarray)
    #print(se_yarray)

        # 異常処理
        temp_ve = se_yarray[i] / float(max_jy_index - 1.0)
        if temp_ve < 0.0001:
            ve_yarray.append(0.0)   
            yita_yarray.append(0.0)  
            Y2_yarray.append(0.0) 
        else:
            temp_Y2 = math.sqrt(temp_ve)
            ve_yarray.append(temp_ve)   
            yita_yarray.append(1.0 / temp_ve)  
            Y2_yarray.append(temp_Y2) 
    #print(btY1_yarray)
    #print(Y2_yarray)

    return round(Y2_yarray[0] - Y2_yarray[1], 5)

# ---------------------------
# 畳み込み処理を実施する
def apply_kernel(row, col, kernel, img_tensor):
    return (img_tensor[row:row+max_cnv_row,col:col+max_cnv_col] * kernel).sum()

# ---------------------------
# RTメトリックスを計算する(テンソル活用版)
def calc_RTmetrics(len_temp, max_jy_index, tsr_sig_matrix, tsr_tani_array): 

    # ---------------------------
    # 変数の初期化
    lnr_yarray, btY1_yarray = [], []
    st_yarray, sb_yarray, se_yarray, ve_yarray = [], [], [], []
    yita_yarray, Y2_yarray = [], []

    # 有効除数の計算
    yuko = torch.dot(tsr_tani_array, tsr_tani_array)
    #print(yuko)

    # 線形式の計算
    for i in range(len_temp):
        lnr_yitem  = torch.dot(tsr_sig_matrix[i], tsr_tani_array)
        btY1_yitem = lnr_yitem / yuko
        lnr_yarray.append(lnr_yitem.item())
        btY1_yarray.append(btY1_yitem.item())
    #print(lnr_yarray)
    #print(btY1_yarray)

    # 全変動ST及び各種中間指標SB,SE,VE,η
    for i in range(len_temp):
        sum_item  = torch.dot(tsr_sig_matrix[i], tsr_sig_matrix[i])
        st_yarray.append(sum_item.item())
        sb_yarray.append(lnr_yarray[i] ** 2 / yuko.item())
        se_yarray.append(st_yarray[i] - sb_yarray[i])
    #print(st_yarray)
    #print(sb_yarray)
    #print(se_yarray)

        # 異常処理
        temp_ve = se_yarray[i] / float(max_jy_index - 1.0)
        if temp_ve < 0.0001:
            comment = 'ゼロ異常発生！！'
            print(comment)
            ve_yarray.append(-1.0)   
            yita_yarray.append(-1.0)  
            Y2_yarray.append(-1.0) 
        else:
            temp_Y2 = math.sqrt(temp_ve)
            ve_yarray.append(temp_ve)   
            yita_yarray.append(1.0 / temp_ve)  
            Y2_yarray.append(temp_Y2) 
    #print(btY1_yarray)
    #print(Y2_yarray)

    return btY1_yarray, Y2_yarray

# ---------------------------
# 畳み込みRT法による計算結果をヒートマップ出力し、かつCSVファイルに保存する
def save_RTmcsv(mx_result, name_csvout, plotNO): 

    # ---------------------------
    # データフレームを作成
    arr_index   = list(range(3))
    arr_columns = list(range(9))
    df_metrics = pd.DataFrame(mx_result, index=arr_index, columns=arr_columns)

    # ---------------------------
    #print("------------ 畳み込みマトリックスのデータフレーム -------------")  
    #print(df_metrics) 
    # CSV ファイル (distance.csv) として出力
    file_csvout = foldername + "RTm_" + name_csvout  + ".csv" # ファイルパス名の生成
    df_metrics.to_csv(file_csvout)
    print("CSVファイルの出力完了 : {}".format(plotNO)) 
    
    return df_metrics

#=================================================
# MAIN PROGRAM(1) : 両目RTメトリックス
#=================================================
# LCR画像ファイルを読んで、テンソルを出力する
img_tensorL, img_tensorC, img_tensorR = read_LCRpics(pic_nameL, pic_nameC, pic_nameR)
#print(img_tensorC)

# ---------------------------
# テンソルイメージ処理のパラメタ
max_tsr_row   = newsize[1]  #(900, 300)
max_tsr_col   = newsize[0]  #(900, 300)
# ストライド量
stride_tsr_row  = 5
stride_tsr_col  = 5
# RT法処理のサイズ
rtm_tsr_row   = 5
rtm_tsr_col   = 5
# RTベクトル長と信号空間長
max_jy_index  = 5*5
len_temp      = 2  # 右と左

# ---------------------------
# テンソル行列の処理(for)開始点のベクトルを生成
row_range, col_range = [], []
sum_row   = 0
while sum_row <= max_tsr_row-rtm_tsr_row:
    row_range.append(sum_row)
    sum_row  += stride_tsr_row
#print(row_range)    # len 60
# -----
sum_col   = 0
while sum_col <= max_tsr_col-rtm_tsr_col:
    col_range.append(sum_col)
    sum_col  += stride_tsr_col
#print(col_range)    # len 180

# ---------------------------
# 両目RT法によるマトリックスの生成
num_rows = len(row_range)
num_cols = len(col_range)
arr_row, arr_col = [], []
deyeY2_pool = []
# ------
cnt_row = 0
for row in row_range:
    cnt_col = 0
    for col in col_range:
        # ------
        # 単位空間の空間ベクトルを生成する
        tsr_tani_array = img_tensorC[row:row+rtm_tsr_row,col:col+rtm_tsr_col].flatten()
        #print(tsr_tani_array)
        # ------
        # 信号空間の空間マトリックスを生成する
        tsr_sigL = img_tensorL[row:row+rtm_tsr_row,col:col+rtm_tsr_col].flatten()
        tsr_sigR = img_tensorR[row:row+rtm_tsr_row,col:col+rtm_tsr_col].flatten()
        # -----
        tsr_sig_matrix = torch.stack([tsr_sigL, tsr_sigR])
        #print("----- tsr_sig_matrix -----")
        #print(tsr_sig_matrix)
        # ------
        # 両目法RTメトリックスを計算する
        deyeY2 = calc_deyeRTmet(len_temp, max_jy_index, tsr_sig_matrix, tsr_tani_array)
        #print(deyeY2)
        # ------
        # 信号空間の空間マトリックスを生成する
        arr_row.append(row)
        arr_col.append(col)
        deyeY2_pool.append(deyeY2)
        # ------
        # COUNT UP
        cnt_col = cnt_col + 1
    # ------
    # COUNT UP.append
    cnt_row = cnt_row + 1

# ---------------------------
# 結果のテキスト出力する
mx_deyeY2 = np.array(deyeY2_pool).reshape([num_rows, num_cols])
tensor_deyeY2 = tensor(mx_deyeY2)
#print(tensor_deyeY2)

#=================================================
# MAIN PROGRAM(2) : 畳み込みメトリックス
#=================================================
# パラメタの設定
max_cnv_parts  = 8
# 画像サンプルのサイズ
max_sp_row     = 60
max_sp_col     = 180
# 畳み込み部品のサイズ
max_cnv_row    = 5
max_cnv_col    = 5
# ストライド量
stride_cnv_row = 5
stride_cnv_col = 5
# ------------------
nam_cnv_input = "基準用CSVデータ" 
code_cnv_input = ["NA"] * 8 # CSVコードの指定
code_cnv_input[0] = "bend1_cnv" # CSVコードの指定
code_cnv_input[1] = "bend2_cnv" # CSVコードの指定
code_cnv_input[2] = "bend3_cnv" # CSVコードの指定
code_cnv_input[3] = "bend4_cnv" # CSVコードの指定
code_cnv_input[4] = "line1_cnv" # CSVコードの指定
code_cnv_input[5] = "line2_cnv" # CSVコードの指定
code_cnv_input[6] = "datum1_cnv" # CSVコードの指定
code_cnv_input[7] = "datum2_cnv" # CSVコードの指定
print("---- 入力:畳み込み用CSVファイル名 ----")
print(code_cnv_input)
print("-------------------------------")

# ------------------
# 畳み込み処理を実施する
for i in range(max_cnv_parts):
    # ---------------------------
    # CSVファイル(実験)情報を読み込み表示する
    # 畳み込みファイル
    file_cnv_input = foldername + code_cnv_input[i] + ".csv"  # ファイルパス名の生成 
    mx_conv = read_csvfile(file_cnv_input)
    if i == 0:    
        tensor_bend1 = tensor(mx_conv).float()
    elif i == 1:
        tensor_bend2 = tensor(mx_conv).float()
    elif i == 2:
        tensor_bend3 = tensor(mx_conv).float()
    elif i == 3:
        tensor_bend4 = tensor(mx_conv).float()
    elif i == 4:
        tensor_line1 = tensor(mx_conv).float()
    elif i == 5:
        tensor_line2 = tensor(mx_conv).float()
    elif i == 6:
        tensor_datum1 = tensor(mx_conv).float()
    elif i == 7:
        tensor_datum2 = tensor(mx_conv).float()
# ---------------------------
# カーネルの生成
signal_kernels  = torch.stack([tensor_bend1, tensor_bend2, tensor_bend3, tensor_bend4, tensor_line1, tensor_line2])
tani_kernel     = tensor_datum1 + tensor_datum2

# ---------------------------
# 画像の処理(for)開始点のベクトルを生成
row_range, col_range = [], []
sum_row   = 0
while sum_row <= max_sp_row-max_cnv_row:
    row_range.append(sum_row)
    sum_row  += stride_cnv_row
#print(row_range)
# -----
sum_col   = 0
while sum_col <= max_sp_col-max_cnv_col:
    col_range.append(sum_col)
    sum_col  += stride_cnv_col
#print(col_range)

# ---------------------------
# 単位空間用の畳み込み処理を実施する
kernel = tani_kernel
tani_timage = tensor([[apply_kernel(i,j,kernel, tensor_deyeY2) for j in col_range] for i in row_range])

# ------------------
# 信号空間用の畳み込み処理を実施する
for i in range(max_cnv_parts-2):

    # ---------------------------
    # CSVファイル(実験)情報を読み込み表示する
    kernel = signal_kernels[i]
    calc_conv = tensor([[apply_kernel(i,j,kernel, tensor_deyeY2) for j in col_range] for i in row_range])
    # -----
    if i == 0:    
        tsr_cvbend1 = tensor(calc_conv).float()
    elif i == 1:
        tsr_cvbend2 = tensor(calc_conv).float()
    elif i == 2:
        tsr_cvbend3 = tensor(calc_conv).float()
    elif i == 3:
        tsr_cvbend4 = tensor(calc_conv).float()
    elif i == 4:
        tsr_cvline1 = tensor(calc_conv).float()
    elif i == 5:
        tsr_cvline2 = tensor(calc_conv).float()
# ---------------------------
# 畳み込みテンソルイメージの生成  
signal_timages = torch.stack([tsr_cvbend1, tsr_cvbend2, tsr_cvbend3, tsr_cvbend4, tsr_cvline1, tsr_cvline2])
# 結果の出力
print(signal_timages.shape)     # torch.Size([6, 12, 36])
print("----- signal_timages[0] -----")
print(signal_timages[0])
print("----- tani_timage -----")
print(tani_timage)

#=================================================
# MAIN PROGRAM(3) : RTメトリックス
#=================================================
# テンソルイメージ処理のパラメタ
max_tsr_row   = 12
max_tsr_col   = 36
# ストライド量
stride_tsr_row  = 4
stride_tsr_col  = 4
# RT法処理のサイズ
rtm_tsr_row   = 4
rtm_tsr_col   = 4
# RTベクトル長と信号空間長
max_jy_index  = 4*4
len_temp      = 6

# ---------------------------
# テンソル行列の処理(for)開始点のベクトルを生成
row_range, col_range = [], []
sum_row   = 0
while sum_row <= max_tsr_row-rtm_tsr_row:
    row_range.append(sum_row)
    sum_row  += stride_tsr_row
#print(row_range)
# -----
sum_col   = 0
while sum_col <= max_tsr_col-rtm_tsr_col:
    col_range.append(sum_col)
    sum_col  += stride_tsr_col
#print(col_range)

# ---------------------------
# RT法によるプーリング計算
arr_row = []
arr_col = []
arr_btY1_pool = []
arr_Y2_pool = []
# ---------------------------
# RTメトリックスをCSVファイルに出力するための行列
mx_p0Y1_output = np.zeros([3,9])
mx_p1Y1_output = np.zeros([3,9])
mx_p2Y1_output = np.zeros([3,9])
mx_p3Y1_output = np.zeros([3,9])
mx_p4Y1_output = np.zeros([3,9])
mx_p5Y1_output = np.zeros([3,9])
# ---
mx_p0Y2_output = np.zeros([3,9])
mx_p1Y2_output = np.zeros([3,9])
mx_p2Y2_output = np.zeros([3,9])
mx_p3Y2_output = np.zeros([3,9])
mx_p4Y2_output = np.zeros([3,9])
mx_p5Y2_output = np.zeros([3,9])
# ---------------------------
cnt_row = 0
for row in row_range:
    cnt_col = 0
    for col in col_range:
        # ------
        # 単位空間の空間ベクトルを生成する
        tsr_tani_array = tani_timage[row:row+rtm_tsr_row,col:col+rtm_tsr_col].flatten()
        # ------
        # 信号空間の空間マトリックスを生成する
        temp_matrix = signal_timages[0]
        tsr_sig_p0 = temp_matrix[row:row+rtm_tsr_row,col:col+rtm_tsr_col].flatten()
        temp_matrix = signal_timages[1]
        tsr_sig_p1 = temp_matrix[row:row+rtm_tsr_row,col:col+rtm_tsr_col].flatten()
        temp_matrix = signal_timages[2]
        tsr_sig_p2 = temp_matrix[row:row+rtm_tsr_row,col:col+rtm_tsr_col].flatten()
        temp_matrix = signal_timages[3]
        tsr_sig_p3 = temp_matrix[row:row+rtm_tsr_row,col:col+rtm_tsr_col].flatten()
        temp_matrix = signal_timages[4]
        tsr_sig_p4 = temp_matrix[row:row+rtm_tsr_row,col:col+rtm_tsr_col].flatten()
        temp_matrix = signal_timages[5]
        tsr_sig_p5 = temp_matrix[row:row+rtm_tsr_row,col:col+rtm_tsr_col].flatten()
        # -----
        tsr_sig_matrix = torch.stack([tsr_sig_p0, tsr_sig_p1, tsr_sig_p2, tsr_sig_p3, tsr_sig_p4, tsr_sig_p5])
        # ------
        # RTメトリックスを計算する
        btY1_yarray, Y2_yarray = calc_RTmetrics(len_temp, max_jy_index, tsr_sig_matrix, tsr_tani_array)
        # ------
        # 信号空間の空間マトリックスを生成する
        arr_row.append(row)
        arr_col.append(col)
        arr_btY1_pool.append(np.max(btY1_yarray))
        arr_Y2_pool.append(np.max(Y2_yarray))
        # ------
        # CSV出力用のマトリックスを生成する
        mx_p0Y1_output[cnt_row, cnt_col] = round(btY1_yarray[0],3)
        mx_p1Y1_output[cnt_row, cnt_col] = round(btY1_yarray[1],3)
        mx_p2Y1_output[cnt_row, cnt_col] = round(btY1_yarray[2],3)
        mx_p3Y1_output[cnt_row, cnt_col] = round(btY1_yarray[3],3)
        mx_p4Y1_output[cnt_row, cnt_col] = round(btY1_yarray[4],3)
        mx_p5Y1_output[cnt_row, cnt_col] = round(btY1_yarray[5],3)
        # ---
        mx_p0Y2_output[cnt_row, cnt_col] = round(Y2_yarray[0],3)
        mx_p1Y2_output[cnt_row, cnt_col] = round(Y2_yarray[1],3)
        mx_p2Y2_output[cnt_row, cnt_col] = round(Y2_yarray[2],3)
        mx_p3Y2_output[cnt_row, cnt_col] = round(Y2_yarray[3],3)
        mx_p4Y2_output[cnt_row, cnt_col] = round(Y2_yarray[4],3)
        mx_p5Y2_output[cnt_row, cnt_col] = round(Y2_yarray[5],3)
        # ------
        # COUNT UP
        #print(cnt_row, cnt_col)
        cnt_col = cnt_col + 1
    # ------
    # COUNT UP
    cnt_row = cnt_row + 1

#=================================================
# MAIN PROGRAM(4) : CSVファイルに出力する
#=================================================
# ---------------------------
# CSVファイルに出力する(Y1)
# ---------------------------
df_p0Y1 = save_RTmcsv(mx_p0Y1_output, "p0Y1",1)
df_p1Y1 = save_RTmcsv(mx_p1Y1_output, "p1Y1",2)
df_p2Y1 = save_RTmcsv(mx_p2Y1_output, "p2Y1",3)
df_p3Y1 = save_RTmcsv(mx_p3Y1_output, "p3Y1",4)
df_p4Y1 = save_RTmcsv(mx_p4Y1_output, "p4Y1",5)
df_p5Y1 = save_RTmcsv(mx_p5Y1_output, "p5Y1",6)
# ---------------------------
# ヒートマップへ出力
fig = plt.figure(figsize=(16, 8))
# ---
# p0
ax0 = fig.add_subplot(3, 2, 1)
ax0.set_title("HEATMAP of {0}".format("df_p0Y1"))
sns.heatmap(df_p0Y1, ax=ax0, annot=True, cbar=True, cmap='Blues', fmt='.2f')
# p1
ax1 = fig.add_subplot(3, 2, 2)
ax1.set_title("HEATMAP of {0}".format("df_p1Y1"))
sns.heatmap(df_p1Y1, ax=ax1, annot=True, cbar=True, cmap='Blues', fmt='.2f')
# p2
ax2 = fig.add_subplot(3, 2, 3)
ax2.set_title("HEATMAP of {0}".format("df_p2Y1"))
sns.heatmap(df_p2Y1, ax=ax2, annot=True, cbar=True, cmap='Blues', fmt='.2f')
# p3
ax3 = fig.add_subplot(3, 2, 4)
ax3.set_title("HEATMAP of {0}".format("df_p3Y1"))
sns.heatmap(df_p3Y1, ax=ax3, annot=True, cbar=True, cmap='Blues', fmt='.2f')
# p4
ax4 = fig.add_subplot(3, 2, 5)
ax4.set_title("HEATMAP of {0}".format("df_p4Y1"))
sns.heatmap(df_p4Y1, ax=ax4, annot=True, cbar=True, cmap='Blues', fmt='.2f')
# p5
ax5 = fig.add_subplot(3, 2, 6)
ax5.set_title("HEATMAP of {0}".format("df_p5Y1"))
sns.heatmap(df_p5Y1, ax=ax5, annot=True, cbar=True, cmap='Blues', fmt='.2f')
# ---
plt.show()
#file_mapout = foldername + "pic" + code_cnv_input[i]  + ".png" # ファイルパス名の生成
#plt.savefig(file_mapout)

# ---------------------------
# CSVファイルに出力する(Y2)
# ---------------------------
df_p0Y2 = save_RTmcsv(mx_p0Y2_output, "p0Y2",1)
df_p1Y2 = save_RTmcsv(mx_p1Y2_output, "p1Y2",2)
df_p2Y2 = save_RTmcsv(mx_p2Y2_output, "p2Y2",3)
df_p3Y2 = save_RTmcsv(mx_p3Y2_output, "p3Y2",4)
df_p4Y2 = save_RTmcsv(mx_p4Y2_output, "p4Y2",5)
df_p5Y2 = save_RTmcsv(mx_p5Y2_output, "p5Y2",6)
# ---------------------------
# ヒートマップへ出力
fig = plt.figure(figsize=(16, 8))
# ---
# p0
ax0 = fig.add_subplot(3, 2, 1)
ax0.set_title("HEATMAP of {0}".format("df_p0Y2"))
sns.heatmap(df_p0Y2, ax=ax0, annot=True, cbar=True, cmap='Blues', fmt='.2f')
# p1
ax1 = fig.add_subplot(3, 2, 2)
ax1.set_title("HEATMAP of {0}".format("df_p1Y2"))
sns.heatmap(df_p1Y2, ax=ax1, annot=True, cbar=True, cmap='Blues', fmt='.2f')
# p2
ax2 = fig.add_subplot(3, 2, 3)
ax2.set_title("HEATMAP of {0}".format("df_p2Y2"))
sns.heatmap(df_p2Y2, ax=ax2, annot=True, cbar=True, cmap='Blues', fmt='.2f')
# p3
ax3 = fig.add_subplot(3, 2, 4)
ax3.set_title("HEATMAP of {0}".format("df_p3Y2"))
sns.heatmap(df_p3Y2, ax=ax3, annot=True, cbar=True, cmap='Blues', fmt='.2f')
# p4
ax4 = fig.add_subplot(3, 2, 5)
ax4.set_title("HEATMAP of {0}".format("df_p4Y2"))
sns.heatmap(df_p4Y2, ax=ax4, annot=True, cbar=True, cmap='Blues', fmt='.2f')
# p5
ax5 = fig.add_subplot(3, 2, 6)
ax5.set_title("HEATMAP of {0}".format("df_p5Y2"))
sns.heatmap(df_p5Y2, ax=ax5, annot=True, cbar=True, cmap='Blues', fmt='.2f')
# ---
plt.show()
#file_mapout = foldername + "pic" + code_cnv_input[i]  + ".png" # ファイルパス名の生成
#plt.savefig(file_mapout)

```

QEU:FOUNDER ： “このプログラムがCSVファイルでメトリックスを出力するだけなんです。まあ・・・、参考までだけど、ヒートマップを見てみましょう。これは感度（Y1）の部分・・・。”

![image3-43-1](https://yaber1965.github.io/images/image3-43-1.jpg)

D先生 ： “高い感度(Y1)はコネクタの端の部分に来るようです。だからどうだとは言えませんが・・・。”

![image3-43-2](https://yaber1965.github.io/images/image3-43-2.jpg)

D先生 ： “SN比の場合はSN比（Y2）が中心部に位置しています。面白い特性ですね。”

QEU:FOUNDER ： “ここでCMです。カンパをください・・・。”

### [＞寄付のお願い(Donate me)＜](https://www.paypal.com/paypalme/QEUglobal?v=1&utm_source=unp&utm_medium=email&utm_campaign=RT000481&utm_unptid=29844400-7613-11ec-ac72-3cfdfef0498d&ppid=RT000481&cnac=HK&rsta=en_GB%28en-HK%29&cust=5QPFDMW9B2T7Q&unptid=29844400-7613-11ec-ac72-3cfdfef0498d&calc=f860991d89600&unp_tpcid=ppme-social-business-profile-creat-ed&page=main%3Aemail%3ART000481&pgrp=main%3Aemail&e=cl&mchn=em&s=ci&mail=sys&appVersion=1.71.0&xt=104038)

D先生 ： “どうぞ、よろしく。”

## ～　まとめ　～

### ・・・　前回のつづきになるかな？　・・・

C部長 ： “あの・・・。イケメン・バトルをやってもよろしいでしょうか・・・。”

![image3-43-3](https://yaber1965.github.io/images/image3-43-3.jpg)

QEU:FOUNDER ： “ちょっと待って・・・。前回のShear（共有）とフリーウェアについての話を少しだけ続けちゃっていい？”

![image3-43-4](https://yaber1965.github.io/images/image3-43-4.jpg)

D先生 : “そういえば、QEUシステムも「フリーウェア」といっていいんですかねぇ・・・？”

QEU:FOUNDER ： “十数年前のQEUシステムの発足初期のときには儲けることができないかと頑張ったけど、あきらめた・・・(笑)。Jeremy Howard, Jason Brownlee, Movan Zhouなどの偉大な先人（?）がいるから現在のQEUシステムがあるんだから・・・。”

![image3-43-5](https://yaber1965.github.io/images/image3-43-5.jpg)

D先生 ： “彼ら（↑）全員、FOUNDERよりも年下じゃないですか・・・（笑）。・・・でも、QEUシステムのコンセプトがこう（↑）だから、共有になるのも必然だったでしょうね。・・・でも、GNU_Emaxのようなエディタならばともかく、Linuxのようなスゴイものがフリー化してしまうのは経済の構造に大きな影響を与えるでしょうね。”

QEU:FOUNDER ： “そうですよ、だからY先生（経済学者）は好きだけど、経済関係のコメントは信用はしていない。経済学は2つの点で「本質的に間違っている」と思っているから・・・。”

D先生 ： “ほう・・・、2つの欠点とな？”

QEU:FOUNDER ： “**現代では、本当に価値のあるものが大量に共有化されてフリーになっている点**・・・。考え方によって細かな差異はあるだろうけど、基本、価値論の前提は「価値のあるモノの価格は高い」でしょ？でも、現代において「最も価値のあるモノがタダ」になったんです！！”

D先生 ： “それが労働の価値、非正規雇用にまで影響を及ぼしていると？”

QEU:FOUNDER ： “突き詰めるとそうなると思います。EMBEDDING（埋め込み）の概念って、経済学で扱っているのかな？もし用語を使っていなければ経済学はスカだな・・・（笑）。本当に価値のある共有物（Linux etc）がProcess InnovationにEmbedされると資本側が強化されすぎて社会が壊れる。間違えないでね、「Innovationはいい」ことなんだよ。（ここでは）副作用のことを言っているんだ・・・。一方、本当に価値ある共有物がProduct InnovationにEmbedされると経済と社会が大きく飛躍する。Elon Muskさんがいい例だね。彼は、上海とドイツの新工場で大変なProduct Innovationをやってのけています。それで社会的な問題が起きていないのは、彼の生み出したProduct Innova-tionの効果が上回っているからです。クルマを作っているT社がA国とJ国にあるけど比較してみて・・・。「Embed」というキーワードで・・・。”

D先生 ： “あえて比較はしません。A国のT社のクルマは「フリーになっている価値あるものを大いにEmbed」しています。アレがクルマかどうかは知らんけど・・・（笑）。”

![image3-43-6](https://yaber1965.github.io/images/image3-43-6.jpg)

QEU:FOUNDER ： “Embeddingというと、いかにも「Elonさんがフリーライドしている」ように誤解されるけど、**実際にはOpenAI（↑）などを通して大きな投資をしている**んです。彼の成功は必然だったの・・・。このように、世界の最も価値のあるものは共有されて、すでにタダになっています。現代におけるProduct Innovationの最良の手法はEmbedすることです。”

D先生 ： “要するに「コピペ」すればいいってことね・・・（笑）。”

QEU:FOUNDER ： “ちょっと・・・、同人誌ぐらいには工夫してよ・・・（笑）。衰退国家J国で、なぜかアニメだけが強いのは「同人」があるから、コミュニティにEmbedの意味が理解されているんです。じゃあ、次に経済学の問題点は「お金そのもの」・・・。”

D先生 ： “お金が悪いんですか？”

QEU:FOUNDER ： “**お金は「過去の記憶」です**。10年前のお金も残っているし、はては遠いナポレオン戦争の出来事もお金はしっかり記憶しています。お金をあまり気にするということは、「過去の亡霊に操られる」ことになりますし、現にそうなっています。”

D先生 ： “**「ロス〇ャイルドの陰謀」みたいな・・・**。”

QEU:FOUNDER ： “「お金の持つ記憶力」が人々にとって、そう見えるだけなんでしょう？でもね・・・、本来、**「お金は今生きている人のためのモノ」**です。よって、**お金は社会的に矛盾している**存在なんです。

![image3-43-7](https://yaber1965.github.io/images/image3-43-7.jpg)

QEU:FOUNDER ： “お金はモノを得るための手段の一つにすぎないのだから、現在進行形に考えるのならば**「経済学の議論の中心は生産力であるべき」**です。そうすれば、小生のイケメン（→）のいっている積極財政の意味がわかってくるでしょう？”

D先生 ： “たしかに、わかりやすくなります。そういえば、最近イケメンは「生産力という言葉を演説で使う」ようになってきています。”

<iframe width="560" height="315" src="https://www.youtube.com/embed/9h5I8ahLjU8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

QEU:FOUNDER ： “**この考え方のメリットは現代の特徴である「最も価値のある価格がない（共有されている）モノ」を正しく評価できるようになることです**。・・・こんなこと、天下のY先生も言わんでしょ？イケメンのほうが天才なんだから・・・（笑）。”

D先生 ： “FOUNDERが勝手に思っているイケメン（→）評です。念のため・・・。”

