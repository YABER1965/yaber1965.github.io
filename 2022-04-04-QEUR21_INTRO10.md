## QEUR21_INTRO10:　NN’erのためのTM（その10）～超能力AIの開発(その4)

### ～　ある意味、このロジックが理想形だが・・・　～

QEU:FOUNDER ： “じゃあ、超能力AIの件のまとめに入りましょう。そもそも、「超能力AI」の考え方ですが・・・。この図がコンセプトとしてわかりやすいのではないのか・・・？もちろん、「？」がたくさん出てくるのでしょうが・・・。”

![image1-10-1](https://yaber1965.github.io/images/image1-10-1.jpg)

D先生 ： “もちろん「？」だらけですよ・・・。例えば「想定範囲」って、何を意味しているのか？もっと根本的には、「超能力の定義はなにか？」などなど・・・”

QEU:FOUNDER ： “う～ん、いい質問だねえ（笑）。「超能力」と「想定範囲」のコンセプトには関連があります。「超能力はある職制を示す」と考えたほうがいいかな？こんな風に・・・。”

![image1-10-2](https://yaber1965.github.io/images/image1-10-2.jpg)

QEU:FOUNDER ： “超能力AIにはロバスト制御とレスポンス制御がベースになっています。D先生はある会社の品質部長をしている前に生産技術をやっていたんでしょう？そこで質問です。生産現場の新人の機械の動かし方はどのようでしたか？例えば、ハンドルの動き方とか・・・。”

D先生 ： “初心者は妙に落ち着きがなく、「カタカタ」とハンドルを動かしますね。”

QEU:FOUNDER ： “じゃあ、3年ぐらいの経験をもつ作業員は？”

D先生 ： “あまり動かさないですよ。ハンドルから手を放してもよい安定な条件を心得ているんでしょうね。”

QEU:FOUNDER ： “じゃあ、**「現場の神様、超人」**といわれた班長は機械を操作しますか？”

D先生 ： “班長は現場をパトロールしており、非常時しか作業しません。想定内の状態下では作業員でも十分対応できますし・・・。「想定範囲」・・・、そういうことか…。”

QEU:FOUNDER ： “超能力AIという名前だから制御能力が普通のAIよりも高いわけではありません。想定外の事態で行われる制御を行うAIであることが前提です。想定範囲内ではロバスト制御が有利です。制御手段がシンプルになりますからね・・・。しかし、想定外のことが起こった場合には、ロバストであることを停止し、レスポンスを最大にする必要があります。これを表現したのが、この図(↓)です。”

![image1-10-3](https://yaber1965.github.io/images/image1-10-3.jpg)

D先生 ： “なるほどね。パラメータ設計ではロバストであることを指向しますが、非常時の場合は反ロバストに敢て切り替えているんですね。”

QEU:FOUNDER ： “我々の昔の超能力AIロジックではタグチメソッドに倣い、外側構造（直交表）と内側構造（直交表）に分かれた数理システムを採用していました。今回の場合、外側と内側のすべてのシステムをディープラーニングで学習してあります。だから、学習した関数を使ってこの図に準じたプロットを描き出すだけです。簡単でしょ？”

## （内側構造）　～　（外側構造）

### ロバスト因子（item3,5）　～　g( [ XCs:回帰因子群] x [XBｓ：交互作用因子群] )

D先生 ： “前回学習した結果を使うんですね。さらに、重回帰分析によってロバスト因子と交互作用因子の「あたり」はついています。”

```python
#                   coef    std err          t      P>|t|      [0.025      0.975]
#--------------------------------------------------------------------------------
#Intercept       53.6389     12.197      4.398      0.000      29.729      77.549
#item1            0.0643      0.016      4.085      0.000       0.033       0.095
#item2           -1.3652      0.078    -17.584      0.000      -1.517      -1.213
#item4            0.0437      0.005      8.372      0.000       0.033       0.054
#item6            0.0054      0.001      7.842      0.000       0.004       0.007
#item8          -55.3086     12.415     -4.455      0.000     -79.646     -30.971
#item9            1.0311      0.138      7.473      0.000       0.761       1.302
#item10           1.3042      0.108     12.043      0.000       1.092       1.516
#item11           0.2763      0.017     16.599      0.000       0.244       0.309
#item3:item10    -0.4732      0.140     -3.369      0.001      -0.749      -0.198
#item5:item7     -0.0411      0.004    -10.944      0.000      -0.048      -0.034
#item5:item8     48.9807      7.258      6.748      0.000      34.752      63.209
#item5:item9    -12.8919      2.140     -6.025      0.000     -17.087      -8.697
#item5:item10    -6.2553      0.880     -7.107      0.000      -7.981      -4.530

```

QEU:FOUNDER ： “それではやってみましょう。プログラムをドン・・・。”

```python
# ---------------
# NN'erのためのタグチメソッド実験
# nn_demo_interaction_plot.py
# 層別されたディープラーニングの第四段階です
# 交互作用グラフを出力する、簡単な超能力AI(SUPER-AI)の実験です
# ---------------
# import libraries
import math, random
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# --------------
# Import `Sequential` from `keras.models`
from keras.models import Sequential 
# Import `Dense` from `keras.layers`
from keras.layers import Dense
# load_modelをインポートする
from tensorflow.python.keras.models import load_model

#=================================================
# definition of function
#=================================================
# T2予測計算の関数定義
def func_prediction(len_signal, mx_Xs_norm):

    #print(mx_Xs_norm)

    # T法(2)の解析結果
    arr_items   = [1 ,2 ,4 ,10 ,11]
    #	        item1	item2	item4	item10	item11
    arr_beta    = [0.2558, -0.0321, -0.6173, 0.0487, 0.5521]
    arr_snr     = [0.0132, 0.0383, 0.0097, 0.054, 0.219 ]

    arr_pred    = np.zeros(len_signal)
    total_snr   = np.sum(arr_snr)

    for iRow in range(len_signal):
        temp_pred   = 0
        for jCol in range(len(arr_items)): 
            jCol_item   = arr_items[jCol]
            temp_pred   = temp_pred + arr_snr[jCol]/arr_beta[jCol]*mx_Xs_norm[iRow, jCol_item]
        arr_pred[iRow]  = temp_pred / total_snr

    return arr_pred

# --------------
# TTTNNのためのインプット
def func_tttnn_input(len_signal, mx_Xs_signal, arr_Y_signal):

    # --------------
    # データセット全体の単位空間情報
    arr_Xs_mean = np.array([0.654709, 8.678700, 0.310673, 0.444709, 4.607175, 0.071143, 23.181614, 74.816143, 0.996080, 3.222152, 0.682646, 11.029596])
    val_Y_mean  = 7.0

    # ノルム化
    mx_Xs_norm  = mx_Xs_signal - arr_Xs_mean
    arr_Y_norm  = arr_Y_signal - val_Y_mean
    
    # -----
    # T法(2)で予測する
    arr_Y_pred  = func_prediction(len_signal, mx_Xs_norm)

    # [前回のアウトプット]T法(2)の解析結果
    # len_signal: 1447
    #	    item1	item2	item4	item10	item11
    #arr_beta = [ 0.2558 -0.0321 -0.6173  0.0487  0.5521]
    #arr_snr = [0.0132 0.0383 0.0097 0.054  0.219 ]
    # -----
    # 出力(y)のうち、予測(arr_Y_pred)分の値を削除する
    arr_Y_res   = np.zeros(len_signal)
    for iRow in range(len_signal):
        arr_Y_res[iRow]  = arr_Y_norm[iRow] - arr_Y_pred[iRow]

    return mx_Xs_norm, arr_Y_res

# --------------
# TTTNNのためのインプット
def func_output_tttnn(y_pred, len_signal, mx_Xs_norm, arr_Y_norm):

    # --------------
    # T法(2)で予測する
    arr_Y_pred  = func_prediction(len_signal, mx_Xs_norm)

    # -----
    # 出力(y)のうち、予測(arr_Y_pred)分の値を削除する
    with_Y_actual   = np.zeros(len_signal)
    with_y_pred     = np.zeros(len_signal)
    for iRow in range(len_signal):
        with_Y_actual[iRow] = arr_Y_norm[iRow] + arr_Y_pred[iRow]
        with_y_pred[iRow]   = y_pred[iRow] + arr_Y_pred[iRow]

    return with_y_pred, with_Y_actual

#=================================================
# Calculation class
#=================================================
# KerasのDLで機械学習を行う
class calc_optimization():

    def __init__(self):

        # --------------
        # Initialize the constructor
        self.model = Sequential()
         
        # Add an input layer(1)
        self.model.add(Dense(128, activation ='relu', input_shape =(12, )))
        # Add one hidden layer(2)
        self.model.add(Dense(128, activation ='relu'))
        # Add one hidden layer(3)
        self.model.add(Dense(128, activation ='relu'))
        # Add one hidden layer(4)
        self.model.add(Dense(128, activation ='relu'))
        # Add an output layer
        self.model.add(Dense(1))

        # Model output shape
        self.model.output_shape
         
        # Model summary
        self.model.summary()
         
        # Model config
        self.model.get_config()

        # モデルを読み込む
        self.model = load_model('tttnn_test.h5')

        # --------------
        # loading the data
        df = pd.read_csv(file_csv_input)

        # --------------
        # コラム名を変更する
        # 変更前：type, fixed acidity,volatile acidity,citric acid,residual sugar,chlorides,free sulfur diox-ide,
        #       total sulfur dioxide,density,pH,sulphates,alcohol  ,(quality)
        # 変更後：item0, 　item1      ,item2           ,item3      ,item4         ,item5    ,item6              
        #       item7               ,item8  ,item9 ,item10 ,item11 ,(quality)
        df2 = df.copy()
        df2.columns = ['item0','item1','item2','item3','item4','item5','item6','item7','item8','item9','item10','item11','quality','attr','attr2']
        #print(df2)

        # --------------
        # 評価用のデータセット
        df_test    = df2[df2['attr2']==3]
        #print(df_test)

        self.num_df_test = len(df_test)
        print('num_df_test:',self.num_df_test)

        self.mx_Xs_test = df_test.loc[:,"item0":"item11"].values
        #print(self.mx_Xs_test)
        self.arr_type_test = df_test.loc[:,"item0"].values
        #print(self.arr_type_test)
        self.arr_Y_test = df_test.loc[:,"quality"].values
        #print(self.arr_Y_test)

        # TTTNNのためのインプット(Test)
        self.mx_Xs_test, self.arr_Y_test   = func_tttnn_input(self.num_df_test, self.mx_Xs_test, self.arr_Y_test)

        # ----------------
        # Predicting the Value
        y_pred_wo = self.model.predict(self.mx_Xs_test).flatten()
        print("--- y_pred_wo ---")
        print(y_pred_wo)

        # ----------------
        # T法(2)補正を含む
        # TTTNNのためのアウトプット(Test)
        with_y_pred, self.arr_Y_test   = func_output_tttnn(y_pred_wo, self.num_df_test, self.mx_Xs_test, self.arr_Y_test)
        print("--- with_y_pred ---")
        print(with_y_pred)

        # ----------------
        # 超能力AIのための計算
        self.calc_spAI()

    # ----------------
    # 超能力AIのための計算
    def calc_spAI(self):

        arr_X_mean  = []
        arr_X_q25   = []
        arr_X_q75   = []
        mx_ptXs     = np.zeros([12,5])
        # ---
        for jCol in range(12):
            mean_X      = np.mean(self.mx_Xs_test[:,jCol])
            ptX_array   = np.percentile(self.mx_Xs_test[:,jCol], q=[0, 25, 50, 75, 100])
            # ---
            arr_X_mean.append(mean_X)
            arr_X_q25.append(ptX_array[1])
            arr_X_q75.append(ptX_array[3])
            mx_ptXs[jCol,:]    = ptX_array
            #print("jCol:{}, mean_X:{}, ptX_array:{}".format(jCol, mean_X, ptX_array))
        #print("arr_X_mean:{}".format(arr_X_mean))
        #print("arr_X_q25:{}".format(arr_X_q25))
        #print("arr_X_q75:{}".format(arr_X_q75))            
        #print("--- mx_ptXs ---")
        #print(mx_ptXs)

        # ----------------
        # Xsマトリックスの生成
        mx_Xs_input = np.zeros([10,12])

        # ---
        for iRow in range(10):
            mx_Xs_input[iRow, :] = arr_X_mean
            # ---
            # item3はロバスト因子
            if iRow <= 4:
                mx_Xs_input[iRow, numb_robust]    = arr_X_q25[numb_robust]
            else:
                mx_Xs_input[iRow, numb_robust]    = arr_X_q75[numb_robust]
            # ---
            # item7は交互作用因子
            klist = iRow%5
            mx_Xs_input[iRow, numb_intact]    = mx_ptXs[numb_intact, klist]
        #print("--- mx_Xs_input ---")
        #print(mx_Xs_input)

        # ----------------
        # Predicting the Value
        y_pred_output = self.model.predict(mx_Xs_input).flatten()
        # ----------------
        # 交互作用を散布図で作画する
        self.plot_interaction(mx_ptXs[jCol,:], y_pred_output)

    # ----------------
    # 交互作用を散布図で作画する
    def plot_interaction(self, ptX_array, y_pred):

        # 2種類に層別する
        arr_Y_q25   = []
        arr_Y_q75   = []
        for iRow in range(10):
            if iRow <= 4:
                arr_Y_q25.append(y_pred[iRow])
            else:
                arr_Y_q75.append(y_pred[iRow])

        # 予測精度を確認する
        fig = plt.figure(figsize=(8,5))

        # 散布図の作画
        ax1 = fig.add_subplot(1,1,1)
        ax1.scatter(ptX_array, arr_Y_q25, color="red", label="q25(robust)")
        ax1.scatter(ptX_array, arr_Y_q75, color="blue", label="q75(robust)")
        ax1.set_title('interaction between R-item{} and I-item{}'.format(numb_robust, numb_intact), fontsize=16)
        ax1.set_xlabel('X(interaction)')
        ax1.set_ylabel('Y')
        ax1.legend(loc='upper left', fontsize=10)
        fig.tight_layout()
        plt.show()

#=================================================
# main function            
#=================================================
if __name__  == '__main__':

    # ---------------------------
    # フォルダ指定
    folder_input    = "./"  # My project folder
    folder_csvout   = "./"  # My project folder

    # ---------------------------
    # ロバスト因子と交互作用因子の番号
    numb_robust     = 3
    numb_intact     = 7

    # ---------------------------
    # 機械学習用のCSVファイルを定義する
    nam_csv_input   = "機械学習のCSVデータ" 
    nam_code_input  = "train_wineq_train1.csv" # CSVコードの指定
    file_csv_input  = folder_input + nam_code_input  # ファイルパス名の生成 
    print("入力用CSVファイル名 ：{0}".format(file_csv_input))

    # ---------------------------
    # 出力用のCSVファイルを定義する
    nam_csvout  = "出力用CSVデータ" 
    code_csvout = "output_SpAI.csv" # CSVコードの指定
    file_csvout = folder_csvout + code_csvout  # ファイルパス名の生成
    print("------------ 計測データ出力用のCSV名 -------------")   
    print("出力用CSVファイル名 ：{0}".format(file_csvout))

    # ---------------------------
    # 機械学習を行う
    calc_optimization()

```

QEU:FOUNDER ： “じゃあ重回帰分析の結果に基づき、順次結果を見てみましょう。まずは、ロバスト因子をitem3に設定した場合です。”

![image1-10-4](https://yaber1965.github.io/images/image1-10-4.jpg)

D先生 ： “いやあ・・・、結果の解釈に困る・・・。生データのプロット（左上図）じゃ、実際の傾向が正確にわからないから・・・。一つ言えるのは、グラフ中の回帰線は合っていないですね。”

![image1-10-5](https://yaber1965.github.io/images/image1-10-5.jpg)

QEU:FOUNDER ： “そこらへんは「心の眼」でみましょう。交互作用があるだと・・・（笑）。それでは、ロバスト因子がitem5の場合を見てみましょう。まずは交互作用が明らかにない場合です・・・。”

![image1-10-6](https://yaber1965.github.io/images/image1-10-6.jpg)

D先生 ： “確かに交互作用はないですね。”

![image1-10-7](https://yaber1965.github.io/images/image1-10-7.jpg)

QEU:FOUNDER ： “一方、若干ですが交互作用が見えるグラフがありました。D先生、もし班長だったとして非常時にどんなアクションをとりますか？”

D先生 ： “ロバスト因子(item5)の値をなるべく下げ、交互作用因子(item9)の値をできるだけ上げれれば最大のパフォーマンスがでます。ただし、item5のロバスト因子は複数の因子と交互作用があります。制御が不安定になりやすいので、非常時が終われば採用をやめたい作業ではあります。”

QEU:FOUNDER ： “よし・・・。これで超能力AIのデモは終わりです。”

D先生 ： “なるほどね・・・。でも、この予測結果が正しいのか判断が難しいですね。”

QEU:FOUNDER ： “「学習データが足らないかも」という意味？こればっかりは、自分で検証実験をして、不足部分があれば工夫してほしいです。学習データを少なくするには、タグチメソッドのように外側構造と内側構造を設けて最適化するしかないですね。”

D先生 ： “デモをやれませんか？”

QEU:FOUNDER ： “「総合SN比」の事例説明ねぇ。良い事例がないかを考えてみましょう。”


## ～　まとめ　～

### ・・・　「美人政治家バトル」にタイトル変えか？　・・・

C部長 : “えっへん・・・。今回はバトルをやりましょう。”

![image1-10-8](https://yaber1965.github.io/images/image1-10-8.jpg)

D先生 ： “あらかじめいいます。参りました・・・。”

C部長 : “いやぁ・・・。いいこというなぁ・・・。”

![image1-10-9](https://yaber1965.github.io/images/image1-10-9.jpg)

QEU:FOUNDER ： “ここまでヤルのか・・・。”

D先生 ： “番組の終わりの終わりにこのコメントは卑怯だ・・・。”

C部長 : “あと1分と急かされて、コメントを単純にしただけです（笑）。”

QEU:FOUNDER ： “こんな展開って日本政治史になかったんじゃない？いいのか、悪いのか・・・。”

C部長 : “みんなが政治に関心を持ってくれればいいんです。”


