## QEUR21_RL2048T11:　Pattern Feature Engineering(その1) ～ パターンを準備する

## ～　準備運動！　～

D先生 ： “それでは、いよいよ本命のステップにつづきます。その手法のお名前は？”

QEU:FOUNDER ： “**パターンRTメトリックス**（笑）！「RT法はパターン認識のためだろ」というツッコミは華麗にスルー・・・。いままでのRT法メトリックスとは、作り方が逆になっています。前回の「スライドRTメトリックス」を例として思い出してくれればわかりやすいよ・・・。”

**（従来RT法：　スライドRTメトリックスetc）**

![imageRL1-20-1](https://yaber1965.github.io/images/imageRL1-20-1.jpg)

**（パターンRT法: 今回のプロジェクトで提案）**

![imageRL1-20-2](https://yaber1965.github.io/images/imageRL1-20-2.jpg)

D先生 ： “なるほど、**RTメトリックスを主成分（principal components）的に使う**という考え方ですね。そのメリットは？”

![imageRL1-20-3](https://yaber1965.github.io/images/imageRL1-20-3.jpg)

QEU:FOUNDER ： “そのメリットは・・・、DL関数がとんでもなく簡単になりますよ。これはシステム設定の前提だが・・・、メトリックスは「命令=パターン」になるように一意（ユニーク）に設定するんです。前回のスライド型RTでのトライアルの命令の生成を思い出してください。命令が0と1がほとんどになり、結果として右上に高い値のパネルが固まったでしょう。このように命令のもつ傾向を利用して、パターンを設定して・・・。”

**（命令がもつ「パターン」）**

![imageRL1-20-4](https://yaber1965.github.io/images/imageRL1-20-4.jpg)

D先生 ： “前回、前々回のプロジェクトでは、学習を通じて命令が0と１に偏っていました。実際には、最強のゲーム戦略のパターンのうち1/4も終わっていないわけですね。”

-     ### 数字を上へ -> 1
-     ### 数字を下へ -> 3
-     ### 数字を左へ -> 0
-     ### 数字を右へ -> 2

- 命令0（左）と命令1（上）　→　パターンが左上に偏る
- 命令0（左）と命令3（下）　→　パターンが左下に偏る
- 命令2（右）と命令1（上）　→　パターンが右上に偏る
- 命令2（右）と命令3（下）　→　パターンが右下に偏る

QEU:FOUNDER ： “2048ゲームの学習を効率よくするには、これらのパターンでメトリックスを作って、学習する必要があります。”

D先生 ： “そのためには？”

QEU:FOUNDER ： “プログラムをドン・・・！！”

```python
# ----------------
# 2048ゲームのマニュアル操作システム
# step3 : RTを動的メトリックスとして活用する
# step3 : random_collection_tkgame2048.py
# step3 : データの収集を行います
# Environment(RT_auto_game_2048_2.py)は以下のWebからの引用です
# https://iter01.com/565336.html
# ---------------- 
# 数値計算のﾗｲﾌﾞﾗﾘ読み込み
import math
import pandas as pd
from collections import Counter
import numpy as np
from scipy.special import softmax
import copy, random, time
from IPython.display import clear_output
# ---------------- 
import matplotlib.pyplot as plt
#matplotlib.rcParams['font.size'] = 20
#%matplotlib inline
# ---------------- 
# environment
import RT_auto_game_2048_2

# =================================================
# difinition of function
# =================================================
# イレギュラー検出関数(タイル移動後の状態とスコア)
def is_invalid_action(state, a_order):
    # ----------------
    spare = copy.deepcopy(state)  # 状態
    #print("spare",type(spare))
    reward = 0  # 当該行動による報酬
    if a_order == 0:
        for y in range(4):
            z_cnt = 0
            prev = -1
            for x in range(4):
                if spare[y, x] == 0:
                    z_cnt = z_cnt + 1
                elif spare[y, x] != prev:
                    tmp = spare[y, x]
                    spare[y, x] = 0
                    spare[y, x - z_cnt] = tmp
                    prev = tmp
                else:
                    z_cnt = z_cnt + 1
                    spare[y, x - z_cnt] *= 2
                    reward += spare[y, x - z_cnt]
                    spare[y, x] = 0
                    prev = -1
    elif a_order == 1:
        for x in range(4):
            z_cnt = 0
            prev = -1
            for y in range(4):
                if spare[y, x] == 0:
                    z_cnt = z_cnt + 1
                elif spare[y, x] != prev:
                    tmp = spare[y, x]
                    spare[y, x] = 0
                    spare[y - z_cnt, x] = tmp
                    prev = tmp
                else:
                    z_cnt = z_cnt + 1
                    spare[y - z_cnt, x] *= 2
                    reward += spare[y - z_cnt, x]
                    spare[y, x] = 0
                    prev = -1
    elif a_order == 2:
        for y in range(4):
            z_cnt = 0
            prev = -1
            for x in range(4):
                if spare[y, 3 - x] == 0:
                    z_cnt = z_cnt + 1
                elif spare[y, 3 - x] != prev:
                    tmp = spare[y, 3 - x]
                    spare[y, 3 - x] = 0
                    spare[y, 3 - x + z_cnt] = tmp
                    prev = tmp
                else:
                    z_cnt = z_cnt + 1
                    spare[y, 3 - x + z_cnt] *= 2
                    reward += spare[y, 3 - x + z_cnt]
                    spare[y, 3 - x] = 0
                    prev = -1
    elif a_order == 3:
        for x in range(4):
            z_cnt = 0
            prev = -1
            for y in range(4):
                if spare[3 - y, x] == 0:
                    z_cnt = z_cnt + 1
                elif spare[3 - y, x] != prev:
                    tmp = state[3 - y, x]
                    spare[3 - y, x] = 0
                    spare[3 - y + z_cnt, x] = tmp
                    prev = tmp
                else:
                    z_cnt = z_cnt + 1
                    spare[3 - y + z_cnt, x] *= 2
                    reward += spare[3 - y + z_cnt, x]
                    spare[3 - y, x] = 0
                    prev = -1

    if (state - spare).any() == False:
        return True, reward, spare
    else:
        return False, reward, spare


# ----------------
# 移動可能な方向をまとめ、RTメトリックスを生成する
def calc_mxlog2(arr_state):    

    # tsr_spareを対数化する
    for jCol in range(16):
        raw_value = arr_state[jCol]
        # print("make_metrics - raw_value",raw_value)
        if raw_value > 0:
            arr_state[jCol] = math.log2(raw_value)
        else:
            arr_state[jCol] = 0

    return arr_state


# ----------------
# 移動可能な方向をまとめ、RTメトリックスを生成する
def calc_movables(state):    

    # --------------------------------------------------
    # 配列の初期化
    spare = np.array(state)
    # --------------------------------------------------
    # オリジナル操作方法 -> 数字に変更します(ENVIRONMENT)
    # 数字を上へ -> 1
    # 数字を下へ -> 3
    # 数字を左へ -> 0
    # 数字を右へ -> 2
    # --------------------------------------------------
    a_map, movables, arr_rewards = [0, 1, 2, 3], [], []
    iCnt, arr_states = 0, []
    for i_map in a_map:
        flg_invalid, val_reward, spare_next = is_invalid_action(spare, i_map)
        if flg_invalid == False:
            arr_states.append(spare_next.flatten())
            arr_rewards.append(val_reward + 4)
            movables.append(i_map)
            iCnt = iCnt + 1
    num_avail = iCnt

    return num_avail, movables, arr_rewards


# ----------------
def find_action(state, num_avail, movables, iCnt_turn):

    # --------------------------------------------------
    # オリジナル操作方法 -> 数字に変更します(ENVIRONMENT)
    # 数字を上へ -> 1
    # 数字を下へ -> 3
    # 数字を左へ -> 0
    # 数字を右へ -> 2
    # --------------------------------------------------
    a_order, gameover, is_invalid = 0, False, True
    a_map = [0,1]   # 数字を左へ -> 0, 数字を上へ -> 1
    #a_map = [0,3]   # 数字を左へ -> 0, 数字を下へ -> 3
    #a_map = [2,1]   # 数字を右へ -> 2, 数字を上へ -> 1
    #a_map = [2,3]   # 数字を右へ -> 2, 数字を下へ -> 3
    if (num_avail == 0):
        gameover = True
        acType = "gameover"
        print("ゲームオーバー")
    else:
        acType = "random"
        a_order = np.random.choice(a_map)   # 初期にわざと偏らせる
        if movables.count(a_order) == 0:
            acType = "stuck"
            a_order = np.random.choice(movables)              
    #print("ターン:{0}, 行動選択:{1}".format(iCnt_turn, a_order))
 
    return a_order, acType


#=================================================
# Game Agent class
#=================================================
# ゲームを動かす（エージェント）
class Agent():
    # -------
    def __init__(self):

        # --------------------------------------------------
        # 記録用パラメタ類(プレイベース)の初期化
        self.arr_iCnt_play  = []  # count game play    プレイ番号
        self.arr_maxturn    = []  # max_turn   ゲームのターン数
        self.arr_csv_play   = []  # name game play    プレイファイル名のリスト
        self.arr_maxscore   = []  # rl_score game play    最終プレイスコア

        # --------------------------------------------------
        gamepanel       = RT_auto_game_2048_2.Board()
        self.game2048   = RT_auto_game_2048_2.Game(gamepanel)
        self.game2048.gamepanel.gridCell = np.array([[0, 2, 4, 0], [2, 0, 16, 0], [0, 0, 2, 0], [0, 8, 0, 4]])
        # ------
        for iCnt_play in range(num_episodes):       # num_episodes

            # --------------------------------------------------
            # 1ゲームだけプレイする
            num_maxturn, num_maxscore = self.get_episode(iCnt_play)
            #print("num_maxturn:{}, num_maxscore:{}".format(num_maxturn, num_maxscore))

            # --------------------------------------------------
            # CSV ファイル (file_csvout) として出力する
            code_csvout = "game2048_play{0}_{1}_score{2}.csv".format(iCnt_play, file_comment, num_maxscore)       # file name  
            file_csvout = folder_csvout + code_csvout
            print("メトリックス保管用CSVファイル名 ：{0}".format(code_csvout))
            # ゲームデータの出力
            self.save_csvGAME(iCnt_play ,file_csvout)        # ゲームCSVファイルに保存する

            # --------------------------------------------------
            # 記録用パラメタ類(プレイベース)の追加
            self.arr_iCnt_play.append(iCnt_play)  # count game play    プレイ番号
            self.arr_maxturn.append(num_maxturn)  # max_turn   ゲームのターン数
            self.arr_csv_play.append(code_csvout)  # name game play    プレイファイル名のリスト
            self.arr_maxscore.append(num_maxscore)  # rl_score game play    最終プレイスコア

        # --------------------------------------------------
        # 出力履歴をグラフ表示する    
        x = list(range(num_episodes))
        
        fig = plt.figure(figsize=(12, 6))
        ax1 = fig.add_subplot(1, 2, 1)
        ax1.set_title('Generating Result : maxturn')
        ax1.plot(x, self.arr_maxturn)
        ax1.set_xlabel('#episode')
        ax1.set_ylabel('#turn')
        # -----
        ax2 = fig.add_subplot(1, 2, 2)
        ax2.set_title('Generating Result : maxscore')
        ax2.set_xlabel('#episode')
        ax2.set_ylabel('#score')
        ax2.plot(x, self.arr_maxscore)
        #ax2.legend(loc='best')
        plt.show()

        # --------------------------------------------------
        # ゲームプレイリストをCSVファイルに保存する
        self.save_playlist()

        # --------------------------------------------------
        self.game2048.gamepanel.window.mainloop()


    # --------------------------------------------------
    # 各ゲームの流れ
    def get_episode(self, iCnt_play): 

        # --------------------------------------------------
        acType, val_reward, rl_done, a_order  = "random", 0, False, 0
        ttlscore_next, ttlscore = 0, 0
        iCnt_turn , num_maxturn, num_maxscore = 0, 0, 0

        # --------------------------------------------------   
        # 記録用パラメタ類(ターンベース)
        self.arr_icount = []        # カウンタリスト
        self.arr_action = []        # 指示リスト
        self.arr_avail = []         # 使用可能な命令数リスト
        self.arr_ttlscore = []      # ゲームスコアリスト(真数)  
        self.arr_reward = []        # 報酬リスト(真数)  
        self.arr_yzero = []         # ゼロ・スコアの数
        self.arr_acType = []        # 指示タイプ(random,machine)
        self.mx_logstate = []       # 状態(対数)

        # --------------------------------------------------
        # ゲーム・エピソードを行う
        state = self.reset()    # 環境をﾘｾｯﾄする
        num_avail, movables, arr_rewards = calc_movables(state)
        #print(" state   :    ", state)
        while True:
        
            # --------------------------------------------------
            # 命令を選択する
            action, acType = find_action(state, num_avail, movables, iCnt_turn)         
            # 環境(ENVIRONMENT)を実行する
            state_next, ttlscore_next, done = self.game2048.link_keys(action)
            num_avail_next, movables_next, arr_rewards_next = calc_movables(state_next)
            # 報酬の正規量を計算する
            val_reward = ttlscore_next - ttlscore

            # --------------------------------------------------
            # 右上角部に小さなタイルがあれば罰金、大きいタイルがあれば賞金
            board_flatten = np.array(state).flatten()
            cc = Counter(board_flatten)
            self.arr_yzero.append(cc[0]) 
            # ---------- 
            self.arr_icount.append(iCnt_turn)       # カウンタリスト
            self.arr_action.append(action)        # 指示リスト
            self.arr_avail.append(num_avail)     # 使用可能な命令数リスト
            self.arr_ttlscore.append(ttlscore)      # ゲームスコアリスト(真数)  
            self.arr_reward.append(val_reward)       # 報酬リスト(真数)  
            self.arr_acType.append(acType)       # 指示タイプ(random,stuck)  
            # ---------- 
            # 移動可能な方向をまとめ、RTメトリックスを生成する
            arr_state = np.array(state).flatten()
            arr_logstate = calc_mxlog2(arr_state)
            if iCnt_turn == 0:
                self.mx_logstate = [arr_logstate]       # 状態(対数)
            else:
                self.mx_logstate = np.vstack([self.mx_logstate, arr_logstate])       # 状態(対数)

            # --------------------------------------------------
            # ターンを繰り返すか、ゲームを終わるか
            ttlscore    = ttlscore_next
            state       = state_next
            num_avail   = num_avail_next
            movables    = movables_next
            arr_rewards = arr_rewards_next
            iCnt_turn   = iCnt_turn + 1
            
            # -------------------------------------------------- 
            # ゲームオーバーの場合の処理
            if done == True:
                # 次に引き渡す変数
                num_maxturn, num_maxscore = iCnt_turn, ttlscore
                #print(self.mx_logstate)
                # ループから外れる
                break

        return num_maxturn, num_maxscore

        
    # --------------------------------------------------
    # GAME2048データベースをCSVファイルに保存する
    def save_csvGAME(self, iCnt_play ,file_csvout): 

        # --------------------------------------------------
        # データフレームを作成する
        arr_columnsA = ["turn", "order", "reward", "navail", "score", "yzero", "acType"]
        arr_columnsB = ["p{}".format(i) for i in range(16)]
        arr_columns  = arr_columnsA + arr_columnsB
        temp_csvout  = np.vstack([self.arr_icount, self.arr_action, self.arr_reward, self.arr_avail, self.arr_ttlscore, self.arr_yzero, self.arr_acType])
        mx_csvout    = temp_csvout.T
        mx_csvout    = np.concatenate([mx_csvout, self.mx_logstate], axis=1)
        print("----- play_turn:{0} -----".format(iCnt_play))
        print(mx_csvout)
        # --------------------------------------------------
        # CSV出力用のデータフレームを作る
        df_csvout = pd.DataFrame(mx_csvout, columns=arr_columns)
        #print("----- play_turn:{0} -----".format(iCnt_play))
        #print(df_csvout)
        df_csvout.to_csv(file_csvout, index=False)


    # ----------------
    # ゲームをﾘｾｯﾄする
    def reset(self):   
    
        state_init = np.array([[0, 2, 4, 0], [2, 0, 16, 0], [0, 0, 2, 0], [0, 8, 0, 4]])
        # --------------------------------------------------
        # パラメタの初期化(Panel)
        self.game2048.gamepanel.gridCell=state_init
        self.game2048.gamepanel.compress=False
        self.game2048.gamepanel.merge=False
        self.game2048.gamepanel.moved=False
        self.game2048.gamepanel.score=0
        
        # --------------------------------------------------
        # パラメタの初期化(Game)
        self.game2048.end=False
        self.game2048.won=False

        # --------------------------------------------------   
        # 記録用リストの初期化(Agentに連結する)
        self.arr_icount = []      # カウンタリスト
        self.arr_action = []       # 指示リスト
        self.arr_avail = []       # 使用可能な命令数リスト
        self.arr_acType = []      # 指示タイプ(random,machine)
        self.arr_yzero = []       # ゼロ・スコアの数
        # ------- 
        self.arr_ttlscore = []    # ゲームスコアリスト(真数)  
        self.arr_reward = []      # 報酬リスト(真数)  
        # -------  
        self.arr_Y1left, self.arr_Y1up, self.arr_Y1right, self.arr_Y1down = [], [], [], []
        self.arr_Y2left, self.arr_Y2up, self.arr_Y2right, self.arr_Y2down = [], [], [], []

        return state_init


    # --------------------------------------------------
    # ゲームプレイリストをCSVファイルに保存する
    def save_playlist(self): 

        # --------------------------------------------------
        # データフレームを作成
        arr_columns = ["iplay", "maxturn", "maxscore", "code_csvout"]
        # print("arr_columns : {0}".format(arr_columns))

        # --------------------------------------------------
        # CSV出力用のデータフレームを作る(1)
        temp_csvout = np.vstack([self.arr_iCnt_play, self.arr_maxturn, self.arr_maxscore, self.arr_csv_play])
        mx_csvout   = np.array(temp_csvout).T
        # print("----- playlist -----")
        # print(mx_csvout)
        df_csvout = pd.DataFrame(mx_csvout, columns=arr_columns)
        print("----- playlist -----")
        print(df_csvout)
        # -----
        df_csvout.to_csv(file_csv_playlist, index=False)


#=================================================
# main function            
#=================================================
if __name__ == "__main__":

    # ---------------------------
    # DQN Parameter
    state_size  = 8
    action_size = 4

    # ---------------------------
    # マスクﾌｧｲﾙﾌｧｲﾙの指定と内容出力
    folder_csvout   = "./ARRAY_RTCNN/"  # My project folder
    file_comment    = "order0-1"

    # --------------------------------------------------
    # バッチNOの定義（初回なので0）
    SLEEP_TIME      = 0.01          # スリープ間隔
    num_episodes    = 20           # 学習の繰り返し数

    # --------------------------------------------------
    # ゲームプレイリスト用のCSVファイルを定義する
    nam_csv_playlist    = "ゲームプレイリストのCSVデータ" 
    code_csv_playlist   = "train_playlist_{}.csv".format(file_comment)         # CSVコードの指定
    file_csv_playlist   = folder_csvout + code_csv_playlist     # ファイルパス名の生成
    print("------------ 計測データ出力用のCSV名 -------------")   
    print("ゲームプレイリストのCSVファイル名 ：{0}".format(file_csv_playlist))

    # ---------------------------
    # ゲームを動かす（エージェント）
    Agent()

```

QEU:FOUNDER ： “まずは、このようなモノが出力されます。”

![imageRL1-20-5](https://yaber1965.github.io/images/imageRL1-20-5.jpg)

D先生 ： “命令を0と1に固定させるだけで、ディープラーニングもなしで簡単に3000ポイントはかるく出るんですね。で・・・、なんで折れ線グラフ・・・？”

QEU:FOUNDER ： “本当ならばヒストグラムですよね。後は、このようなCSVファイルが大量にでてきます。”

![imageRL1-20-6](https://yaber1965.github.io/images/imageRL1-20-6.jpg)

D先生 ： “あれ？p1-p16ってボードの数字ですよね。数字がおかしい・・・.”

QEU:FOUNDER ： “対数化されているんです。あとは次回につづきます。つきましてはカンパください！！”

### [＞寄付のお願い(Donate me)＜](https://www.paypal.com/paypalme/QEUglobal?v=1&utm_source=unp&utm_medium=email&utm_campaign=RT000481&utm_unptid=29844400-7613-11ec-ac72-3cfdfef0498d&ppid=RT000481&cnac=HK&rsta=en_GB%28en-HK%29&cust=5QPFDMW9B2T7Q&unptid=29844400-7613-11ec-ac72-3cfdfef0498d&calc=f860991d89600&unp_tpcid=ppme-social-business-profile-creat-ed&page=main%3Aemail%3ART000481&pgrp=main%3Aemail&e=cl&mchn=em&s=ci&mail=sys&appVersion=1.71.0&xt=104038)

D先生 ：“よろしくお願いします。”

## ～　まとめ　～

QEU:FOUNDER ： “おヨヨ・・・、およョ・・・・（泣）。”

<iframe width="560" height="315" src="https://www.youtube.com/embed/K6qz36k3MPo" ti-tle="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; en-crypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

C部長 : “何、泣いてるんです？”

D先生 : “あの人、さっきまでこの音楽（↓）を聴いていたんです・・・。”

<iframe width="560" height="315" src="https://www.youtube.com/embed/Hrr3dp7zRQY" ti-tle="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; en-crypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

D先生 : “この音楽家は北海道では有名です。たしか、昔、FOUNDERは彼のライブハウスに行かなかったっけ・・・？”

QEU:FOUNDER ： “彼の「スロウボート」には行きたかったんだけど、当日にライブがなかったので近くの「ハーフノート」にしました。でも、とても良かったよ。札幌って、そんなに大きくもない都市なのに、あちこちでジャズが聞けていいところだと思ったわ・・・。”

C部長 : “え～っづ！いいなぁ・・・。”

QEU:FOUNDER ： “Yooooutube再生回数を見てごらん・・・。”

![imageRL1-20-7](https://yaber1965.github.io/images/imageRL1-20-7.jpg)

C部長 : “**動画再生回数が1200万回**！？ウソだろ・・・。”

![imageRL1-20-8](https://yaber1965.github.io/images/imageRL1-20-8.jpg)

D先生 : “札幌JAZZ界のローカル・スターのはずなんですが、英語のWikiまで見つかりました。一体、なにが起こったんでしょうか・・・。”

![imageRL1-20-9](https://yaber1965.github.io/images/imageRL1-20-9.jpg)

C部長 : “どうやら、彼が亡くなる直前に何気なくアップした動画が大ヒットして1200万回をたたき出したようですね。”

![imageRL1-20-10](https://yaber1965.github.io/images/imageRL1-20-10.jpg)

QEU:FOUNDER ： “どうやら**AIの一種のバグ**だったらしい・・・。「体を壊す前にバグってくれよ・・・」と思い、泣けてきた・・・。”

D先生 : “この人の運命なんでしょうね。ただし、彼は音楽家の中では恵まれていた人なんでしょう。”

QEU:FOUNDER: “これからは、芸術家をはじめ物価高で大変なことになるでしょう。”



