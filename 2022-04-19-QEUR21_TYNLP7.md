## QEUR21_TYNLP7:　自然言語解析(その7) ～ RTメトリックスの活用(その5)

## ～　失敗、でも十分に役には立った　～

### ・・・　RTメトリックスって、結構いいんだね　・・・

D先生 ： “じゃあ、次は主成分分析（PCA）ということで・・・。”

QEU:FOUNDER ： “もう特に言うことはないよね。プログラムをドン・・・。”

```python
# -------
#
# 自然言語処理(NLP)をRT法とSVMで解く
# その5　RTメトリックスを計算する（step5）
# step5_nlp_rtm_pca_scatter.py
#
# -------
import re, math , numpy as np, pandas as pd
import matplotlib.pyplot as plt

# ---------------------------
#import numpy as np, pandas as pd
# CSV読み込み
raw_train = pd.read_csv('data/pattern_fxxk_raw.csv', encoding = 'ISO-8859-1')
raw_train.head(10)

# ---------------------------
# RTメトリックス計算(新版)
def calc_RTmetrics(len_temp, max_jy_index, mx_valMesY, mean_valMesY): 

    # 変数の初期化
    lnr_yarray, btY1_yarray = [], []
    st_yarray, sb_yarray, se_yarray, ve_yarray = [], [], [], []
    yita_yarray, Y2_yarray = [], []

    # 有効除数の計算
    yuko = np.dot(mean_valMesY, mean_valMesY)
    #print('有効除数=:{0:.4f}'.format(yuko))

    # AVE_Y1とAVE_Y2を計算する
    # 線形式の計算
    for iRow in range(len_temp):
        sum_array = np.dot(mx_valMesY[iRow, :], mean_valMesY)
        lnr_yarray.append(sum_array)
        btY1_yarray.append(round(sum_array/float(yuko),4))
    #print('レコードix={0}の線形式：{1}'.format(iRow,lnr_yarray[0:5]))
    #print('レコードix={0}の感度：{1}'.format(iRow,btY1_yarray[0:5]))

    # 全変動ST及び各種中間指標SB,SE,VE,η
    for iRow in range(len_temp):
        sum_array = np.dot(mx_valMesY[iRow, :], mx_valMesY[iRow, :])
        st_yarray.append(sum_array)
        sb_yarray.append(lnr_yarray[iRow] ** 2 / float(yuko))
        se_yarray.append(st_yarray[iRow] - sb_yarray[iRow])
        # 異常処理
        temp_ve = se_yarray[iRow] / float(max_jy_index - 1.0)
        if temp_ve < 0.000001:
            comment = 'ゼロ異常発生！！'
            print(comment)
            ve_yarray.append(-0.1)   
            yita_yarray.append(-0.1)  
            Y2_yarray.append(-0.1) 
        else:
            temp_Y2 = math.sqrt(temp_ve)
            ve_yarray.append(temp_ve)   
            yita_yarray.append(1.0 / temp_ve)  
            Y2_yarray.append(round(math.sqrt(temp_Y2),4)) 
    #print('レコードix={0}の比例項変動：{1}'.format(iRow,sb_yarray[0:5]))
    #print('レコードix={0}の感度：{1}'.format(iRow,btY1_yarray[0:5]))

    return btY1_yarray, Y2_yarray

# ---------------------------
# 単位空間マトックスの生成
# 特定のnum_fxxk数を抽出し、平均をとる
num_Xs   = 90
num_fxxk = 9
mx_tani_Xs = np.zeros([num_fxxk, num_Xs])
for i in range(num_fxxk):
    df_raw_fxxk = raw_train[raw_train['num_fk']==i+1]
    mx_raw_fxxk = df_raw_fxxk.loc[:,"s0":].values
    for j in range(num_Xs):
        val_mean = np.mean(mx_raw_fxxk[:,j])
        mx_tani_Xs[i,j] = round(val_mean,3)
print(mx_tani_Xs)

# ---------------------------
# Y1-Y2マトリックスを生成する
select_sig  = [1,2,3,4,5,6,7,8,9]
select_tani = [1,2,3,4,5]
mx_metrics  = np.zeros([4176,10])
# -----
col_beta = 0
col_snr  = 1
for iTani in select_tani:

    # ------------------
    # RTメトリックス計算
    acc_btY1    = []
    acc_Y2      = []
    acc_sigY    = []
    for jSig in select_sig:

        # ------------------
        # 信号空間マトックスを抽出する
        df_raw_fxxk = raw_train[raw_train['num_fk']==jSig]
        num_signal = len(df_raw_fxxk)
        mx_sig_Xs  = df_raw_fxxk.loc[:,"s0":"s89"].values
        arr_sig_Y  = df_raw_fxxk.loc[:,"num_fk"].values
        #print(jSig, num_signal)
        # -----
        len_temp = num_signal
        max_jy_index = num_Xs
        npmx_valMesY = mx_sig_Xs
        mean_valMesY = mx_tani_Xs[iTani-1,:]
        # -----
        btY1_yarray, Y2_yarray = calc_RTmetrics(len_temp, max_jy_index, npmx_valMesY, mean_valMesY)
        acc_btY1 = acc_btY1 + btY1_yarray
        acc_Y2   = acc_Y2   + Y2_yarray
        acc_sigY = acc_sigY + arr_sig_Y.tolist()
    # ------------------
    # 結果の出力
    mx_metrics[:, col_beta] = acc_btY1
    mx_metrics[:, col_snr]  = acc_Y2
    col_beta = col_beta + 2
    col_snr  = col_snr + 2
    # ------------------
    # 結果の出力
    #print("----- iTani:{}, -----".format(iTani))
    #print("acc_btY1 : ", len(acc_btY1))
    #print("acc_Y2 : ", len(acc_Y2))
    #print("acc_sigY : ", len(acc_sigY))
# ------------------
# 結果の出力
print("----- mx_metrics -----")
print(mx_metrics)

# ------------------
# 次元の確認
mx_metrics.shape
#(4176, 10)

# ---------------------------
# 主成分分析
from sklearn.decomposition import PCA

pca = PCA(n_components=4)
components = pca.fit(mx_metrics).components_
components.shape
#(4, 10)
print(pca.explained_variance_ratio_)
print(pca.explained_variance_)
#[9.98737454e-01 6.71411349e-04 4.54880202e-04 8.40822259e-05]
#[1.16532957e+03 7.83404582e-01 5.30755453e-01 9.81073691e-02]

# ------------------
# 散布図を生成する
X_new = pca.transform(mx_metrics)

arr_x1, arr_y1 = [], []
arr_x2, arr_y2 = [], []
arr_x3, arr_y3 = [], []
arr_x4, arr_y4 = [], []
arr_x5, arr_y5 = [], []
arr_x6, arr_y6 = [], []
for i in range(4176):
    if acc_sigY[i] ==1:
        arr_x1.append(X_new[i, 0])
        arr_y1.append(X_new[i, 1])
    if acc_sigY[i] ==2:
        arr_x2.append(X_new[i, 0])
        arr_y2.append(X_new[i, 1])
    if acc_sigY[i] ==3:
        arr_x3.append(X_new[i, 0])
        arr_y3.append(X_new[i, 1])
    if acc_sigY[i] ==4:
        arr_x4.append(X_new[i, 0])
        arr_y4.append(X_new[i, 1])
    if acc_sigY[i] ==5:
        arr_x5.append(X_new[i, 0])
        arr_y5.append(X_new[i, 1])
    if acc_sigY[i] ==6:
        arr_x6.append(X_new[i, 0])
        arr_y6.append(X_new[i, 1])
#print(arr_x1)

# ------------------
# figureを生成する
fig = plt.figure(figsize=(16,8))
 
# axをfigureに設定する
ax1 = fig.add_subplot(1, 2, 1)
 
# プロットマーカーの大きさ、色、透明度を変更
ax1.scatter(arr_x1, arr_y1, s=100, alpha=0.5, linewidths=2, c='#aaaaFF', edgecolors='b', label='sig1')
ax1.scatter(arr_x2, arr_y2, s=100, alpha=0.5, linewidths=2, c='#aaFFaa', edgecolors='g', label='sig2')
ax1.scatter(arr_x3, arr_y3, s=100, alpha=0.5, linewidths=2, c='#FFaaaa', edgecolors='r', label='sig3')
ax1.set_title("principal components made from RT metrics(1,2,4)", fontsize=14)
ax1.set_xlim(-80,100)
ax1.set_ylim(-4,8)
ax1.set_xlabel("first component")
ax1.set_ylabel("second component")
ax1.legend(loc='best', borderaxespad=1, fontsize=14)
ax1.grid(True)

# axをfigureに設定する
ax2 = fig.add_subplot(1, 2, 2)
 
# プロットマーカーの大きさ、色、透明度を変更
ax2.scatter(arr_x4, arr_y4, s=100, alpha=0.5, linewidths=2, c='#aaaaFF', edgecolors='b', label='sig4')
ax2.scatter(arr_x5, arr_y5, s=100, alpha=0.5, linewidths=2, c='#aaFFaa', edgecolors='g', label='sig5')
ax2.scatter(arr_x6, arr_y6, s=100, alpha=0.5, linewidths=2, c='#FFaaaa', edgecolors='r', label='sig6')
ax2.set_title("principal components made from RT metrics(4,5,6)", fontsize=14)
ax2.set_xlim(-80,100)
ax2.set_ylim(-4,8)
ax2.set_xlabel("first component")
ax2.set_ylabel("second component")
ax2.legend(loc='best', borderaxespad=1, fontsize=14)

ax2.grid(True)
plt.show()

```

QEU:FOUNDER ： “これが結論だね。主成分の第1と第2の散布図です。”

![image2-77-1](https://yaber1965.github.io/images/image2-77-1.jpg)

D先生 ： “あ～ぁ、だめだこりゃ・・・。これでは判別は不可能ですね。”

QEU:FOUNDER ： “これはNLPという技術分野が、RTメトリックスには荷が重すぎるのが原因・・・。NLPってデータとしては予測技術では時系列分析と同じになるんだけど、複雑すぎるんですよ。”

D先生 ： “設備異常の予測なんかは簡単でしょうね。”

![image2-77-2](https://yaber1965.github.io/images/image2-77-2.jpg)

QEU:FOUNDER ： “正常モードと各種異常モードが発生する直前のデータを単位空間とし、それらをSVM（サポートベクトルマシン）やディープラーニングに載せるだけだから、とても簡単です。今回の失敗で、逆に自信がつきましたね。”

D先生 ： “じゃあ、さらに次に行きます？ディープラーニングに・・・。”

QEU:FOUNDER ： “もう無理、やめましょう・・・。”

D先生 ： “りょうかいです。それでは、CMです。”

### [＞寄付のお願い(別のページに飛びます)＜](https://jpnqeur21vinsp.blogspot.com/2022/04/qeur21tynlp67-rt4_18.html)

QEU:FOUNDER ： “次は自動検査プロジェクトにつづく・・・。”

## ～　まとめ　～

QEU:FOUNDER ： “ちょっと疲れたので、休みましょう。この音楽でも聴きながら・・・。”

<iframe width="560" height="315" src="https://www.youtube.com/embed/FmGYxpVzI_g" ti-tle="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; en-crypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

D先生 ： “聞いているとリラックスできますね。ん・・・？“

![image2-77-3](https://yaber1965.github.io/images/image2-77-3.jpg)

QEU:FOUNDER ： “どうした？”

![image2-77-4](https://yaber1965.github.io/images/image2-77-4.jpg)

C部長 : “この国・・・、どこ・・・？”

QEU:FOUNDER ： “え～っと・・・、D国ですよ。くるくる回るモノがたくさん海についてるね・・・。”

![image2-77-5](https://yaber1965.github.io/images/image2-77-5.jpg)

C部長 : “信じられない。火力発電所のそばに風車が・・・。”

QEU:FOUNDER ： “なんか、「別次元」の国ダネ・・・。”

![image2-77-6](https://yaber1965.github.io/images/image2-77-6.jpg)

C部長 : “風車が街のこんなに近くに・・・。“

QEU:FOUNDER ： “街の美観を損ねると思っていないのかな？。”

D先生 ： “逆に、誇りを感じているのでしょう。“

QEU:FOUNDER ： “イヤイヤ・・・。リラックスしようと思ったら、逆に興奮してきたわ（笑）。”


