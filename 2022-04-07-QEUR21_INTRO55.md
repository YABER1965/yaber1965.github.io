## QEUR21_FATOY11:　カテゴリ変数入りデータの予測 (その6)

## ～　出来栄えは単位空間次第か・・・？　～

### ・・・　まだ試行錯誤はつづいています　・・・

QEU:FOUNDER ： “T法(2)を使ったメトリックス計算結果は、こうなりました・・・。”

__(month)__
![image1-55-1](https://yaber1965.github.io/images/image1-55-1.jpg)

__(weekday)__
![image1-55-2](https://yaber1965.github.io/images/image1-55-2.jpg)

D先生 ： “こっ・・・、これは・・・。エンベッディングの場合と全く違うメトリックス分布になりました。”

QEU:FOUNDER ： “1次関数VS2次関数の戦い（笑）。これはワクワクしますね。あとはディープラーニングをまわすだけです。プログラムをいきなり、ドン！！”

```python
# -------------------------
# calc_dl_t2m_cat2vec_example.py
# エンベッティングによる予測事例(PyTorch - t2m)
# -------------------------
import pandas as pd
import torch
import numpy as np
import matplotlib.pyplot as plt
# One-hot Encoding the Island Feature
from sklearn.preprocessing import OneHotEncoder
%matplotlib inline 

# -------------------------
# TRAIN側の変換作業
# -------------------------
path = './'
# 基本データ
data_df = pd.read_csv(path+'bike_sharing_daily_t2m.csv')
del data_df['dteday']
del data_df['yr']
del data_df['casual']
del data_df['registered']
num_data = len(data_df)
print(num_data)
data_df.head()

# mnthのエンベッディング
# CSVファイルを読み込む
mt_df = pd.read_csv(path+'t2m_table_monthC.csv')
#mt_df

# month : エンベッディングに変換する
arr_mnth    = mt_df['ITEM'].values
arr_embed_1 = mt_df['BETA'].values
arr_embed_2 = mt_df['SNR'].values
# -----
add_embeddA = []
add_embeddB = []
for iRow in range(num_data):
    val_mnth = data_df.loc[iRow, 'mnth']
    jCol = val_mnth -1
    add_embeddA.append(arr_embed_1[jCol])
    add_embeddB.append(arr_embed_2[jCol])
data_df['mnth_A'] = add_embeddA
data_df['mnth_B'] = add_embeddB
del data_df['mnth']
data_df.head()

# weekdayのエンベッディング
# CSVファイルを読み込む
wd_df = pd.read_csv(path+'t2m_table_weekdayC.csv')
wd_df

# weekday : エンベッディングに変換する
arr_wkday   = wd_df['ITEM'].values
arr_embed_1 = wd_df['BETA'].values
arr_embed_2 = wd_df['SNR'].values
#print(arr_wkday)
# -----
add_embeddA = []
add_embeddB = []
for iRow in range(num_data):
    val_wkday = data_df.loc[iRow, 'weekday']
    jCol = val_wkday -1
    add_embeddA.append(arr_embed_1[jCol])
    add_embeddB.append(arr_embed_2[jCol])
data_df['wkday_A'] = add_embeddA
data_df['wkday_B'] = add_embeddB
del data_df['weekday']
data_df.head()

# ------
# One-hot Encoding the weathersit Feature
one_hot = OneHotEncoder()
data_df2 = data_df.copy()
encoded = one_hot.fit_transform(data_df2[['weathersit']])
data_df2[one_hot.categories_[0]] = encoded.toarray()
del data_df2['weathersit']
data_df2.head()

# ------
# train用データセット
train_df = data_df2.copy()
train_df = train_df[train_df["use"]=="train"]
del train_df['use']
arr_train_Y = train_df.loc[:,"cnt"].values
print(arr_train_Y)
del train_df['cnt']
mx_train_Xs = train_df.values
print(mx_train_Xs)
#train_df.head()

# ------
# test用データセット
test_df = data_df2.copy()
test_df = test_df[test_df["use"]=="test"]
del test_df['use']
arr_test_Y = test_df.loc[:,"cnt"].values
del test_df['cnt']
mx_test_Xs = test_df.values

# ------
# テンソル化
X_train = torch.from_numpy(mx_train_Xs).float()
new_shape = (len(arr_train_Y), 1)
y_train = torch.from_numpy(arr_train_Y).float()
y_train = y_train.view(new_shape)
X_test = torch.from_numpy(mx_test_Xs).float()
new_shape = (len(arr_test_Y), 1)
y_test = torch.from_numpy(arr_test_Y).float()
y_test = y_test.view(new_shape)

# インプットデータの確認
print("X_train.shape：",X_train.shape)
print("y_train.shape：",y_train.shape)
#X_train.shape： torch.Size([610, 26])
#y_train.shape： torch.Size([610, 1])

# ------
# D_in is input dimension;H is hidden dimension; D_out is output dimension.
D_in, H, D_out = 11, 20, 1
# 学習モデルの定義
# model
class Net(torch.nn.Module):
    def __init__(self, D_in, H, D_out):
        super(Net, self).__init__()
        self.L0 = torch.nn.Linear(D_in, H)
        self.N0 = torch.nn.ReLU()
        self.L1 = torch.nn.Linear(H, D_out)

    def forward(self, x):
        x = self.L0(x)
        x = self.N0(x)
        x = self.L1(x)
        return x

model = Net(D_in, H, D_out)
criterion = torch.nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.1)

# NN繰り返し学習する
losses = []
testlosses = []
for t in range(5000):
    y_pred = model(X_train)

    loss = criterion(y_pred, y_train)
    losses.append(loss.item())
    if t % 500 == 0:
        print(t, loss.item())

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    with torch.no_grad():
        y_test_pred = model(X_test)
        testloss = criterion(y_test_pred, y_test)
        testlosses.append(testloss.item())

# ------
# drawing learning curve
def learn_curve(losses, testlosses):
    fig = plt.figure(figsize=(10,6))
    ax = fig.add_subplot(1,1,1)
    plt.plot(list(range(len(losses))), losses, label = "losses" , color = "r")
    plt.plot(list(range(len(losses))), testlosses, label = "testlosses" , color = "g")
    plt.xlabel('#epoch')
    plt.ylabel('loss')
    plt.legend(loc='upper right')
    plt.show()

# 学習結果（loss:trainloss, testloss:いわゆるvalidloss）
learn_curve(losses, testlosses)

# ------
# make a class prediction for one row of data
def predict(row, model):
    # make prediction
    yhat = model(row)
    # retrieve numpy array
    yhat = yhat.detach().numpy()
    return yhat.flatten()

# 学習結果（精度検証）
ycomp = predict(X_test, model)
fig = plt.figure(figsize=(10,6))
ax = fig.add_subplot(1,1,1)
plt.scatter(ycomp, arr_test_Y, label = "accuracy" , color = "r")
plt.xlabel('prediction')
plt.ylabel('actual')
plt.legend(loc='best')
plt.show()

```

QEU:FOUNDER ： “こんな結果がでました。ワンホット、エンベッディングの結果と比較しましょう。”

**（ワンホット法）**
![image1-55-3](https://yaber1965.github.io/images/image1-55-3.jpg)

**（エンベッディング法）**
![image1-55-4](https://yaber1965.github.io/images/image1-55-4.jpg)

**（T法単位空間A）**
![image1-55-5](https://yaber1965.github.io/images/image1-55-5.jpg)

D先生 ： “ワンホットのレベルとそれほど変わらないですね。そういえば、今回のT法で単位空間をどうとったんでしたっけ？”

QEU:FOUNDER ： “（単位空間は）テストデータベースをそのままつかっています。ですから、2-5-8-11月をつかっています。”

D先生 ： “1年のうち一番寒い2月だけを単位空間としてとるとどうなりますか？”

QEU:FOUNDER ： “じゃあ、やってみました。結果をドン・・・。”

**（メトリックス）**
![image1-55-6](https://yaber1965.github.io/images/image1-55-6.jpg)

**（学習結果）**
![image1-55-7](https://yaber1965.github.io/images/image1-55-7.jpg)

D先生 ： “分布の線形性は「ずば抜けて良く」なりましたが、傾きがずれまくってます（笑）。トータルとしては精度が悪くなったような・・・。じゃあ、8月を単位空間でやると？”

QEU:FOUNDER ： “イチかバチでドン！！”

**（メトリックス）**
![image1-55-8](https://yaber1965.github.io/images/image1-55-8.jpg)

**（学習結果）**
![image1-55-9](https://yaber1965.github.io/images/image1-55-9.jpg)

D先生 ： “あ～あ・・・、これもだめか・・・。全体として傾きはあるていど修正されたんですがばらつきが増えました。まあ、単位空間の決め方で当てはめのバラツキが大きく変わることが分かったことは収穫でしたね。”

QEU:FOUNDER ： “じゃあ、本番は次で・・・。”

D先生 ： “あの・・・、本番が何回あるの？”

QEU:FOUNDER ： “もともと、次回のスキームを本番と考えていたんです。”


## ～　まとめ　～

QEU:FOUNDER ： “おっさんのコーナーです。しかし、地味やなぁ・・・。”

<iframe width="560" height="315" src="https://www.youtube.com/embed/rzBPDsW3QQU" ti-tle="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; en-crypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

C部長 : “それが「味」なんですよ。旭川ラーメンを食べたい。”

