## QEUR21_FATOY7:　閑話休題～カテゴリ変数入りデータの予測 (その2)

## ～　思ったよりも具合が良くて「意外・・・」！？　～

### ・・・　ベースライン(baseline)を設定しましょう　・・・

D先生 ： “さあて始めましょうか・・・。今回のプロジェクトは手法の比較になるので、しっかり比較できるようなプラットフォームが必要ですね。”

QEU:FOUNDER ： “ベースラインというよね、この場合・・・。エンベッドをやる前にワンホットをやらないと・・・。”

D先生 ： “いやいや・・・。それ以前に、ディープラーニングの実力が正しく計測されていないといけません。”

QEU:FOUNDER ： “もっとも予測が簡単な比変量(continuous-ratio)データの予測がどれだけできるのかから始めなければいけないということね。そうだね・・・。”

![image1-51-1](https://yaber1965.github.io/images/image1-51-1.jpg)

QEU:FOUNDER ： “じゃあ、**「ワイン品質の予測」(↓)**をやりましょうか・・・。”

![image1-51-2](https://yaber1965.github.io/images/image1-51-2.jpg)

D先生 ： “それはいいですね。”

QEU:FOUNDER ： “じゃあ、これをPyTorchで解いてみましょう。プログラムをドン！！”

```python
# -------------------------
# onehot_cat2vec_example.py
# エンベッティングによる予測事例
# その１：練習問題（wine quality）
# -------------------------
import pandas as pd
import numpy as np
import torch
import matplotlib.pyplot as plt
# One-hot Encoding the Island Feature
from sklearn.preprocessing import OneHotEncoder
%matplotlib inline 

# ------
# CSVファイルの読み込み（trainとtestを含む）
path = './'
temp_df = pd.read_csv(path+'winequality-red.csv')
temp_df.head()

# ------
# train用データセット
train_df = temp_df.copy()
train_df = train_df[train_df["use"]=="train"]
del train_df['use']
arr_train_Y = train_df.loc[:,"quality"].values
#print(arr_train_Y)
del train_df["quality"]
mx_train_Xs = train_df.values
#print(mx_train_Xs)
#train_df.head()

# ------
# test用データセット
test_df = temp_df.copy()
test_df = test_df[test_df["use"]=="test"]
del test_df['use']
arr_test_Y = test_df.loc[:,"quality"].values
#print(arr_test_Y)
del test_df["quality"]
mx_test_Xs = test_df.values
print(mx_test_Xs)
#test_df.head()

# ------
# テンソル化
X_train = torch.from_numpy(mx_train_Xs).float()
new_shape = (len(arr_train_Y), 1)
y_train = torch.from_numpy(arr_train_Y).float()
y_train = y_train.view(new_shape)
X_test = torch.from_numpy(mx_test_Xs).float()
new_shape = (len(arr_test_Y), 1)
y_test = torch.from_numpy(arr_test_Y).float()
y_test = y_test.view(new_shape)
#print(y_train.shape)
#print(X_test)
#print(y_test)

# インプットデータの確認
print("X_train.shape：",X_train.shape)
print("y_train.shape：",y_train.shape)
# X_train.shape： torch.Size([1198, 11])
# y_train.shape： torch.Size([1198, 1])

# ------
# D_in is input dimension;H is hidden dimension; D_out is output dimension.
D_in, H, D_out = 11, 20, 1
# 学習モデルの定義
# model
class Net(torch.nn.Module):
    def __init__(self, D_in, H, D_out):
        super(Net, self).__init__()
        self.L0 = torch.nn.Linear(D_in, H)
        self.N0 = torch.nn.ReLU()
        self.L1 = torch.nn.Linear(H, D_out)

    def forward(self, x):
        x = self.L0(x)
        x = self.N0(x)
        x = self.L1(x)
        return x

model = Net(D_in, H, D_out)
criterion = torch.nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.1)

# NN繰り返し学習する
losses = []
testlosses = []
for t in range(5000):
    y_pred = model(X_train)

    loss = criterion(y_pred, y_train)
    losses.append(loss.item())
    if t % 500 == 0:
        print(t, loss.item())

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    with torch.no_grad():
        y_test_pred = model(X_test)
        testloss = criterion(y_test_pred, y_test)
        testlosses.append(testloss.item())

# ------
# drawing learning curve
def learn_curve(losses, testlosses):
    fig = plt.figure(figsize=(10,6))
    ax = fig.add_subplot(1,1,1)
    plt.plot(list(range(len(losses))), losses, label = "losses" , color = "r")
    plt.plot(list(range(len(losses))), testlosses, label = "testlosses" , color = "g")
    plt.xlabel('#epoch')
    plt.ylabel('loss')
    plt.legend(loc='upper right')
    plt.show()

# 学習結果（loss:trainloss, testloss:いわゆるvalidloss）
learn_curve(losses, testlosses)

# ------
# make a class prediction for one row of data
def predict(row, model):
    # make prediction
    yhat = model(row)
    # retrieve numpy array
    yhat = yhat.detach().numpy()
    return yhat.flatten()

# 学習結果（精度検証）
ycomp = predict(X_test, model)
#print(ycomp)
fig = plt.figure(figsize=(10,6))
ax = fig.add_subplot(1,1,1)
plt.scatter(ycomp, arr_test_Y, label = "accuracy" , color = "r")
plt.xlabel('prediction')
plt.ylabel('actual')
plt.legend(loc='best')
plt.show()

```

QEU:FOUNDER ： “これがベースラインのベースラインになるわけだが、いきなり結果を出しましょう。いままで、さんざんやっている話なんで・・・。”

![image1-51-3](https://yaber1965.github.io/images/image1-51-3.jpg)

D先生 ： “学習の収束レベルは見事ですね。でも、予測精度としてはここまでなのか・・・。以前、KERASで同じデータベースの回帰をやったら同じ感じだったので、これでいいんじゃないでしょうか・・・。”

QEU:FOUNDER ： “じゃあ、次は自転車(bike_sharing_daily_train)のデータで「ワンホット(onehot)予測」をやりましょう。でも、onehot変換をやるプログラムを作るのは結構大変でした。”

D先生 ： “例によってパクり？”

### （From wikipedia）
### 車輪の再発明（しゃりんのさいはつめい、英: reinventing the wheel）とは、「広く受け入れられ確立されている技術や解決法を（知らずに、または意図的に無視して）再び一から作ること」を指すための慣用句。誰でも直観的にその意味が分かるように、車輪という誰でも知っていて古くから広く使われている既存の技術を比喩の題材として使った慣用表現で、世界中で使われている。

QEU:FOUNDER ： “おいおい「お勉強」と呼んでくれ。車輪の再発明はよくない。「1+1＝2」を勉強することはパクリじゃないだろう・・・、でもね、J国語でpythonプログラムにおいて**「効率的にonehot変換する方法」**についての情報を得ようとしたらすごく苦労しました。まあ、これで**J国のAI熱のレベル**がわかったね。どこの国の参考Webが多かったかな・・・、たぶんI国・・・”

D先生 ： “ガンダーラ・・・。”

QEU:FOUNDER ： “あそこ、近年の経済が伸びている理由がわかるよね。じゃあプログラム解説にいくよ・・・。晒す部分は前半のワンホット変換部だけです。後半はワインの件と同じだからね。”


```python
# -------------------------
# onehot_cat2vec_example.py
# エンベッティングによる予測事例
# その２：ワンホットでやってみる
# -------------------------
import pandas as pd
import numpy as np
import torch
import matplotlib.pyplot as plt
# One-hot Encoding the Island Feature
from sklearn.preprocessing import OneHotEncoder
%matplotlib inline 

# ------
# CSVファイルの読み込み（trainとtestを含む）
path = './'
temp_df = pd.read_csv(path+'bike_sharing_daily_train.csv')
#temp_df = df.loc[:,'mnth':'cnt']
del temp_df['dteday']
del temp_df['yr']
del temp_df['casual']
del temp_df['registered']
temp_df.head()

# ------
# One-hot Encoding the weathersit Feature
one_hot = OneHotEncoder()
temp_df2 = temp_df.copy()
encoded = one_hot.fit_transform(temp_df2[['weathersit']])
temp_df2[one_hot.categories_[0]] = encoded.toarray()

# ------
# One-hot Encoding the weekday Feature
temp_df3 = temp_df2.copy()
encoded = one_hot.fit_transform(temp_df3[['weekday']])
temp_df3[one_hot.categories_[0]] = encoded.toarray()

# ------
# One-hot Encoding the mnth Feature
temp_df4 = temp_df3.copy()
encoded = one_hot.fit_transform(temp_df4[['mnth']])
temp_df4[one_hot.categories_[0]] = encoded.toarray()
del temp_df4['mnth']
del temp_df4['weekday']
del temp_df4['weathersit']
#temp_df4.head()

```

QEU:FOUNDER ： “これ（↓）は変換前（のデータ）・・・。カテゴリ・データの値が文字列「MT1など」になっていることに注意してください。あとは、useコラムに「train/test」が記入されています。これはデータの分離用に必要です。”

![image1-51-4](https://yaber1965.github.io/images/image1-51-4.jpg)

QEU:FOUNDER ： “そして、これ（↓）がワンホット変換後の状況です。”

![image1-51-5](https://yaber1965.github.io/images/image1-51-5.jpg)

D先生 ： “わぁ・・・、コラム（項目）数が27もあるのか・・・。で、肝心の結果は？”

QEU:FOUNDER ： “結果をドン！すでに説明したワインデータセットの結果と比較をしてくださいね。”

![image1-51-6](https://yaber1965.github.io/images/image1-51-6.jpg)

D先生 ： “えっ？意外だ・・・。思ったよりもいいですね。”

QEU:FOUNDER ： “そうだね・・・。LOSSの値だけを見ると大きいように思えるが、散布図で予測精度を見ると思ったよりも当てはまりがいいように見えます。ただ、当てはめがいいのは部分的だけどね・・・。”

D先生 ： “そうそう・・・。おそらく、この現象は学習データ量が足らないだけです。”

QEU:FOUNDER ： “項目数を著しく多くさせるワンホット変換の欠点がでたよね。”

D先生 ： “う～ん・・・。・・・ということは、学習データが少なくてもイケるT法(2)でも精度が上がらないわけですね。”

QEU:FOUNDER ： “基本はそうだとは思います・・・。あとから、ちょっとそれを使って「遊び」ましょう（笑）。”


## ～　まとめ　～

### ・・・　「おっさん推し」はまたまだ続きます　・・・

QEU:FOUNDER ： “あのおっさんはどこだ？”

<iframe width="560" height="315" src="https://www.youtube.com/embed/migs3JgISfE" ti-tle="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; en-crypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

C部長 : “この動画では「うどん」のようです。”

QEU:FOUNDER ： “あの方は日本中を回っていて、タフですね。”

